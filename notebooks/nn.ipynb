{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba946e7e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Twitter Posts\n",
    "<!-- Notebook name goes here -->\n",
    "<center><b>Notebook: Neural Network Model, Error Analysis, and Tuning</b></center>\n",
    "<br>\n",
    "\n",
    "**By**: Stephen Borja, Justin Ching, Erin Chua, and Zhean Ganituen.\n",
    "\n",
    "**Dataset**: Hussein, S. (2021). Twitter Sentiments Dataset [Dataset]. Mendeley. https://doi.org/10.17632/Z9ZW7NT5H2.1\n",
    "\n",
    "**Motivation**: Every minute, social media users generate a large influx of textual data on live events. Performing sentiment analysis on this data provides a real-time view of public perception, enabling quick insights into the general populationâ€™s opinions and reactions.\n",
    "\n",
    "**Goal**: By the end of the project, our goal is to create and compare supervised learning algorithms for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a380d-da2b-4ec3-99b3-f09ee41a46f5",
   "metadata": {},
   "source": [
    "# **1. Project Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92ea17f6-d1a3-4c4f-8e51-e3478eed17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# General Imports\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../lib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d3968-22e5-452c-9a05-952a4829579a",
   "metadata": {},
   "source": [
    "# **2. Data Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3490a-14d8-4b20-a051-9ff692ab905e",
   "metadata": {},
   "source": [
    "Run the data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c665e7fa-2134-4610-8ba6-c687e92fa59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Setup is DONE\n",
      "All tests passed.\n"
     ]
    }
   ],
   "source": [
    "import IPython.core.page\n",
    "import builtins\n",
    "from IPython.utils.capture import capture_output\n",
    "\n",
    "pager = IPython.core.page.page\n",
    "helper = builtins.help\n",
    "\n",
    "IPython.core.page.page = lambda *args, **kwargs: None\n",
    "builtins.help = lambda *args, **kwargs: None\n",
    "\n",
    "try:\n",
    "    with capture_output():\n",
    "        %run data.ipynb\n",
    "finally:\n",
    "    IPython.core.page.page = pager\n",
    "    builtins.help = helper\n",
    "\n",
    "print(\"Data Setup is DONE\")\n",
    "\n",
    "# Tests\n",
    "assert X.shape == (162_801, 29318), \"Feature matrix shape is wrong; expected (162_801, 29318)\"\n",
    "assert y.shape == (162_801,), \"Labels shape is wrong; expected (162_801,)\"\n",
    "\n",
    "assert X_train.shape == (113_960, 29_318), \"Train shape is wrong; expected (113_960, 2)\"\n",
    "assert X_test.shape == (48_841, 29_318), \"Test shape is wrong; expected (48_841, 2)\"\n",
    "\n",
    "assert y_train.shape == (113_960,), \"Train labels shape is wrong; expected (113_960,)\"\n",
    "assert y_test.shape == (48_841,), \"Test labels shape is wrong; expected (48_841,)\"\n",
    "print(\"All tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a3771-5170-4588-b77e-f271786fffb3",
   "metadata": {},
   "source": [
    "Now, we need to convert the dataset to a Pytorch compatible dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d69a404-fbb8-4699-b490-ce2c57652df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWForTorch(Dataset):\n",
    "    label_map = {-1: 0, 0: 1, 1: 2}\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y.map(self.label_map).values.astype(int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].toarray().ravel().astype(\"float32\")\n",
    "        y = self.y[idx]\n",
    "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "train_dataset = BoWForTorch(X_train, y_train)\n",
    "test_dataset  = BoWForTorch(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cf691-f2b1-4b9e-a0f8-d702cd671b86",
   "metadata": {},
   "source": [
    "Then, construct DataLoader objects for the train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95f42d81-46bb-4d1c-aa09-1120e0caf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44fa53-033c-4adb-8422-cf23813b91fb",
   "metadata": {},
   "source": [
    "# **3. Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9168c785-75cd-4a28-92ae-6afc9eeb8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLittlePony(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, n_sentiment, n_hiddens=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [nn.Linear(vocab_size, hidden_dim), nn.ReLU(), nn.Dropout(dropout)]\n",
    "\n",
    "        for _ in range(n_hiddens - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, n_sentiment))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a96ee3-83e6-4af3-9383-612a43b089e1",
   "metadata": {},
   "source": [
    "## **Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "960631a1-8842-4e53-8a13-8423e9e377a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparameters:\n",
    "    \"\"\"\n",
    "    Hyperparameters for the multi-layer perceptron (MLP) used for sentiment analysis.\n",
    "\n",
    "    Remark (Zhean). I defined this as a class to enforce IMMUTABILITY of the hyperparamters. That is,\n",
    "    no matter what happens in the code, we can ensure that these are never changed.\n",
    "\n",
    "    # Hyperparameters\n",
    "    * N_EPOCHS: The number of training epochs.\n",
    "    * N_HIDDENS: The number of hidden layers in the MLP.\n",
    "    * N_SNEAKY_NEURONS: The number of neurons in each hidden layer.\n",
    "\n",
    "    # Usage\n",
    "    ```\n",
    "    print(Hyperparameters.N_EPOCHS)          # 10\n",
    "    print(Hyperparameters.N_HIDDENS)         # 2\n",
    "    print(Hyperparameters.N_SNEAKY_NEURONS) # 128\n",
    "    ```\n",
    "    \"\"\"\n",
    "    N_EPOCHS = 10\n",
    "    N_HIDDENS = 2\n",
    "    N_SNEAKY_NEURONS = 128\n",
    "\n",
    "    # block assignments\n",
    "    def __setattr__(self, name, value):\n",
    "        raise AttributeError(\"Cannot modify Hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319ee6b-88d9-4856-96f7-2c9c07600b56",
   "metadata": {},
   "source": [
    "## **Initializing the MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1c11623-a7e7-45ea-adf9-85d28565ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "MLP initialized\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "vocab_size = X_train.shape[1]\n",
    "n_sentiment = 3\n",
    "\n",
    "model = MyLittlePony(\n",
    "    vocab_size  = vocab_size,\n",
    "    hidden_dim  = Hyperparameters.N_SNEAKY_NEURONS,\n",
    "    n_sentiment = 3,\n",
    "    n_hiddens   = Hyperparameters.N_HIDDENS\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(\"MLP initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b829a663-948d-4d48-b898-56397d6abd06",
   "metadata": {},
   "source": [
    "# **4. Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06b038-1e07-4d46-a171-166d88e6eee4",
   "metadata": {},
   "source": [
    "## **Training Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d915f1f1-95fd-4101-b9ab-720187c17b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ade42-e228-4494-829c-ba3aa757268e",
   "metadata": {},
   "source": [
    "## **Training Proper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14214db7-8333-47cd-8399-962021020153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce335b4f26ec49b795ab4ec4ee5063f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.5421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b9f097030d4e2f94edcf31564ae87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Loss: 0.3276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7a4a6bb1f84108a9306475dbecce28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Loss: 0.2021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d8b55a1a8a414a9ec84a9bea472f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Loss: 0.1164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0b79f150a7423eaf29f12acb4deed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Loss: 0.0731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf1801fbdae4b55a844904fb1f59858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Loss: 0.0525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9ce1644c744d2e8827da3d2b9f30a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Loss: 0.0408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71deda9ab11b4014b5f1f27b2a95ffe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Loss: 0.0344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe776c1f98b427994889370bdf614c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Loss: 0.0296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4608c30f19fc4ba393446c081ca2a7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/3562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Loss: 0.0259\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(Hyperparameters.N_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Hyperparameters.N_EPOCHS}\"):\n",
    "        x_batch = x_batch.to(device, non_blocking=True)\n",
    "        y_batch = y_batch.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{Hyperparameters.N_EPOCHS} | Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd50210-79ec-448c-95a9-457914549d4a",
   "metadata": {},
   "source": [
    "# **5. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba1e6372-c87d-4038-8bf1-13c286e0f64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2d6fbb92bd4b89b1023571faad70e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8190\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a validation/test dataset.\n",
    "\n",
    "    # Parameters\n",
    "    * model: PyTorch model\n",
    "    * data_loader: DataLoader for validation/test set\n",
    "    * device: torch.device ('cpu' or 'cuda')\n",
    "\n",
    "    # Returns\n",
    "    * accuracy: float, proportion of correct predictions\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(data_loader, desc=\"Validation\"):\n",
    "            x_batch = x_batch.to(device, non_blocking=True)\n",
    "            y_batch = y_batch.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(x_batch)\n",
    "            \n",
    "            prediction = logits.argmax(dim=1)\n",
    "\n",
    "            correct += (prediction == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "val_accuracy = evaluate(model, test_loader, device)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
