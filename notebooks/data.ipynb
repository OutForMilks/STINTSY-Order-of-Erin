{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44906e4e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Twitter Posts\n",
    "<!-- Notebook name goes here -->\n",
    "<center><b>Notebook: Data Description, Cleaning, Exploratory Data Analysis, and Preprocessing</b></center>\n",
    "<br>\n",
    "\n",
    "**by**: Stephen Borja, Justin Ching, Erin Chua, and Zhean Ganituen.\n",
    "\n",
    "**dataset**: Hussein, S. (2021). Twitter Sentiments Dataset [Dataset]. Mendeley. https://doi.org/10.17632/Z9ZW7NT5H2.1\n",
    "\n",
    "**motivation**: Every minute, social media users generate a large influx of textual data on live events. Performing sentiment analysis on this data provides a real-time view of public perception, enabling quick insights into the general population‚Äôs opinions and reactions.\n",
    "\n",
    "**goal**: By the end of the project, our goal is to create and compare supervised learning algorithms for sentiment analysis.\n",
    "\n",
    "### **dataset description**\n",
    "\n",
    "The Twitter Sentiments Dataset is a dataset that contains nearly 163k tweets from Twitter. The time period of when these were collected is unknown, but it was published to Mendeley Data on May 14, 2021 by Sherif Hussein of Mansoura University.\n",
    "\n",
    "Tweets were extracted using the Twitter API, but the specifics of how the tweets were selected are unmentioned. The tweets are mostly English with a mix of some Hindi words for code-switching <u>(El-Demerdash., 2021)</u>. All of them seem to be talking about the political state of India. Most tweets mention Narendra Modi, the current Prime Minister of India.\n",
    "\n",
    "Each tweet was assigned a label using TextBlob's sentiment analysis <u>(El‚ÄëDemerdash, Hussein, & Zaki, 2021)</u>, which assigns labels automatically.\n",
    "\n",
    "Twitter_Data\n",
    "- **`clean_text`**: The tweet's text\n",
    "- **`category`**: The tweet's sentiment category\n",
    "\n",
    "What each row and column represents: `each row represents one tweet.` <br>\n",
    "Number of observations: `162,980`\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) Code-switching is the practice of alternating between two languages $L_1$ (the native language) and $L_2$ (the source language) in a conversation. In this context, the code-switching is done to appear more casual since the conversation is done via Twitter (now, X). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47491b2f",
   "metadata": {},
   "source": [
    "## **1. Project Set-up**\n",
    "We set the global imports for the projects (ensure these are installed via uv and is part of the environment). Furthermore, load the dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d7578d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:01:26.803271Z",
     "start_time": "2025-06-17T14:01:26.567527Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Use lib directory\n",
    "sys.path.append(os.path.abspath(\"../lib\"))\n",
    "\n",
    "# Imports from lib files\n",
    "from janitor import *\n",
    "from lemmatize import lemmatizer\n",
    "from boilerplate import stopwords_set\n",
    "from bag_of_words import BagOfWordsModel\n",
    "\n",
    "# Pandas congiruation\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Load raw data file\n",
    "df = pd.read_csv(\"../data/Twitter_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ec446",
   "metadata": {},
   "source": [
    "## **2. Data Cleaning**\n",
    "This section discusses the methodology for data cleaning.\n",
    "\n",
    "As to not waste computational time, a preliminary step is to ensure that no `NaN` or duplicate entries exist before the cleaning steps. Everytime we call a `.drop()` function, we will show the result of `info()` to see how many entries are filtered out.\n",
    "\n",
    "Let's first drop the `NaN` entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "28609dbc-1d51-4bba-b64c-a570c9ac4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8865f85-09ec-4528-8b69-4f39ec72ae26",
   "metadata": {},
   "source": [
    "Now, remove the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "452f1167-41cd-49a9-a328-8311f1567071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b98d6d",
   "metadata": {},
   "source": [
    "We also ensure that all the values in the `category` column are within the range of [-1, 0, 1], which represent the three sentiments, namely, negative, neutral, and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c9f17c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225e3f7",
   "metadata": {},
   "source": [
    "Then remove any values outside of the provided range to keep the data consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a7fa1384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129756   -1.0\n",
       "159102    1.0\n",
       "104282    0.0\n",
       "91065     1.0\n",
       "34390     1.0\n",
       "61503     0.0\n",
       "127467   -1.0\n",
       "100487    0.0\n",
       "42512     1.0\n",
       "11929    -1.0\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['category'].isin([-1, 0, 1])]\n",
    "df['category'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a31de7",
   "metadata": {},
   "source": [
    "By converting a CSV file into a DataFrame, pandas automatically defaults numeric values to `float64` when it encounters decimals or `NaN` types. Text of `str` type get inferred and loaded into a `object` as the generic type for strings. We can check the dtype of our DataFrame column through `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a5f1374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d93c9",
   "metadata": {},
   "source": [
    "First we convert column `category` from `float64` to `int64` after dropping `NaN` rows and removing any values outside of [-1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fe43fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Series name: category\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "162969 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "df['category'] = df['category'].astype(int)\n",
    "df['category'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4b01cbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87818     1\n",
       "85707    -1\n",
       "120828   -1\n",
       "105907    0\n",
       "120843    1\n",
       "125318    1\n",
       "140007    1\n",
       "30775    -1\n",
       "31051     0\n",
       "33845    -1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a8070",
   "metadata": {},
   "source": [
    "Next, we convert column `clean_string` from `object` type into the pandas defined `string` type for consistency and better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "edc2bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Series name: clean_text\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "162969 non-null  string\n",
      "dtypes: string(1)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = df['clean_text'].astype('string')\n",
    "df['clean_text'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3d21b06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[0, 'clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec33f2-9967-4458-878b-79b697ec9e4e",
   "metadata": {},
   "source": [
    "## **Main Cleaning Pipeline**\n",
    "\n",
    "We follow a similar methodology for data cleaning presented in (George & Murugesan, 2024). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a22cb",
   "metadata": {},
   "source": [
    "### **Normalization**\n",
    "\n",
    "Due to the nature of the text being tweets, we noticed a prevalence in the use of emojis and accented characters as seen in the samples below. Although in a real-world context these do serve as a form of emotional expression, it provides no relevance towards _textual_ sentiment analysis, thus we normalize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e06f520c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89813                                                                                                                                                                                                    just love the new con√ßept must watch th√© video \n",
       "72727                                                                                                                                                                        modi hails indias arrival space power after shoots down satellite test v√≠a \n",
       "86264                                                                                                                                                    there should some basic quality check such clich√©d juvenile satire silly even for modi bashing \n",
       "124646    arnab vehemently ranted for weeks against sushma and vasundhara raje during lalit modi expos√©rahul was apparently unbiased anchor until and arun purie travelled together with amit shah during karnataka poll both now are panna pramukhs bjp\n",
       "140427                                                                                                                                                                                                              edo nair√© too consumed hate for modi\n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with accented characters\n",
    "accented_char_rows = df[df['clean_text'].str.contains(r'√â|√©|√Å|√°|√≥|√ì|√∫|√ö|√≠|√ç')]\n",
    "accented_char_rows['clean_text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ff6b5d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121548      both seem stupid from there rhetoric speeches one says being anti modi anti india smh ‚Äç‚ôÇÔ∏è and another one still communist 21st century that‚Äôsin itself idiotic ‚Äç‚ôÇÔ∏è\n",
       "61554     modi has sensed somethingit was really desperate move himwas the nyay effect ‡§æ ‡§¨‡§¶‡§≤ ‡•Ä ‡•á anyway kudos the drdo isro for the achievement hats off all the scientists‚úåÔ∏è \n",
       "121880                                                                         @ kmsharma yes this chokidar modi sir thief who theft heart all man world\\n‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚úå‚úå‚úå‚úå‚úå‚úå‚úã \n",
       "82437                                                                                                                                 modi the great lion one roar enough ‚úåÔ∏è‚úåÔ∏è\n",
       "54332                                                               amazing promosyon really sir very congratulations super performance summit our prayers with you sir‚õ§‚õ§‚õ§‚õ§‚õ§  \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with emojis\n",
    "rows_with_emojis = df[df['clean_text'].str.contains(r'[\\u263a-\\U0001f645]', regex=True)]\n",
    "rows_with_emojis['clean_text'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb30dbd",
   "metadata": {},
   "source": [
    "The first function is the `normalize` function, it normalizes the text input to ASCII-only characters (say, \"c√≥mo est√°s\" becomes \"como estas\") and lowercased alphabetic symbols. The dataset contains Unicode characters (e.g., emojis and accented characters) which the function replaces to the empty string (`''`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b0425f96-ed91-41ca-9033-5bb53f14c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m normalize(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m normalize(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Normalize text from a pandas entry to ASCII-only lowercase characters. Hence, this removes Unicode characters with no ASCII\u001b[39m\n",
      "\u001b[33m    equivalent (e.g., emojis and CJKs).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    ASCII-normalized text containing only lowercase letters.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    normalize(\"¬øC√≥mo est√°s?\")\u001b[39m\n",
      "\u001b[33m    $ 'como estas?'\u001b[39m\n",
      "\n",
      "\u001b[33m    normalize(\" hahahaha HUY! Kamusta üòÖ Mayaman $$$ ka na ba?\")\u001b[39m\n",
      "\u001b[33m    $ ' hahahaha huy! kamusta  mayaman $$$ ka na ba?'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    normalized = unicodedata.normalize(\u001b[33m\"NFKD\"\u001b[39m, text)\n",
      "    ascii_text = normalized.encode(\u001b[33m\"ascii\"\u001b[39m, \u001b[33m\"ignore\"\u001b[39m).decode(\u001b[33m\"ascii\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m ascii_text.lower()\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "normalize??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc84505-f974-442b-8763-62bd20d729ea",
   "metadata": {},
   "source": [
    "### **Punctuations**\n",
    "Punctuations are part of natural speech and reading to provide a sense of structure, clarity, and tone to sentences, but in the context of a classification study punctuations do not add much information to the sentiment of a message. The sentiment of `i hate you!` and `i hate you` are going to be the same despite the punctuation mark `!` being used to accentuate the sentiment. We can see a sample of rows with punctations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3e026e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113455                                                     like congress claims because sowed the seeds happened all these loooters too sowed their seeds under government when comes obviously has come robbers aren‚Äô going wait \n",
       "43529                                                                                              heres how ajay devgn kriti sanon rajkummar rao madhavan replied narendra modi‚Äô ‚Äòvote kar‚Äô election 2019 campaign via namo app\\n\n",
       "128898    had manmohan singhs govt given clearance drdo ‡•á could have launched this 2014 2015 but singh hardly took any decision was the present govt modi which gave clearance and see the result for that modi govt must credited\n",
       "26163       modi had made advani the president india then you guys would have started hyperventilating about babri masjid seat gandhinagar given his daughter then dynast would been complain you hate modiji‚Äô guts sadhavi effect\n",
       "71902                                                                                                                    election commission examine narendra modi address nation mission shakti for poll code violation ‚ö°match ‚ö° \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with punctuation\n",
    "rows_with_punc = df[df['clean_text'].str.contains(r'[^\\w\\s]')]\n",
    "rows_with_punc['clean_text'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b3a75",
   "metadata": {},
   "source": [
    "The function `rem_punctuation` replaces all punctuations and special characters into an empty string (`''`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "62aa658b-8dbd-4533-af84-cbb221571835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m rem_punctuation(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m rem_punctuation(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Removes the punctuations. This function simply replaces all punctuation marks and special characters\u001b[39m\n",
      "\u001b[33m    to the empty string. Hence, for symbols enclosed by whitespace, the whitespace are not collapsed to a single whitespace\u001b[39m\n",
      "\u001b[33m    (for more information, see the examples).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the punctuation removed.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    rem_punctuation(\"this word $$ has two spaces after it!\")\u001b[39m\n",
      "\u001b[33m    $ 'this word  has two spaces after it'\u001b[39m\n",
      "\n",
      "\u001b[33m    rem_punctuation(\"these!words@have$no%space\")\u001b[39m\n",
      "\u001b[33m    $ 'thesewordshavenospace'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(f\"[{re.escape(string.punctuation)}]\", \u001b[33m\"\"\u001b[39m, text)\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rem_punctuation??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47e93e-aa0e-473c-89d5-f30df86815da",
   "metadata": {},
   "source": [
    "### **Numbers**\n",
    "Similar to punctuations, numbers do not add any information to the sentiment of a message as seen in the samples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "103a4a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68104                                                                                                                                                               model code conduct was revoked 2014\\nnow guided modi code conduct\n",
       "21202     2009 the environment ministry categorised 170000 hectares hasdeo arand ‚Äúnogo‚Äù area for mining for its rich unfragmented forest cover feb this year modi govt permitted coal mines there adani group will operate this mine \n",
       "5911                                 modi announced and implemented prudent allocation already done till 2014 upa didnt buy rafale because there was money this lakh crore more than indian defense budgetwhere will money come from \n",
       "111753         23rd may chowkidar ashok swine chowkidar salil chowkidar and their brethren will face cheer haran from indians bet they will not twitter for month after that\\ntheir only agenda hate modi and consequently hate india\n",
       "47989                                                                                                             only one humble request for 2019 general elections vote for any party nota but don‚Äô vote for this idiot modi that‚Äô \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows that contain numbers\n",
    "rows_with_numbers = df[df['clean_text'].str.contains(r'\\d')]\n",
    "rows_with_numbers['clean_text'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d403d",
   "metadata": {},
   "source": [
    "Hence we defined the `rem_numbers` as a function that replaces all numerical values as an empty string (`''`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d3a58576-8dd7-4043-a903-41b7cfab88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m rem_numbers(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m rem_numbers(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Removes numbers. This function simply replaces all numerical symbols to the empty string. Hence, for symbols enclosed by\u001b[39m\n",
      "\u001b[33m    whitespace, the whitespace are not collapsed to a single whitespace (for more information, see the examples).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the numerical symbol removed\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    rem_numbers(\" h3llo, k4must4 k4  n4?\")\u001b[39m\n",
      "\u001b[33m    ' hllo, kmust k  n?'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33mr\"\\d+\"\u001b[39m, \u001b[33m\"\"\u001b[39m, text)\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rem_numbers??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b1491-1821-42b1-a63f-dab941dc003f",
   "metadata": {},
   "source": [
    "### **Whitespace**\n",
    "We also noticed the prevalance of excess whitespaces in between words, as seen in the sample below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "da2c270a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79293                                                                                           fantastic speech hari  and perfect insight why need someone with caliber such our beloved and dynamic prime minister sri narendra modi once again \n",
       "142795                                                                                                                                                                                                             modis zumla dreams youngsters  \n",
       "27095                                                                                                                                                                         who says modi didnt create jobs see even vivek oberoi got the role  \n",
       "33385                                                                                                                                                   this nonsense bjp leaders will speak like this when modi slogan says sab sat sabka vikas  \n",
       "39615     micro this story every single inch  gurugram haryanagujrat dehli this major incidents communal violence state sponsored terrorism last weeks many others wake this todays india modis hindu india gandhis secular  ventilator right now \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows that contain 2 or more whitespaces in a row\n",
    "rows_with_whitespaces = df[df['clean_text'].str.contains(r'\\s{2,}')]\n",
    "rows_with_whitespaces['clean_text'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8144d29",
   "metadata": {},
   "source": [
    "Thus, function `collapse_whitespace` collapses all whitespace characters to a single space. Formally, it is a transducer \n",
    "\n",
    "$$\n",
    "\\Box^+ \\mapsto \\Box \\qquad \\text{where the space character is } \\Box\n",
    "$$\n",
    "\n",
    "Informally, it replaces all strings of whitespaces to a single whitespace character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3823f3bc-0a42-473a-8888-a4c06f0659ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m collapse_whitespace(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m collapse_whitespace(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    This collapses whitespace. Here, collapsing means the transduction of all whitespace strings of any\u001b[39m\n",
      "\u001b[33m    length to a whitespace string of unit length (e.g., \"   \" -> \" \"; formally \" \"+ -> \" \").\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the whitespaces collapsed.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    collapse_whitespace(\"  huh,  was.  that!!! \")\u001b[39m\n",
      "\u001b[33m    $ 'huh, was. that!!!'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33m\" +\"\u001b[39m, \u001b[33m\" \"\u001b[39m, text).strip()\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "collapse_whitespace??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd388a-e397-4100-a6df-a971db6f85df",
   "metadata": {},
   "source": [
    "To seamlessly call all these cleaning functions, we have the `clean` function that acts as a container that calls these separate components. The definition of this wrapper function is quite long, see [this appendix](#appendix:-clean-wrapper-function-definition) for its definition.\n",
    "\n",
    "We can now clean the dataset and store it in a new column names `clean_ours` (to differentiate it will the, still dirty, column `clean_text` from the dataset author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6d4ea4d2-e8fe-437f-a46f-a18b1b34f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  string\n",
      " 1   category    162969 non-null  int64 \n",
      " 2   clean_ours  162969 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 9.0 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"clean_ours\"] = df[\"clean_text\"].map(clean).astype('string')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf28ad",
   "metadata": {},
   "source": [
    "To confirm if the character cleaning worked, we can check for the differences between `clean_text` and `clean_ours` from the filtered rows below and compare the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "12724f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16510</th>\n",
       "      <td>pmofull speech narendra modi‚Äô lakhs security guards across the¬†country</td>\n",
       "      <td>0</td>\n",
       "      <td>pmofull speech narendra modi lakhs security guards across the country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41434</th>\n",
       "      <td>doubt messiah poor\\nworld bank says india longer poor people‚Äô country indians pulled out poverty every minute indias per capita income has also increased under modi govt</td>\n",
       "      <td>-1</td>\n",
       "      <td>doubt messiah poor\\nworld bank says india longer poor people country indians pulled out poverty every minute indias per capita income has also increased under modi govt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60921</th>\n",
       "      <td>opposition parties will have copy modi‚Äô permanent campaign trick sooner later theprint via</td>\n",
       "      <td>0</td>\n",
       "      <td>opposition parties will have copy modi permanent campaign trick sooner later theprint via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63017</th>\n",
       "      <td>next 2448 hours the opposition and their loyal gang intellectuals will start demanding the proof thats what modi wants everytime modi lays trap and these idiots walk into</td>\n",
       "      <td>-1</td>\n",
       "      <td>next hours the opposition and their loyal gang intellectuals will start demanding the proof thats what modi wants everytime modi lays trap and these idiots walk into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102834</th>\n",
       "      <td>that next time where you the theatrics wiping out sweat pidi journo looks more real</td>\n",
       "      <td>1</td>\n",
       "      <td>that next time where you the theatrics wiping out sweat pidi journo looks more real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34695</th>\n",
       "      <td>more taxes would needed realize the pappus offer\\ninflation would follow miserable future offered stupid along with his mad offer guaranteed income see better inflation rate modi\\n2010121 201187 201210 201394\\n201549 201645 201736 20183</td>\n",
       "      <td>-1</td>\n",
       "      <td>more taxes would needed realize the pappus offer\\ninflation would follow miserable future offered stupid along with his mad offer guaranteed income see better inflation rate modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59315</th>\n",
       "      <td>definitely today under modi‚Äô leadership india has become force reckoned with let‚Äô not surprised pappu will ask for the proof well from drdo</td>\n",
       "      <td>-1</td>\n",
       "      <td>definitely today under modi leadership india has become force reckoned with let not surprised pappu will ask for the proof well from drdo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110245</th>\n",
       "      <td>very true ramesh jarakiholi will give new angle this fight guess prabhakar kore and ramesh katthi won‚Äô have much say already many rss workers are ground spreading that whoever bjp candidate vote for modi</td>\n",
       "      <td>1</td>\n",
       "      <td>very true ramesh jarakiholi will give new angle this fight guess prabhakar kore and ramesh katthi won have much say already many rss workers are ground spreading that whoever bjp candidate vote for modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158692</th>\n",
       "      <td>china bring computer 50s india could have made 60s again 30yrs delay 2007 china got its anti missile sattelite modi made 04yrs but 7yrs cong gov mum</td>\n",
       "      <td>0</td>\n",
       "      <td>china bring computer s india could have made s again yrs delay china got its anti missile sattelite modi made yrs but yrs cong gov mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27952</th>\n",
       "      <td>didn‚Äô modi bhakats are weak maths they just jumping the gun</td>\n",
       "      <td>-1</td>\n",
       "      <td>didn modi bhakats are weak maths they just jumping the gun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          clean_text  \\\n",
       "16510                                                                                                                                                                        pmofull speech narendra modi‚Äô lakhs security guards across the¬†country    \n",
       "41434                                                                     doubt messiah poor\\nworld bank says india longer poor people‚Äô country indians pulled out poverty every minute indias per capita income has also increased under modi govt    \n",
       "60921                                                                                                                                                    opposition parties will have copy modi‚Äô permanent campaign trick sooner later theprint via    \n",
       "63017                                                                    next 2448 hours the opposition and their loyal gang intellectuals will start demanding the proof thats what modi wants everytime modi lays trap and these idiots walk into    \n",
       "102834                                                                                                                                                         that next time where you the theatrics wiping out sweat pidi journo looks more real     \n",
       "34695   more taxes would needed realize the pappus offer\\ninflation would follow miserable future offered stupid along with his mad offer guaranteed income see better inflation rate modi\\n2010121 201187 201210 201394\\n201549 201645 201736 20183   \n",
       "59315                                                                                                    definitely today under modi‚Äô leadership india has become force reckoned with let‚Äô not surprised pappu will ask for the proof well from drdo   \n",
       "110245                                   very true ramesh jarakiholi will give new angle this fight guess prabhakar kore and ramesh katthi won‚Äô have much say already many rss workers are ground spreading that whoever bjp candidate vote for modi   \n",
       "158692                                                                                         china bring computer 50s india could have made 60s again 30yrs delay 2007 china got its anti missile sattelite modi made 04yrs but 7yrs cong gov mum    \n",
       "27952                                                                                                                                                                                    didn‚Äô modi bhakats are weak maths they just jumping the gun   \n",
       "\n",
       "        category  \\\n",
       "16510          0   \n",
       "41434         -1   \n",
       "60921          0   \n",
       "63017         -1   \n",
       "102834         1   \n",
       "34695         -1   \n",
       "59315         -1   \n",
       "110245         1   \n",
       "158692         0   \n",
       "27952         -1   \n",
       "\n",
       "                                                                                                                                                                                                        clean_ours  \n",
       "16510                                                                                                                                        pmofull speech narendra modi lakhs security guards across the country  \n",
       "41434                                     doubt messiah poor\\nworld bank says india longer poor people country indians pulled out poverty every minute indias per capita income has also increased under modi govt  \n",
       "60921                                                                                                                    opposition parties will have copy modi permanent campaign trick sooner later theprint via  \n",
       "63017                                        next hours the opposition and their loyal gang intellectuals will start demanding the proof thats what modi wants everytime modi lays trap and these idiots walk into  \n",
       "102834                                                                                                                         that next time where you the theatrics wiping out sweat pidi journo looks more real  \n",
       "34695                           more taxes would needed realize the pappus offer\\ninflation would follow miserable future offered stupid along with his mad offer guaranteed income see better inflation rate modi  \n",
       "59315                                                                    definitely today under modi leadership india has become force reckoned with let not surprised pappu will ask for the proof well from drdo  \n",
       "110245  very true ramesh jarakiholi will give new angle this fight guess prabhakar kore and ramesh katthi won have much say already many rss workers are ground spreading that whoever bjp candidate vote for modi  \n",
       "158692                                                                      china bring computer s india could have made s again yrs delay china got its anti missile sattelite modi made yrs but yrs cong gov mum  \n",
       "27952                                                                                                                                                   didn modi bhakats are weak maths they just jumping the gun  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "example_rows = df[df['clean_text'].str.contains(r'\\s{2,}|\\d|[^\\w\\s]|[\\u263a-\\U0001f645]|[√â√©√Å√°√≥√ì√∫√ö√≠√ç]')]\n",
    "example_rows.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110683a-3879-452e-9d2f-50c4af4e0ad6",
   "metadata": {},
   "source": [
    "### **Spam, Expressions, Onomatopoeia, etc.**\n",
    "\n",
    "Since the domain of the corpus is Twitter, spam (e.g., `bbbb`), expressions (e.g., `bruhhhh`), and onomatopoeia (e.g., `hahahaha`) may become an issue by the vector representation step. Hence we employed a simple rule-based spam removal algorithm.\n",
    "\n",
    "We remove words in the string that contains the same letter or substring thrice and consecutively. These were done using regular expressions:\n",
    "\n",
    "$$\n",
    "\\text{same\\_char\\_thrice} := (.)\\textbackslash1^{\\{2,\\}}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\text{same\\_substring\\_twice} := (.^+)\\textbackslash1^+\n",
    "$$\n",
    "\n",
    "Furthermore, we also remove any string that has a length less than three, since these are either stopwords (that weren't detected in the stopword removal stage) or more spam. \n",
    "\n",
    "Finally, we employ adaptive character diversity threshold for the string $s$. \n",
    "\n",
    "$$\n",
    "\\frac{\\texttt{\\#\\_unique\\_chars}(s)}{|s|} < 0.3 + \\left(\\frac{0.1 \\cdot \\text{min}(|s|, 10)}{10}\\right)\n",
    "$$\n",
    "\n",
    "It calculates the diversity of characters in a string; if the string repeats the same character alot, we expect it to be unintelligible or useless, hence we remove it.\n",
    "\n",
    "The definition of this wrapper function is quite long, see its definition in [this appendix](#appendix:-find_spam_and_empty-wrapper-function-definition).\n",
    "\n",
    "Let's first look at a random sample of 10 entries in the dataset before the cleaning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9015aea8-b6f6-4408-b027-f9c79cf7d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71301</th>\n",
       "      <td>first reply why did not tested then modi will tell why did</td>\n",
       "      <td>1</td>\n",
       "      <td>first reply why did not tested then modi will tell why did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117536</th>\n",
       "      <td>modi spoke all the oppos seen with their tales btwn the legs</td>\n",
       "      <td>0</td>\n",
       "      <td>modi spoke all the oppos seen with their tales btwn the legs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126262</th>\n",
       "      <td>you dont have any sorrow over farmers suicide then vote for modi you want the dead body soldiers used for political gain then definitely vote for modi</td>\n",
       "      <td>-1</td>\n",
       "      <td>you dont have any sorrow over farmers suicide then vote for modi you want the dead body soldiers used for political gain then definitely vote for modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60908</th>\n",
       "      <td>jab tak bhaiya president hain inc modi rehenge happy theaters day</td>\n",
       "      <td>1</td>\n",
       "      <td>jab tak bhaiya president hain inc modi rehenge happy theaters day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78292</th>\n",
       "      <td>modis ayushman bharat success coz congress kept millions below poverty line over decades</td>\n",
       "      <td>1</td>\n",
       "      <td>modis ayushman bharat success coz congress kept millions below poverty line over decades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49865</th>\n",
       "      <td>lying concealing factsinfodata are part his via</td>\n",
       "      <td>0</td>\n",
       "      <td>lying concealing factsinfodata are part his via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122273</th>\n",
       "      <td>modi the can‚Äô protect defence files his own office modi feeds peoples life‚Äô due dogs due his flawed policies calls himself chowkidhars</td>\n",
       "      <td>-1</td>\n",
       "      <td>modi the can protect defence files his own office modi feeds peoples life due dogs due his flawed policies calls himself chowkidhars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103927</th>\n",
       "      <td>hmmmdoing everything against modi his supporters</td>\n",
       "      <td>0</td>\n",
       "      <td>hmmmdoing everything against modi his supporters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63519</th>\n",
       "      <td>not only does this tweet officially pellucids paid media and the state journalism today but also shows the surpassing rise fascism india today stating that even after much ruination and despotism mrmodi fears neither the opposition nor the public</td>\n",
       "      <td>1</td>\n",
       "      <td>not only does this tweet officially pellucids paid media and the state journalism today but also shows the surpassing rise fascism india today stating that even after much ruination and despotism mrmodi fears neither the opposition nor the public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47181</th>\n",
       "      <td>mission shakti\\nthanks drdo isro and modi proud you all india now space superpower</td>\n",
       "      <td>1</td>\n",
       "      <td>mission shakti\\nthanks drdo isro and modi proud you all india now space superpower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                     clean_text  \\\n",
       "71301                                                                                                                                                                                                first reply why did not tested then modi will tell why did   \n",
       "117536                                                                                                                                                                                             modi spoke all the oppos seen with their tales btwn the legs   \n",
       "126262                                                                                                  you dont have any sorrow over farmers suicide then vote for modi you want the dead body soldiers used for political gain then definitely vote for modi    \n",
       "60908                                                                                                                                                                                         jab tak bhaiya president hain inc modi rehenge happy theaters day   \n",
       "78292                                                                                                                                                                 modis ayushman bharat success coz congress kept millions below poverty line over decades    \n",
       "49865                                                                                                                                                                                                          lying concealing factsinfodata are part his via    \n",
       "122273                                                                                                                   modi the can‚Äô protect defence files his own office modi feeds peoples life‚Äô due dogs due his flawed policies calls himself chowkidhars   \n",
       "103927                                                                                                                                                                                                         hmmmdoing everything against modi his supporters   \n",
       "63519   not only does this tweet officially pellucids paid media and the state journalism today but also shows the surpassing rise fascism india today stating that even after much ruination and despotism mrmodi fears neither the opposition nor the public    \n",
       "47181                                                                                                                                                                        mission shakti\\nthanks drdo isro and modi proud you all india now space superpower   \n",
       "\n",
       "        category  \\\n",
       "71301          1   \n",
       "117536         0   \n",
       "126262        -1   \n",
       "60908          1   \n",
       "78292          1   \n",
       "49865          0   \n",
       "122273        -1   \n",
       "103927         0   \n",
       "63519          1   \n",
       "47181          1   \n",
       "\n",
       "                                                                                                                                                                                                                                                    clean_ours  \n",
       "71301                                                                                                                                                                                               first reply why did not tested then modi will tell why did  \n",
       "117536                                                                                                                                                                                            modi spoke all the oppos seen with their tales btwn the legs  \n",
       "126262                                                                                                  you dont have any sorrow over farmers suicide then vote for modi you want the dead body soldiers used for political gain then definitely vote for modi  \n",
       "60908                                                                                                                                                                                        jab tak bhaiya president hain inc modi rehenge happy theaters day  \n",
       "78292                                                                                                                                                                 modis ayushman bharat success coz congress kept millions below poverty line over decades  \n",
       "49865                                                                                                                                                                                                          lying concealing factsinfodata are part his via  \n",
       "122273                                                                                                                    modi the can protect defence files his own office modi feeds peoples life due dogs due his flawed policies calls himself chowkidhars  \n",
       "103927                                                                                                                                                                                                        hmmmdoing everything against modi his supporters  \n",
       "63519   not only does this tweet officially pellucids paid media and the state journalism today but also shows the surpassing rise fascism india today stating that even after much ruination and despotism mrmodi fears neither the opposition nor the public  \n",
       "47181                                                                                                                                                                       mission shakti\\nthanks drdo isro and modi proud you all india now space superpower  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e75f3f-6619-47b8-9b73-5d3d9fa38fbc",
   "metadata": {},
   "source": [
    "Let's now call this function on the `clean_ours` column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7ac69746-f471-4a66-9292-c2b363d12de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  string\n",
      " 1   category    162969 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 9.0 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"clean_ours\"] = df[\"clean_ours\"].map(find_spam_and_empty).astype('string')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "16f66f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[0, 'clean_ours'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e183f-9359-4a84-b212-0cb3d09fc0ed",
   "metadata": {},
   "source": [
    "And look at another random sample of 10 entries in the dataset after the cleaning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f55e97e4-bbda-41ad-9438-3547b0f0e973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50519</th>\n",
       "      <td>see what manish tiwari saying this the reason why narendra modi needed</td>\n",
       "      <td>0</td>\n",
       "      <td>see what manish tiwari saying this the reason why narendra modi needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>only modi matters</td>\n",
       "      <td>0</td>\n",
       "      <td>only modi matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65540</th>\n",
       "      <td>low show for lowly subhumans pakistan showed how much fear modi 272</td>\n",
       "      <td>1</td>\n",
       "      <td>low show for lowly subhumans pakistan showed how much fear modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63804</th>\n",
       "      <td>opinion modis ‚Äúgrand disclosure‚Äù extension the nationalist card being vigorously pushed the bjp after the and the balakot air strikes writes</td>\n",
       "      <td>1</td>\n",
       "      <td>opinion modis grand disclosure extension the nationalist card being vigorously pushed the bjp after the and the balakot air strikes writes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112699</th>\n",
       "      <td>another jumla exposed modi worst indias history</td>\n",
       "      <td>-1</td>\n",
       "      <td>another jumla exposed modi worst indias history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69845</th>\n",
       "      <td>drdo chief upa govt didnt give the nod ahead but now modi had the will power dont understand why congress trying hard push our country back every front</td>\n",
       "      <td>-1</td>\n",
       "      <td>drdo chief upa govt didnt give the nod ahead but now modi had the will power dont understand why congress trying hard push our country back every front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76199</th>\n",
       "      <td>two strong reasons for not voting for congress forces were prohibited from avenging 2611 attack\\n2isro was not allowed conduct mission shakti test</td>\n",
       "      <td>1</td>\n",
       "      <td>two strong reasons for not voting for congress forces were prohibited from avenging attack isro was not allowed conduct mission shakti test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69060</th>\n",
       "      <td>today proud indian have great leader who leading today who kept national interest first proud our narendra modi and our great sciencetists</td>\n",
       "      <td>1</td>\n",
       "      <td>today proud indian have great leader who leading today who kept national interest first proud our narendra modi and our great sciencetists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120390</th>\n",
       "      <td>will send you doggy bag tomorrow\\nnice one because nirav modi has dog wanted nirav set free\\nwof wof nice try\\nwhat next</td>\n",
       "      <td>1</td>\n",
       "      <td>will send you doggy bag tomorrow nice one because nirav modi has dog wanted nirav set free wof wof nice try what next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147651</th>\n",
       "      <td>72k won‚Äô spent ipl tickets pop corn emi but essential goods should only boost the profits those companies who cater them overall they will have chance rise become consumers like you unlike modi‚Äô election strategy that drove many ruin</td>\n",
       "      <td>1</td>\n",
       "      <td>won spent ipl tickets pop corn emi but essential goods should only boost the profits those companies who cater them overall they will have chance rise become consumers like you unlike modi election strategy that drove many ruin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                       clean_text  \\\n",
       "50519                                                                                                                                                                     see what manish tiwari saying this the reason why narendra modi needed    \n",
       "1458                                                                                                                                                                                                                            only modi matters   \n",
       "65540                                                                                                                                                                        low show for lowly subhumans pakistan showed how much fear modi 272    \n",
       "63804                                                                                               opinion modis ‚Äúgrand disclosure‚Äù extension the nationalist card being vigorously pushed the bjp after the and the balakot air strikes writes    \n",
       "112699                                                                                                                                                                                           another jumla exposed modi worst indias history    \n",
       "69845                                                                                     drdo chief upa govt didnt give the nod ahead but now modi had the will power dont understand why congress trying hard push our country back every front   \n",
       "76199                                                                                         two strong reasons for not voting for congress forces were prohibited from avenging 2611 attack\\n2isro was not allowed conduct mission shakti test    \n",
       "69060                                                                                                  today proud indian have great leader who leading today who kept national interest first proud our narendra modi and our great sciencetists   \n",
       "120390                                                                                                                   will send you doggy bag tomorrow\\nnice one because nirav modi has dog wanted nirav set free\\nwof wof nice try\\nwhat next   \n",
       "147651  72k won‚Äô spent ipl tickets pop corn emi but essential goods should only boost the profits those companies who cater them overall they will have chance rise become consumers like you unlike modi‚Äô election strategy that drove many ruin   \n",
       "\n",
       "        category  \\\n",
       "50519          0   \n",
       "1458           0   \n",
       "65540          1   \n",
       "63804          1   \n",
       "112699        -1   \n",
       "69845         -1   \n",
       "76199          1   \n",
       "69060          1   \n",
       "120390         1   \n",
       "147651         1   \n",
       "\n",
       "                                                                                                                                                                                                                                 clean_ours  \n",
       "50519                                                                                                                                                                see what manish tiwari saying this the reason why narendra modi needed  \n",
       "1458                                                                                                                                                                                                                      only modi matters  \n",
       "65540                                                                                                                                                                       low show for lowly subhumans pakistan showed how much fear modi  \n",
       "63804                                                                                            opinion modis grand disclosure extension the nationalist card being vigorously pushed the bjp after the and the balakot air strikes writes  \n",
       "112699                                                                                                                                                                                      another jumla exposed modi worst indias history  \n",
       "69845                                                                               drdo chief upa govt didnt give the nod ahead but now modi had the will power dont understand why congress trying hard push our country back every front  \n",
       "76199                                                                                           two strong reasons for not voting for congress forces were prohibited from avenging attack isro was not allowed conduct mission shakti test  \n",
       "69060                                                                                            today proud indian have great leader who leading today who kept national interest first proud our narendra modi and our great sciencetists  \n",
       "120390                                                                                                                will send you doggy bag tomorrow nice one because nirav modi has dog wanted nirav set free wof wof nice try what next  \n",
       "147651  won spent ipl tickets pop corn emi but essential goods should only boost the profits those companies who cater them overall they will have chance rise become consumers like you unlike modi election strategy that drove many ruin  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3dbd4-474c-4d76-9afe-198c4c53c063",
   "metadata": {},
   "source": [
    "## **Post-Cleaning Steps**\n",
    "\n",
    "At some point during the cleaning stage, some entries of the dataset could have been reduced to `NaN` or the empty string `\"\"`, or we could have introduced duplicates again. So, let's call `dropna` and `drop_duplicates` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f365bcfa-e44b-46a1-9702-ad36cfcf7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "bdd5c44f-32ab-4b34-b7e4-121c2a898c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb4d20",
   "metadata": {},
   "source": [
    "# **3. Preprocessing**\n",
    "\n",
    "> üèóÔ∏è Perhaps swap S3 and S4. Refer to literature on what comes first.\n",
    "\n",
    "This section discusses preprocessing steps for the cleaned data. Because the goal is to analyze the textual sentiments of tweets the following preprocessing steps are needed to provide the Bag of Words model with the relevant information required to get the semantic embeddings of each tweet.\n",
    "\n",
    "Before and after each preprocessing step, we will show 5 random entries in the dataset to show the effects of each preprocessing task.\n",
    "\n",
    "## **Lemmatization**\n",
    "\n",
    "We follow a similar methodology for data cleaning presented in <u>(George & Murugesan, 2024)</u>. We preprocess the dataset entries via lemmatization. We use NLTK for this task using WordNetLemmatizer lemmatization, repectively <u>(Bird & Loper, 2004)</u>. For the lemmatization step, we use the WordNet for English lemmatization and Open Multilingual WordNet version 1.4 for translations and multilingual support which is important for our case since some tweets contain text from Indian Languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a0c3a9b5-b35a-47ca-9ecf-7f950db07395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99797</th>\n",
       "      <td>the people india dont want towards instability prime minister narendra modi</td>\n",
       "      <td>0</td>\n",
       "      <td>the people india dont want towards instability prime minister narendra modi</td>\n",
       "      <td>the people india dont want towards instability prime minister narendra modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154363</th>\n",
       "      <td>modi went for two seats could have left gujarat argument was that vikas gujarat running awayhe went varanasi argument was that one knows him outside gujarat had prove his pan india image and counter baseless argument congress</td>\n",
       "      <td>0</td>\n",
       "      <td>modi went for two seats could have left gujarat argument was that vikas gujarat running awayhe went varanasi argument was that one knows him outside gujarat had prove his pan india image and counter baseless argument congress</td>\n",
       "      <td>modi went for two seat could have left gujarat argument wa that vikas gujarat running awayhe went varanasi argument wa that one know him outside gujarat had prove his pan india image and counter baseless argument congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84525</th>\n",
       "      <td>nehru was launching anti satellite missile 1959 for which modi taking credit</td>\n",
       "      <td>0</td>\n",
       "      <td>nehru was launching anti satellite missile for which modi taking credit</td>\n",
       "      <td>nehru wa launching anti satellite missile for which modi taking credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17430</th>\n",
       "      <td>modi way making job creation 2014 sale chai and proud chaiwallah 2017 sale pakodas and proud business man 2019 became chowkidar front richman home 2019 sale tshirts proud bhakth</td>\n",
       "      <td>1</td>\n",
       "      <td>modi way making job creation sale chai and proud chaiwallah sale pakodas and proud business man became chowkidar front richman home sale tshirts proud bhakth</td>\n",
       "      <td>modi way making job creation sale chai and proud chaiwallah sale pakodas and proud business man became chowkidar front richman home sale tshirts proud bhakth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82287</th>\n",
       "      <td>right\\nthe least educated modis bravados now unsold</td>\n",
       "      <td>-1</td>\n",
       "      <td>right the least educated modis bravados now unsold</td>\n",
       "      <td>right the least educated modis bravado now unsold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44536</th>\n",
       "      <td>modi did itt</td>\n",
       "      <td>0</td>\n",
       "      <td>modi did itt</td>\n",
       "      <td>modi did itt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152977</th>\n",
       "      <td>this what call sensible criticism possible only bcoz rahul‚Äô idea had been modi‚Äô there would have been discussion bcoz fear</td>\n",
       "      <td>0</td>\n",
       "      <td>this what call sensible criticism possible only bcoz rahul idea had been modi there would have been discussion bcoz fear</td>\n",
       "      <td>this what call sensible criticism possible only bcoz rahul idea had been modi there would have been discussion bcoz fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148410</th>\n",
       "      <td>another difference modi chose state where bjp was not projected weak made stronger rahul chose state where his party projected win seats benefits from partys strength like parasite</td>\n",
       "      <td>1</td>\n",
       "      <td>another difference modi chose state where bjp was not projected weak made stronger rahul chose state where his party projected win seats benefits from partys strength like parasite</td>\n",
       "      <td>another difference modi chose state where bjp wa not projected weak made stronger rahul chose state where his party projected win seat benefit from party strength like parasite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12564</th>\n",
       "      <td>you guys give time then can hamara modi sal hoya aaj bhe pakistan pakistan aur nahru par ilzam lagata hai give him some time bhai</td>\n",
       "      <td>0</td>\n",
       "      <td>you guys give time then can hamara modi sal hoya bhe pakistan pakistan aur nahru par ilzam lagata hai give him some time bhai</td>\n",
       "      <td>you guy give time then can hamara modi sal hoya bhe pakistan pakistan aur nahru par ilzam lagata hai give him some time bhai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106793</th>\n",
       "      <td>most idiotic question from criminal modis steps polling arent connected all pakistani stooges like must hanged even after youre dead</td>\n",
       "      <td>-1</td>\n",
       "      <td>most idiotic question from criminal modis steps polling arent connected all pakistani stooges like must hanged even after youre dead</td>\n",
       "      <td>most idiotic question from criminal modis step polling arent connected all pakistani stooge like must hanged even after youre dead</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                               clean_text  \\\n",
       "99797                                                                                                                                                        the people india dont want towards instability prime minister narendra modi    \n",
       "154363  modi went for two seats could have left gujarat argument was that vikas gujarat running awayhe went varanasi argument was that one knows him outside gujarat had prove his pan india image and counter baseless argument congress   \n",
       "84525                                                                                                                                                       nehru was launching anti satellite missile 1959 for which modi taking credit    \n",
       "17430                                                   modi way making job creation 2014 sale chai and proud chaiwallah 2017 sale pakodas and proud business man 2019 became chowkidar front richman home 2019 sale tshirts proud bhakth   \n",
       "82287                                                                                                                                                                                 right\\nthe least educated modis bravados now unsold   \n",
       "44536                                                                                                                                                                                                                       modi did itt    \n",
       "152977                                                                                                         this what call sensible criticism possible only bcoz rahul‚Äô idea had been modi‚Äô there would have been discussion bcoz fear   \n",
       "148410                                               another difference modi chose state where bjp was not projected weak made stronger rahul chose state where his party projected win seats benefits from partys strength like parasite   \n",
       "12564                                                                                                   you guys give time then can hamara modi sal hoya aaj bhe pakistan pakistan aur nahru par ilzam lagata hai give him some time bhai   \n",
       "106793                                                                                               most idiotic question from criminal modis steps polling arent connected all pakistani stooges like must hanged even after youre dead   \n",
       "\n",
       "        category  \\\n",
       "99797          0   \n",
       "154363         0   \n",
       "84525          0   \n",
       "17430          1   \n",
       "82287         -1   \n",
       "44536          0   \n",
       "152977         0   \n",
       "148410         1   \n",
       "12564          0   \n",
       "106793        -1   \n",
       "\n",
       "                                                                                                                                                                                                                               clean_ours  \\\n",
       "99797                                                                                                                                                         the people india dont want towards instability prime minister narendra modi   \n",
       "154363  modi went for two seats could have left gujarat argument was that vikas gujarat running awayhe went varanasi argument was that one knows him outside gujarat had prove his pan india image and counter baseless argument congress   \n",
       "84525                                                                                                                                                             nehru was launching anti satellite missile for which modi taking credit   \n",
       "17430                                                                       modi way making job creation sale chai and proud chaiwallah sale pakodas and proud business man became chowkidar front richman home sale tshirts proud bhakth   \n",
       "82287                                                                                                                                                                                  right the least educated modis bravados now unsold   \n",
       "44536                                                                                                                                                                                                                        modi did itt   \n",
       "152977                                                                                                           this what call sensible criticism possible only bcoz rahul idea had been modi there would have been discussion bcoz fear   \n",
       "148410                                               another difference modi chose state where bjp was not projected weak made stronger rahul chose state where his party projected win seats benefits from partys strength like parasite   \n",
       "12564                                                                                                       you guys give time then can hamara modi sal hoya bhe pakistan pakistan aur nahru par ilzam lagata hai give him some time bhai   \n",
       "106793                                                                                               most idiotic question from criminal modis steps polling arent connected all pakistani stooges like must hanged even after youre dead   \n",
       "\n",
       "                                                                                                                                                                                                                           lemmatized  \n",
       "99797                                                                                                                                                     the people india dont want towards instability prime minister narendra modi  \n",
       "154363  modi went for two seat could have left gujarat argument wa that vikas gujarat running awayhe went varanasi argument wa that one know him outside gujarat had prove his pan india image and counter baseless argument congress  \n",
       "84525                                                                                                                                                          nehru wa launching anti satellite missile for which modi taking credit  \n",
       "17430                                                                   modi way making job creation sale chai and proud chaiwallah sale pakodas and proud business man became chowkidar front richman home sale tshirts proud bhakth  \n",
       "82287                                                                                                                                                                               right the least educated modis bravado now unsold  \n",
       "44536                                                                                                                                                                                                                    modi did itt  \n",
       "152977                                                                                                       this what call sensible criticism possible only bcoz rahul idea had been modi there would have been discussion bcoz fear  \n",
       "148410                                               another difference modi chose state where bjp wa not projected weak made stronger rahul chose state where his party projected win seat benefit from party strength like parasite  \n",
       "12564                                                                                                    you guy give time then can hamara modi sal hoya bhe pakistan pakistan aur nahru par ilzam lagata hai give him some time bhai  \n",
       "106793                                                                                             most idiotic question from criminal modis step polling arent connected all pakistani stooge like must hanged even after youre dead  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized\"] = df[\"clean_ours\"].map(lemmatizer)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42589219-d005-4ab3-b825-cccb7fa6d663",
   "metadata": {},
   "source": [
    "## **Stop Word Removal**\n",
    "\n",
    "After lemmatization, we may now remove the stop words present in the dataset. The stopword removal _needs_ to be after lemmatization since this step requires all words to be reduces to their base dictionary form, and the `stopword_set` only considers base dictionary forms of the stopwords.\n",
    "\n",
    "**stopwords.** For stop words removal, we refer to the English stopwords dataset defined in NLTK and Wolfram Mathematica <u>(Bird & Loper, 2004; Wolfram Research, 2015)</u>. However, since the task is sentiment analysis, words that invoke polarity, intensification, and negation are important. Words like \"not\" and \"okay\" are commonly included as stopwords. Therefore, the stopwords from [nltk,mathematica] are manually adjusted to only include stopwords that invoke neutrality, examples are \"after\", \"when\", and \"you.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4a91231f-c21d-41da-9296-7b8607f9cd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148169</th>\n",
       "      <td>bjp party poor says modi meanwhile bjp assets increased 627 last amit shah assets jumped times yrs gadkari income increased 141 yrs other news\\nbsnl verge bankruptcy\\nbank npa has been highest\\nyouths have job</td>\n",
       "      <td>-1</td>\n",
       "      <td>bjp party poor says modi meanwhile bjp assets increased last amit shah assets jumped times yrs gadkari income increased yrs other news bsnl verge bankruptcy bank npa has been highest youths have job</td>\n",
       "      <td>bjp party poor modi bjp asset increased amit shah asset jumped time gadkari income increased news bsnl verge bankruptcy bank npa ha highest youth job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27628</th>\n",
       "      <td>not supported modiproud anti indian</td>\n",
       "      <td>0</td>\n",
       "      <td>not supported modiproud anti indian</td>\n",
       "      <td>supported modiproud anti indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98798</th>\n",
       "      <td>shameless communal who has ganged with and who meet these creeps every evening chalk out narrative favouring pak and design anti modi caimpaign their hate for man they shame india 24x7 kick ass</td>\n",
       "      <td>-1</td>\n",
       "      <td>shameless communal who has ganged with and who meet these creeps every evening chalk out narrative favouring pak and design anti modi caimpaign their hate for man they shame india kick ass</td>\n",
       "      <td>shameless communal ha ganged meet creep evening chalk narrative favouring pak design anti modi caimpaign hate man shame india kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120226</th>\n",
       "      <td>would expect more balanced argument from welleducated man like you this article criticizes but gives clean chit clean starts from home</td>\n",
       "      <td>1</td>\n",
       "      <td>would expect more balanced argument from welleducated man like you this article criticizes but gives clean chit clean starts from home</td>\n",
       "      <td>expect more balanced argument welleducated man like article criticizes clean chit clean start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46914</th>\n",
       "      <td>love kaftan anytime any day</td>\n",
       "      <td>1</td>\n",
       "      <td>love kaftan anytime any day</td>\n",
       "      <td>love kaftan anytime day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130127</th>\n",
       "      <td>when indian population turn 600crores modi will definitely bring back black money with the help baba ramdev</td>\n",
       "      <td>-1</td>\n",
       "      <td>when indian population turn crores modi will definitely bring back black money with the help ramdev</td>\n",
       "      <td>indian population turn crore modi definitely bring back black money help ramdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95825</th>\n",
       "      <td>modi was the 1969</td>\n",
       "      <td>0</td>\n",
       "      <td>modi was the</td>\n",
       "      <td>modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110417</th>\n",
       "      <td>absolutely but this weird behaviour modi would enable trumpus understand that country can all weather friend except pakistan</td>\n",
       "      <td>-1</td>\n",
       "      <td>absolutely but this weird behaviour modi would enable trumpus understand that country can all weather friend except pakistan</td>\n",
       "      <td>absolutely weird behaviour modi enable trumpus understand country all weather friend pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120234</th>\n",
       "      <td>not fan hater modi rahul big fan india \\nbest use that money was for the poor people india for public welfare schemes\\ndont you all think that this could the best use tax payers money</td>\n",
       "      <td>1</td>\n",
       "      <td>not fan hater modi rahul big fan india best use that money was for the poor people india for public welfare schemes dont you all think that this could the best use tax payers money</td>\n",
       "      <td>fan hater modi rahul big fan india best money poor people india public welfare scheme all best tax payer money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117918</th>\n",
       "      <td>you vote modi you are with india you are not with modi you are anti india the above shit bjp candidate from bangalore dear not with modi with indian people not anti india sanjeev bard</td>\n",
       "      <td>-1</td>\n",
       "      <td>you vote modi you are with india you are not with modi you are anti india the above shit bjp candidate from bangalore dear not with modi with indian people not anti india sanjeev bard</td>\n",
       "      <td>vote modi india modi anti india above shit bjp candidate bangalore dear modi indian people anti india sanjeev bard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                clean_text  \\\n",
       "148169  bjp party poor says modi meanwhile bjp assets increased 627 last amit shah assets jumped times yrs gadkari income increased 141 yrs other news\\nbsnl verge bankruptcy\\nbank npa has been highest\\nyouths have job    \n",
       "27628                                                                                                                                                                                 not supported modiproud anti indian    \n",
       "98798                   shameless communal who has ganged with and who meet these creeps every evening chalk out narrative favouring pak and design anti modi caimpaign their hate for man they shame india 24x7 kick ass    \n",
       "120226                                                                             would expect more balanced argument from welleducated man like you this article criticizes but gives clean chit clean starts from home    \n",
       "46914                                                                                                                                                                                         love kaftan anytime any day    \n",
       "130127                                                                                                         when indian population turn 600crores modi will definitely bring back black money with the help baba ramdev   \n",
       "95825                                                                                                                                                                                                    modi was the 1969   \n",
       "110417                                                                                        absolutely but this weird behaviour modi would enable trumpus understand that country can all weather friend except pakistan   \n",
       "120234                            not fan hater modi rahul big fan india \\nbest use that money was for the poor people india for public welfare schemes\\ndont you all think that this could the best use tax payers money    \n",
       "117918                            you vote modi you are with india you are not with modi you are anti india the above shit bjp candidate from bangalore dear not with modi with indian people not anti india sanjeev bard    \n",
       "\n",
       "        category  \\\n",
       "148169        -1   \n",
       "27628          0   \n",
       "98798         -1   \n",
       "120226         1   \n",
       "46914          1   \n",
       "130127        -1   \n",
       "95825          0   \n",
       "110417        -1   \n",
       "120234         1   \n",
       "117918        -1   \n",
       "\n",
       "                                                                                                                                                                                                    clean_ours  \\\n",
       "148169  bjp party poor says modi meanwhile bjp assets increased last amit shah assets jumped times yrs gadkari income increased yrs other news bsnl verge bankruptcy bank npa has been highest youths have job   \n",
       "27628                                                                                                                                                                      not supported modiproud anti indian   \n",
       "98798             shameless communal who has ganged with and who meet these creeps every evening chalk out narrative favouring pak and design anti modi caimpaign their hate for man they shame india kick ass   \n",
       "120226                                                                  would expect more balanced argument from welleducated man like you this article criticizes but gives clean chit clean starts from home   \n",
       "46914                                                                                                                                                                              love kaftan anytime any day   \n",
       "130127                                                                                                     when indian population turn crores modi will definitely bring back black money with the help ramdev   \n",
       "95825                                                                                                                                                                                             modi was the   \n",
       "110417                                                                            absolutely but this weird behaviour modi would enable trumpus understand that country can all weather friend except pakistan   \n",
       "120234                    not fan hater modi rahul big fan india best use that money was for the poor people india for public welfare schemes dont you all think that this could the best use tax payers money   \n",
       "117918                 you vote modi you are with india you are not with modi you are anti india the above shit bjp candidate from bangalore dear not with modi with indian people not anti india sanjeev bard   \n",
       "\n",
       "                                                                                                                                                   lemmatized  \n",
       "148169  bjp party poor modi bjp asset increased amit shah asset jumped time gadkari income increased news bsnl verge bankruptcy bank npa ha highest youth job  \n",
       "27628                                                                                                                         supported modiproud anti indian  \n",
       "98798                      shameless communal ha ganged meet creep evening chalk narrative favouring pak design anti modi caimpaign hate man shame india kick  \n",
       "120226                                                          expect more balanced argument welleducated man like article criticizes clean chit clean start  \n",
       "46914                                                                                                                                 love kaftan anytime day  \n",
       "130127                                                                        indian population turn crore modi definitely bring back black money help ramdev  \n",
       "95825                                                                                                                                                    modi  \n",
       "110417                                                          absolutely weird behaviour modi enable trumpus understand country all weather friend pakistan  \n",
       "120234                                         fan hater modi rahul big fan india best money poor people india public welfare scheme all best tax payer money  \n",
       "117918                                     vote modi india modi anti india above shit bjp candidate bangalore dear modi indian people anti india sanjeev bard  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized\"] = df[\"lemmatized\"].map(lambda t: rem_stopwords(t, stopwords_set))\n",
    "df = df.dropna(subset=[\"lemmatized\"])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd19e4-020a-4e3d-9d0f-6187ce4102d0",
   "metadata": {},
   "source": [
    "## **Looking at the DataFrame**\n",
    "\n",
    "After preprocessing, the dataset now contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "883b7f78-ba3d-4bad-9969-0a09b067e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      " 3   lemmatized  162942 non-null  object\n",
      "dtypes: int64(1), object(1), string(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54e5b1-3b81-477e-96ee-602c33533a41",
   "metadata": {},
   "source": [
    "Here are 10 randomly picked entries in the dataframe with all columns shown for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "54e069ce-83c3-4769-8914-b442625a6032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16111</th>\n",
       "      <td>two penny hate monger modi and netanyahu lover etc etc etc and not peaceful any way all</td>\n",
       "      <td>-1</td>\n",
       "      <td>two penny hate monger modi and netanyahu lover etc etc etc and not peaceful any way all</td>\n",
       "      <td>penny hate monger modi netanyahu lover peaceful all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>western buyers who were shifting india from china because price rise there went pakistan bangladesh sri lanka vietnam etc because they have better price they are clocking big time thanks modi</td>\n",
       "      <td>1</td>\n",
       "      <td>western buyers who were shifting india from china because price rise there went pakistan bangladesh sri lanka vietnam etc because they have better price they are clocking big time thanks modi</td>\n",
       "      <td>western buyer shifting india china price rise pakistan bangladesh sri lanka vietnam better price clocking big time modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139905</th>\n",
       "      <td>want watch debate between kanhaiya kumar the great orator narendra modi  plz arrange debate</td>\n",
       "      <td>1</td>\n",
       "      <td>want watch debate between kanhaiya kumar the great orator narendra modi plz arrange debate</td>\n",
       "      <td>watch debate kanhaiya kumar great orator narendra modi plz arrange debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83968</th>\n",
       "      <td>narendra modi says meerut ‚Äòthe rld and bsp together make sharab alcohol this alcohol will ruin you‚Äô</td>\n",
       "      <td>0</td>\n",
       "      <td>narendra modi says meerut the rld and bsp together make sharab alcohol this alcohol will ruin you</td>\n",
       "      <td>narendra modi meerut rld bsp sharab alcohol alcohol ruin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57144</th>\n",
       "      <td>everytime modi govt achieves somethingone your body part starts burningironically you use the same body part think and that body part not brain</td>\n",
       "      <td>0</td>\n",
       "      <td>everytime modi govt achieves somethingone your body part starts burningironically you use the same body part think and that body part not brain</td>\n",
       "      <td>everytime modi govt achieves somethingone body start burningironically body body brain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                             clean_text  \\\n",
       "16111                                                                                                           two penny hate monger modi and netanyahu lover etc etc etc and not peaceful any way all   \n",
       "2266    western buyers who were shifting india from china because price rise there went pakistan bangladesh sri lanka vietnam etc because they have better price they are clocking big time thanks modi   \n",
       "139905                                                                                                      want watch debate between kanhaiya kumar the great orator narendra modi  plz arrange debate   \n",
       "83968                                                                                              narendra modi says meerut ‚Äòthe rld and bsp together make sharab alcohol this alcohol will ruin you‚Äô    \n",
       "57144                                                   everytime modi govt achieves somethingone your body part starts burningironically you use the same body part think and that body part not brain   \n",
       "\n",
       "        category  \\\n",
       "16111         -1   \n",
       "2266           1   \n",
       "139905         1   \n",
       "83968          0   \n",
       "57144          0   \n",
       "\n",
       "                                                                                                                                                                                             clean_ours  \\\n",
       "16111                                                                                                           two penny hate monger modi and netanyahu lover etc etc etc and not peaceful any way all   \n",
       "2266    western buyers who were shifting india from china because price rise there went pakistan bangladesh sri lanka vietnam etc because they have better price they are clocking big time thanks modi   \n",
       "139905                                                                                                       want watch debate between kanhaiya kumar the great orator narendra modi plz arrange debate   \n",
       "83968                                                                                                 narendra modi says meerut the rld and bsp together make sharab alcohol this alcohol will ruin you   \n",
       "57144                                                   everytime modi govt achieves somethingone your body part starts burningironically you use the same body part think and that body part not brain   \n",
       "\n",
       "                                                                                                                     lemmatized  \n",
       "16111                                                                       penny hate monger modi netanyahu lover peaceful all  \n",
       "2266    western buyer shifting india china price rise pakistan bangladesh sri lanka vietnam better price clocking big time modi  \n",
       "139905                                                watch debate kanhaiya kumar great orator narendra modi plz arrange debate  \n",
       "83968                                                                  narendra modi meerut rld bsp sharab alcohol alcohol ruin  \n",
       "57144                                    everytime modi govt achieves somethingone body start burningironically body body brain  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a64d042-e337-4d55-a6e4-0d065abd2738",
   "metadata": {},
   "source": [
    "## **Tokenization** \n",
    "\n",
    "Since the data cleaning and preprocessing stage is comprehensive, the tokenization step in the BoW model reduces to a simple word-boundary split operation. Each preprocessed entry in the DataFrame is split by spaces. For example, the entry `\"shri narendra modis\"` (entry: 42052) becomes `[\"shri\", \"narendra\", \"modis\"]`. By the end of tokenization, all entries are transformed into arrays of strings.\n",
    "\n",
    "## **Word Bigrams** \n",
    "\n",
    "As noted earlier, modifiers and polarity words are not included in the stopword set. The BoW model constructs a vocabulary containing both unigrams and bigrams. Including bigrams allows the model to capture common word patterns, such as  \n",
    "\n",
    "$$\n",
    "\\left\\langle \\texttt{Adj}\\right\\rangle \\left\\langle \\texttt{M} \\mid \\texttt{Pron} \\right\\rangle \n",
    "$$  \n",
    "\n",
    "<center>or</center>\n",
    "\n",
    "$$\n",
    "\\left\\langle \\texttt{Adv}\\right\\rangle \\left\\langle \\texttt{V} \\mid \\texttt{Adj} \\mid \\texttt{Adv} \\right\\rangle \n",
    "$$  \n",
    "\n",
    "## **Vector Representation**\n",
    "\n",
    "After the stemming and lemmatization steps, each entry can now be represented as a vector using a Bag of Words (BoW) model. We employ scikit-learn's `CountVectorizer`, which provides a ready-to-use implementation of BoW <u>(Pedregosa et al., 2011)</u>.\n",
    "\n",
    "A comparison of other traditional vector representations are discussed in [this appendix](#appendix:-comparison-of-traditional-vectorization-techniques).\n",
    "Words with modifiers have the modifiers directly attached, enabling subsequent models to capture the concept of modification fully. Consequently, after tokenization and bigram construction, the vocabulary size can grow up to $O(n^2)$, where $n$ is the number of unique tokens.\n",
    "\n",
    "**minimum document frequency constraint:** Despite cleaning and spam removal, some tokens remain irrelevant or too rare. To address this, a minimum document frequency constraint is applied: $\\texttt{min\\_df} = 10$, meaning a token must appear in at least 10 documents to be included in the BoW vocabulary. This reduces noise and ensures the model focuses on meaningful terms.\n",
    "\n",
    "---\n",
    "\n",
    "These parameters of the BoW model are encapsulated in the `BagOfWordsModel` class. The class definition is available in [this appendix](#appendix:-BagOfWordsModel-class-definition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7bfba459-6837-4481-929c-ef5ee023b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erin\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bow = BagOfWordsModel(df[\"lemmatized\"], 10)\n",
    "\n",
    "# some sanity checks\n",
    "assert bow.matrix.shape[0] == df.shape[0], \"number of rows in the matrix DOES NOT matches the number of documents\"\n",
    "assert bow.sparsity,                       \"the sparsity is TOO HIGH, something went wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75919779-1b56-4bec-9662-90afc11e1356",
   "metadata": {},
   "source": [
    "The error above is normal, recall that our tokenization step essentially reduced into an array split step. With this, we need to set the `tokenizer` function attribute of the `BagOfWordsModel` to not use its default tokenization pattern. That causes this warning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf5220-712f-4af3-9e2e-0fc3753f5cb1",
   "metadata": {},
   "source": [
    "### **Model Metrics**\n",
    "\n",
    "To get an idea of the model, we will now look at its shape and sparsity, with shape being the number of documents and tokens present in the model. While sparsity refers to the number of elements in a matrix that are zero, calculating how sparse or varied the words are in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0246d-899e-4bb6-957a-75419316197a",
   "metadata": {},
   "source": [
    "The resulting vector has a shape of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b6a5b688-b636-4320-bf22-e508a97aa862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162942, 30386)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc081f2-0630-4a0c-a40a-aeddcdfc8fb8",
   "metadata": {},
   "source": [
    "The first entry of the pair is the number of documents (the ones that remain after all the data cleaning and preprocessing steps) and the second entry is the number of tokens (or unique words in the vocabulary). \n",
    "\n",
    "The resulting model has a sparsity of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4fd01aa7-4842-4473-b410-591fd47983f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995039539872171"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - bow.sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33434da",
   "metadata": {},
   "source": [
    "The model is 99.95% sparse, meaning the tweets often do not share the same words leading to a large vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3277d-2106-490d-a304-8ff6e0780fd5",
   "metadata": {},
   "source": [
    "Now, looking at the most frequent and least frequent terms in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "10dd4551-90d0-4795-9303-1118fcc058c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['modi', 'india', 'ha', 'all', 'people', 'bjp', 'like', 'congress',\n",
       "       'narendra', 'only', 'election', 'narendra modi', 'vote', 'govt',\n",
       "       'about', 'indian', 'year', 'time', 'country', 'just', 'modis',\n",
       "       'more', 'nation', 'rahul', 'even', 'government', 'party', 'power',\n",
       "       'gandhi', 'minister', 'leader', 'good', 'modi govt', 'need',\n",
       "       'modi ha', 'space', 'work', 'prime', 'money', 'credit', 'sir',\n",
       "       'pakistan', 'back', 'day', 'today', 'prime minister', 'scientist',\n",
       "       'never', 'support', 'win'], dtype=object)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_frequencies = np.asarray((bow.matrix > 0).sum(axis=0)).flatten()\n",
    "freq_order = np.argsort(doc_frequencies)[::-1]\n",
    "bow.feature_names[freq_order[:50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c2f23-6494-4d41-937f-19664010b138",
   "metadata": {},
   "source": [
    "We see that the main talking point of the Tweets, which hovers around Indian politics with keywords like \"modi\", \"india\", and \"bjp\". For additional context, \"bjp\" referes to the _Bharatiya Janata Party_ which is a conservative political party in India, and one of the two major Indian political parties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b775494-3472-4089-8d86-e24346616155",
   "metadata": {},
   "source": [
    "Now, looking at the least popular words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "35f91a0d-dae1-41af-9f92-c06a973ebbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['healthy democracy', 'ha mass', 'ha separate', 'ha shifted',\n",
       "       'hat drdo', 'about defeat', 'yet ha', 'yes more', 'yes narendra',\n",
       "       'hatred people', 'ha requested', 'hate more', 'hate much',\n",
       "       'hatemonger', 'hater gonna', 'heal', 'hazaribagh', 'head drdo',\n",
       "       'sleep night', 'abinandan', 'able provide', 'able speak',\n",
       "       'able vote', 'youth need', 'youth power', 'hai isliye', 'hai chor',\n",
       "       'handy', 'hand narendra', 'hand people', 'hae', 'ha withdrawn',\n",
       "       'happens credit', 'happier', 'bhaiyo', 'socha', 'social political',\n",
       "       'social security', 'biased journalist', 'big congratulation',\n",
       "       'sirmodi', 'bhutan', 'bhi berozgar', 'bhi mumkin', 'skta',\n",
       "       'bhatt aditi', 'bhi aur', 'slamming', 'smart modi', 'slogan blame'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.feature_names[freq_order[-50:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5478a6-4ff0-4d64-a329-11278fe4e60a",
   "metadata": {},
   "source": [
    "We still see that the themes mentioned in the most frequent terms are still present in this subset. Although, more filler or non-distinct words do appear more often, like \"photos\", \"soft\" and \"types\".\n",
    "\n",
    "But the present of words like \"reelection\" and \"wars\" still point to this subset still being relevant to the main theme of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb530e2",
   "metadata": {},
   "source": [
    "# **4 exploratory data analysis**\n",
    "\n",
    "This section discusses the exploratory data analysis conducted on the dataset after cleaning.\n",
    "\n",
    "> Notes from Zhean: <br>\n",
    "> From manual checking via OpenRefine, there are a total of 162972. `df.info()` should have the same result post-processing.\n",
    "> Furthermore, there should be two columns, `clean_text` (which is a bit of a misnormer since it is still dirty) contains the Tweets (text data). The second column is the `category` which contains the sentiment of the Tweet and is a tribool (1 positive, 0 neutral or indeterminate, and -1 for negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ad21e-cb7b-4d91-87f9-a14c15ec8365",
   "metadata": {},
   "source": [
    "# **references**\n",
    "Bird, S., & Loper, E. (2004, July). NLTK: The natural language toolkit. *Proceedings of the ACL Interactive Poster and Demonstration Sessions*, 214‚Äì217. https://aclanthology.org/P04-3031/\n",
    "\n",
    "El-Demerdash, A. A., Hussein, S. E., & Zaki, J. F. W. (2021). Course evaluation based on deep learning and SSA hyperparameters optimization. *Computers, Materials & Continua, 71*(1), 941‚Äì959. https://doi.org/10.32604/cmc.2022.021839\n",
    "\n",
    "George, M., & Murugesan, R. (2024). Improving sentiment analysis of financial news headlines using hybrid Word2Vec-TFIDF feature extraction technique. *Procedia Computer Science, 244*, 1‚Äì8.\n",
    "\n",
    "Hussein, S. (2021). *Twitter sentiments dataset*. Mendeley.\n",
    "\n",
    "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. *Journal of Machine Learning Research, 12*, 2825‚Äì2830.\n",
    "\n",
    "Rani, D., Kumar, R., & Chauhan, N. (2022, October). Study and comparison of vectorization techniques used in text classification. In *2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)* (pp. 1‚Äì6). IEEE.\n",
    "\n",
    "Wolfram Research. (2015). *DeleteStopwords*. https://reference.wolfram.com/language/ref/DeleteStopwords.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7173f9-2c8d-4a5a-af3d-95761f09463a",
   "metadata": {},
   "source": [
    "# **appendix: `clean` wrapper function definition**\n",
    "Below is the definition of the `clean` wrapper function that encapsulates all internal functions used in the cleaning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fef8310b-aad6-4e48-80e6-e891c17a0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m clean(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m clean(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    This is the main function for data cleaning (i.e., it calls all the cleaning functions in the prescribed order).\u001b[39m\n",
      "\n",
      "\u001b[33m    This function should be used as a first-class function in a map.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: The string entry from a DataFrame column.\u001b[39m\n",
      "\u001b[33m    * stopwords: stopword dictionary.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Clean string\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;66;03m# cleaning on the base string\u001b[39;00m\n",
      "    text = normalize(text)\n",
      "    text = rem_punctuation(text)\n",
      "    text = rem_numbers(text)\n",
      "    text = collapse_whitespace(text)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "clean??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d116f4e-672a-4f3e-aa7d-1ee96d62d86b",
   "metadata": {},
   "source": [
    "# **appendix: `find_spam_and_empty` wrapper function definition**\n",
    "Below is the definition of the `find_spam_and_empty` wrapper function that encapsulates all internal functions for the spam detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "434da366-1648-4abd-8af0-ad4d4cd53d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m find_spam_and_empty(text: str, min_length: int = \u001b[32m3\u001b[39m) -> str | \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m find_spam_and_empty(text: str, min_length: int = \u001b[32m3\u001b[39m) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Filter out empty text and unintelligible/spammy unintelligible substrings in the text.\u001b[39m\n",
      "\n",
      "\u001b[33m    Spammy substrings:\u001b[39m\n",
      "\u001b[33m    - Shorter than min_length\u001b[39m\n",
      "\u001b[33m    - Containing non-alphabetic characters\u001b[39m\n",
      "\u001b[33m    - Consisting of a repeated substring (e.g., 'aaaaaa', 'ababab', 'abcabcabc')\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: input string.\u001b[39m\n",
      "\u001b[33m    * min_length: minimum length of word to keep.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m        Cleaned string, or None if empty after filtering.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    cleaned_tokens = []\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;28;01min\u001b[39;00m text.split():\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(t) < min_length:\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m re.search(\u001b[33mr\"(.)\\1{2,}\"\u001b[39m, t):\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        min_diversity = \u001b[32m0.3\u001b[39m + (\u001b[32m0.1\u001b[39m * min(len(t), \u001b[32m10\u001b[39m) / \u001b[32m10\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(set(t)) / len(t) < min_diversity:\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m re.match(\u001b[33mr\"^(.+)\\1+\"\u001b[39m, t):\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        cleaned_tokens.append(t)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\" \"\u001b[39m.join(cleaned_tokens) \u001b[38;5;28;01mif\u001b[39;00m cleaned_tokens \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "find_spam_and_empty??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f63c6-670f-42b1-8195-3c8156b2f4be",
   "metadata": {},
   "source": [
    "# **appendix: comparison of traditional vectorization techniques**\n",
    "\n",
    "Traditional vectorization techniques include BoW and Term Frequency-Inverse Document Frequency (TF-IDF). TF-IDF weights each word based on its frequency in a document and its rarity across the corpus, reducing the impact of common words. BoW, in contrast, simply counts word occurrences without considering corpus-level frequency. In this project, BoW was chosen because stopwords were already removed during preprocessing, and the dataset is domain-specific <u>(Rani et al., 2022)</u>. In such datasets, frequent words are often meaningful domain keywords, so scaling them down (as TF-IDF would) could reduce the importance of these key terms in the feature representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e651fa3-b1f3-4e71-9092-018bbabc07dc",
   "metadata": {},
   "source": [
    "# **appendix: `BagOfWordsModel` class definition**\n",
    "Below is the definition of the `BagOfWordsModel` class that encapsulates the desired parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0a9c57a0-98b3-40cb-8cd4-a1d9b30eb6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m BagOfWordsModel(texts: Iterable[str], min_freq: int | float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mSource:\u001b[39m        \n",
      "\u001b[38;5;28;01mclass\u001b[39;00m BagOfWordsModel:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    A Bag-of-Words representation for a text corpus.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Attributes\u001b[39m\n",
      "\u001b[33m    * matrix (scipy.sparse.csr_matrix): The document-term matrix of word counts.\u001b[39m\n",
      "\u001b[33m    * feature_names (list[str]): List of feature names corresponding to the matrix columns.\u001b[39m\n",
      "\u001b[33m    *\u001b[39m\n",
      "\u001b[33m    # Usage\u001b[39m\n",
      "\u001b[33m    ```\u001b[39m\n",
      "\u001b[33m    bow = BagOfWordsModel(df[\"lemmatized_str\"])\u001b[39m\n",
      "\u001b[33m    ```\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __init__(self, texts: Iterable[str], min_freq: int | float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Initialize the BagOfWordsModel by fitting the vectorizer to the text corpus. This also filters out tokens\u001b[39m\n",
      "\u001b[33m        that do not appear more than five times in the dataset.\u001b[39m\n",
      "\n",
      "\u001b[33m        This sets its tokenizer to the word boundary tokenizer since the input, at this point, **should** be\u001b[39m\n",
      "\u001b[33m        cleaned and processed text.\u001b[39m\n",
      "\n",
      "\u001b[33m        This also uses both unigrams and bigrams, hence, at the worst case its space complexity is O(n^2).\u001b[39m\n",
      "\n",
      "\u001b[33m        # Parameters\u001b[39m\n",
      "\u001b[33m        * texts: An iterable of cleaned text documents.\u001b[39m\n",
      "\u001b[33m        * min_freq: Determines the document frequency of a token for it to appear in the model.\u001b[39m\n",
      "\u001b[33m        Can be a type of int (i.e., the token must appear min_freq number of times in the document)\u001b[39m\n",
      "\u001b[33m        or a float (i.e, token must be in min_freq% of the documents)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        vectorizer = CountVectorizer(\n",
      "            min_df=min_freq \u001b[38;5;28;01mif\u001b[39;00m min_freq \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m,\n",
      "            tokenizer=str.split,    \u001b[38;5;66;03m# Use str.split instead of lambda\u001b[39;00m\n",
      "            lowercase=\u001b[38;5;28;01mFalse\u001b[39;00m,        \u001b[38;5;66;03m# Don't lowercase\u001b[39;00m\n",
      "            ngram_range=(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m),      \u001b[38;5;66;03m# Unigrams and bigrams\u001b[39;00m\n",
      "        )\n",
      "        self.matrix = vectorizer.fit_transform(texts)\n",
      "        self.feature_names = vectorizer.get_feature_names_out()\n",
      "        self.vectorizer = vectorizer\n",
      "        self.sparsity = self.matrix.nnz / (self.matrix.shape[\u001b[32m0\u001b[39m] * self.matrix.shape[\u001b[32m1\u001b[39m])\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m transform_sentence(self, sentence: str):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Returns the embedding of the sentence using the BoW matrix.\u001b[39m\n",
      "\n",
      "\u001b[33m        # Parameters:\u001b[39m\n",
      "\u001b[33m        * sentence: Cleaned sentence to vectorize.\u001b[39m\n",
      "\n",
      "\u001b[33m        # Returns\u001b[39m\n",
      "\u001b[33m        Sentence embedding.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.vectorizer.transform([sentence])\n",
      "\u001b[31mFile:\u001b[39m           c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\bag_of_words.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "BagOfWordsModel??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
