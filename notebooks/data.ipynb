{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44906e4e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Twitter Posts\n",
    "\n",
    "<!-- Notebook name goes here -->\n",
    "<center><b>Notebook: Data Description, Cleaning, Exploratory Data Analysis, and Preprocessing</b></center>\n",
    "<br>\n",
    "\n",
    "**by**: Stephen Borja, Justin Ching, Erin Chua, and Zhean Ganituen.\n",
    "\n",
    "**dataset**: Hussein, S. (2021). Twitter Sentiments Dataset [Dataset]. Mendeley. https://doi.org/10.17632/Z9ZW7NT5H2.1\n",
    "\n",
    "**motivation**: Every minute, social media users generate a large influx of textual data on live events. Performing sentiment analysis on this data provides a real-time view of public perception, enabling quick insights into the general population‚Äôs opinions and reactions.\n",
    "\n",
    "**goal**: By the end of the project, our goal is to create and compare supervised learning algorithms for sentiment analysis.\n",
    "\n",
    "### **dataset description**\n",
    "\n",
    "The Twitter Sentiments Dataset is a dataset that contains nearly 163k tweets from Twitter. The time period of when these were collected is unknown, but it was published to Mendeley Data on May 14, 2021 by Sherif Hussein of Mansoura University.\n",
    "\n",
    "Tweets were extracted using the Twitter API, but the specifics of how the tweets were selected are unmentioned. The tweets are mostly English with a mix of some Hindi words for code-switching <u>(El-Demerdash., 2021)</u>. All of them seem to be talking about the political state of India. Most tweets mention Narendra Modi, the current Prime Minister of India.\n",
    "\n",
    "Each tweet was assigned a label using TextBlob's sentiment analysis <u>(El‚ÄëDemerdash, Hussein, & Zaki, 2021)</u>, which assigns labels automatically.\n",
    "\n",
    "Twitter_Data\n",
    "\n",
    "- **`clean_text`**: The tweet's text\n",
    "- **`category`**: The tweet's sentiment category\n",
    "\n",
    "What each row and column represents: `each row represents one tweet.` <br>\n",
    "Number of observations: `162,980`\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) Code-switching is the practice of alternating between two languages $L_1$ (the native language) and $L_2$ (the source language) in a conversation. In this context, the code-switching is done to appear more casual since the conversation is done via Twitter (now, X).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47491b2f",
   "metadata": {},
   "source": [
    "## **1. Project Set-up**\n",
    "\n",
    "We set the global imports for the projects (ensure these are installed via uv and is part of the environment). Furthermore, load the dataset here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d7578d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:01:26.803271Z",
     "start_time": "2025-06-17T14:01:26.567527Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Use lib directory\n",
    "sys.path.append(os.path.abspath(\"../lib\"))\n",
    "\n",
    "# Imports from lib files\n",
    "from janitor import *\n",
    "from lemmatize import lemmatizer\n",
    "from boilerplate import stopwords_set\n",
    "from bag_of_words import BagOfWordsModel\n",
    "\n",
    "# Pandas congiruation\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Load raw data file\n",
    "df = pd.read_csv(\"../data/Twitter_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ec446",
   "metadata": {},
   "source": [
    "## **2. Data Cleaning**\n",
    "\n",
    "This section discusses the methodology for data cleaning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7681e",
   "metadata": {},
   "source": [
    "As to not waste computational time, a preliminary step is to ensure that no `NaN` or duplicate entries exist before the cleaning steps. We can call on `.info()` after each step to see the rows changed in our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1c44c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162980 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162976 non-null  object \n",
      " 1   category    162973 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9f47b",
   "metadata": {},
   "source": [
    "There are clear inconsistencies with the amount of non-null values between column `clean_text` and `category` versus the total entries, so our first step would be to drop the `NaN` entries. We can first check which rows have `category` as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1101a22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130448</th>\n",
       "      <td>the foundation stone northeast gas grid inaugurated modi came major</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155642</th>\n",
       "      <td>dear terrorists you can run but you cant hide are giving more years modi which you won‚Äô see you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155698</th>\n",
       "      <td>offense the best defence with mission shakti modi has again proved why the real chowkidar our</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155770</th>\n",
       "      <td>have always heard politicians backing out their promises but modi has been fulfilling his each every</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158693</th>\n",
       "      <td>modi government plans felicitate the faceless nameless warriors india totally deserved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158694</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159442</th>\n",
       "      <td>chidambaram gives praises modinomics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159443</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160559</th>\n",
       "      <td>the reason why modi contested from seats 2014 and the real reason why rahul doing the same now</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  clean_text  \\\n",
       "148                                                                                                      NaN   \n",
       "130448                                   the foundation stone northeast gas grid inaugurated modi came major   \n",
       "155642       dear terrorists you can run but you cant hide are giving more years modi which you won‚Äô see you   \n",
       "155698         offense the best defence with mission shakti modi has again proved why the real chowkidar our   \n",
       "155770  have always heard politicians backing out their promises but modi has been fulfilling his each every   \n",
       "158693                modi government plans felicitate the faceless nameless warriors india totally deserved   \n",
       "158694                                                                                                   NaN   \n",
       "159442                                                                  chidambaram gives praises modinomics   \n",
       "159443                                                                                                   NaN   \n",
       "160559        the reason why modi contested from seats 2014 and the real reason why rahul doing the same now   \n",
       "160560                                                                                                   NaN   \n",
       "\n",
       "        category  \n",
       "148          0.0  \n",
       "130448       NaN  \n",
       "155642       NaN  \n",
       "155698       NaN  \n",
       "155770       NaN  \n",
       "158693       NaN  \n",
       "158694      -1.0  \n",
       "159442       NaN  \n",
       "159443       0.0  \n",
       "160559       NaN  \n",
       "160560       1.0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaN_rows = df[df.isna().any(axis=1)]\n",
    "NaN_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e844d7",
   "metadata": {},
   "source": [
    "As expected, there are a total of 11 rows that have `NaN` values, thus we drop them to ensure the integrity and accuracy of our data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "28609dbc-1d51-4bba-b64c-a570c9ac4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8865f85-09ec-4528-8b69-4f39ec72ae26",
   "metadata": {},
   "source": [
    "Another issue found commonly in real-world datasets would be duplicate rows, often from manual data entry errors, system glitches, or when merging data from multiple, overlapping sources. We can first check for duplicates in our DataFrame then remove them.\n",
    "> üç† do i need to cite this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8502764d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clean_text, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = df[df.duplicated()]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733f800",
   "metadata": {},
   "source": [
    "There exist no duplicate rows within our DataFrame but we will still drop any duplicate rows for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "452f1167-41cd-49a9-a328-8311f1567071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a31de7",
   "metadata": {},
   "source": [
    "By converting a CSV file into a DataFrame, pandas automatically defaults numeric values to `float64` when it encounters decimals or `NaN` types. Text of `str` type get inferred and loaded into a `object` as the generic type for strings. We can check the dtype of our DataFrame columns through `.info()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a5f1374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d93c9",
   "metadata": {},
   "source": [
    "We can see that `clean_text` column dtype is of `object` and category is of dytpe `float64`, we first we convert column `category` from `float64` to `int64` considering that the range of values (-1, 0, 1) for a tweet's sentiment category will only ever be whole numbers. This step is done after dropping `NaN` value rows because `NaN` is fundamentally a float type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fe43fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  object\n",
      " 1   category    162969 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df[\"category\"] = df[\"category\"].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a8070",
   "metadata": {},
   "source": [
    "After successfully converting the `category` column into `int64`, next we convert column `clean_string` from `object` type into the pandas defined `string` type for consistency and better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "edc2bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  string\n",
      " 1   category    162969 non-null  int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"clean_text\"] = df[\"clean_text\"].astype(\"string\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b98d6d",
   "metadata": {},
   "source": [
    "Considering that the sentiment values or the `category` column should be within the range [-1, 0, 1] to represent the three sentiments, namely, negative, neutral, and positive, we check for all unique values in `category` and remove any that do not fall within the provided range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c9f17c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225e3f7",
   "metadata": {},
   "source": [
    "All existing values in the `category` column in the DataFrame are within the expected range, but we still drop any rows that have values outside of the provided range for data consistency and extra precaution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa1384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31875     1\n",
       "126871   -1\n",
       "84922    -1\n",
       "13722     0\n",
       "2910      0\n",
       "106910    1\n",
       "39553     0\n",
       "88887     0\n",
       "64471     1\n",
       "12340    -1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"category\"].isin([-1, 0, 1])]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec33f2-9967-4458-878b-79b697ec9e4e",
   "metadata": {},
   "source": [
    "## **Main Cleaning Pipeline**\n",
    "\n",
    "We follow a similar methodology for data cleaning presented in (George & Murugesan, 2024).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a22cb",
   "metadata": {},
   "source": [
    "### **Normalization**\n",
    "\n",
    "Due to the nature of the text being tweets, we noticed a prevalence in the use of emojis and accented characters as seen in the samples below. Although in a real-world context these do serve as a form of emotional expression, it provides no relevance towards _textual_ sentiment analysis, thus we normalize the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e06f520c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61048                                                           v√≠a bjp leaders hail for indias successful demonstration antimissile technology read \n",
       "97413                                         sir please one expos√© about the degree modi also everyone wants see his degree entire political science\n",
       "21088                                  leaders opposition parties will joint press conference today 100 says will expos√© one scam the modi government\n",
       "50461    v√≠a not against any particular nation demonstration our own technology former drdo chief saraswat tells cnnnews18s follow live updates here \n",
       "23608                dinesh rodi ardent fan modi has opened rodi resto cafe themed modi tamil nadus thoothukudi take peep inside the modithemed caf√© \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with accented characters\n",
    "accented_char_rows = df[df[\"clean_text\"].str.contains(r\"√â|√©|√Å|√°|√≥|√ì|√∫|√ö|√≠|√ç\")]\n",
    "accented_char_rows[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ff6b5d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73411                                                                                                                                                                                   love ‚ù§Ô∏è love ‚ù§Ô∏è love ‚ù§Ô∏è chal jutha \n",
       "119259                                                                                                                                                                                                         how sweet ‚ò∫Ô∏è\n",
       "88147                                                                                                                                                                         here ‚ò∫Ô∏è the trailer upcoming web series modi \n",
       "23615     too much appeasement for vote banking resulted you have forgotten your hindu customs and religion that have festival called ‚Äú ayudha pooja ‚Äú khangress doesn‚Äô respect hindu festivals vote for modi modi again ‚úåÔ∏è\n",
       "23190                                                                                                                                                         hey surya happy for you special thanks honorable shri modi ‚ò∫‚úå\n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with emojis\n",
    "rows_with_emojis = df[df[\"clean_text\"].str.contains(r\"[\\u263a-\\U0001f645]\", regex=True)]\n",
    "rows_with_emojis[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb30dbd",
   "metadata": {},
   "source": [
    "The first function is the `normalize` function, it normalizes the text input to ASCII-only characters (say, \"c√≥mo est√°s\" becomes \"como estas\") and lowercased alphabetic symbols. The dataset contains Unicode characters (e.g., emojis and accented characters) which the function replaces to the empty string (`''`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b0425f96-ed91-41ca-9033-5bb53f14c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m normalize(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m normalize(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Normalize text from a pandas entry to ASCII-only lowercase characters. Hence, this removes Unicode characters with no ASCII\u001b[39m\n",
      "\u001b[33m    equivalent (e.g., emojis and CJKs).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    ASCII-normalized text containing only lowercase letters.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    normalize(\"¬øC√≥mo est√°s?\")\u001b[39m\n",
      "\u001b[33m    $ 'como estas?'\u001b[39m\n",
      "\n",
      "\u001b[33m    normalize(\" hahahaha HUY! Kamusta üòÖ Mayaman $$$ ka na ba?\")\u001b[39m\n",
      "\u001b[33m    $ ' hahahaha huy! kamusta  mayaman $$$ ka na ba?'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    normalized = unicodedata.normalize(\u001b[33m\"NFKD\"\u001b[39m, text)\n",
      "    ascii_text = normalized.encode(\u001b[33m\"ascii\"\u001b[39m, \u001b[33m\"ignore\"\u001b[39m).decode(\u001b[33m\"ascii\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m ascii_text.lower()\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "normalize??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc84505-f974-442b-8763-62bd20d729ea",
   "metadata": {},
   "source": [
    "### **Punctuations**\n",
    "\n",
    "Punctuations are part of natural speech and reading to provide a sense of structure, clarity, and tone to sentences, but in the context of a classification study punctuations do not add much information to the sentiment of a message. The sentiment of `i hate you!` and `i hate you` are going to be the same despite the punctuation mark `!` being used to accentuate the sentiment. We can see a sample of rows with punctations below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3e026e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28665                                           hey you cut modi not the nation ‚Äô with democracy people like you are rupturing india great and modi the fat ugly moron sht ‚Äô with india ‚Äô with democracy but ‚Äô not with hate monger airhead\n",
       "3560                                                                                                                                              modi can execute this scheme simply raiding gandhi‚Äô and vadra‚Äô assets swiss bank accounts\n",
       "27259                                                                                   why necessary for you that year old brahmin must fight election just because you don‚Äô like modi why don‚Äô you bell the cat instead preaching others \n",
       "26503                                                           nikal demonetisation killed over 100 people left over crore jobless still you were over modi‚Äô masterstoke demonetisation people get three times food than vote for congress\n",
       "70648    were national disaster you would have blamed modi alone for now wouldn‚Äô you anyone can plant seeds but ‚Äô the one who nurtures the seed that deserves the actual credit period also see what the chief drdo said regarding this fyi\n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with punctuation\n",
    "rows_with_punc = df[df[\"clean_text\"].str.contains(r\"[^\\w\\s]\")]\n",
    "rows_with_punc[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b3a75",
   "metadata": {},
   "source": [
    "The function `rem_punctuation` replaces all punctuations and special characters into an empty string (`''`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "62aa658b-8dbd-4533-af84-cbb221571835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m rem_punctuation(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m rem_punctuation(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Removes the punctuations. This function simply replaces all punctuation marks and special characters\u001b[39m\n",
      "\u001b[33m    to the empty string. Hence, for symbols enclosed by whitespace, the whitespace are not collapsed to a single whitespace\u001b[39m\n",
      "\u001b[33m    (for more information, see the examples).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the punctuation removed.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    rem_punctuation(\"this word $$ has two spaces after it!\")\u001b[39m\n",
      "\u001b[33m    $ 'this word  has two spaces after it'\u001b[39m\n",
      "\n",
      "\u001b[33m    rem_punctuation(\"these!words@have$no%space\")\u001b[39m\n",
      "\u001b[33m    $ 'thesewordshavenospace'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(f\"[{re.escape(string.punctuation)}]\", \u001b[33m\"\"\u001b[39m, text)\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rem_punctuation??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47e93e-aa0e-473c-89d5-f30df86815da",
   "metadata": {},
   "source": [
    "### **Numbers**\n",
    "\n",
    "Similar to punctuations, numbers do not add any information to the sentiment of a message as seen in the samples below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "103a4a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161779                                                                                                                               according survey hindus want modi will the countys again 2019 you are also then retweet and follow hindu supporter\\n‡•ç‡§ü‡§∞‡§π‡§ø‡•ç‡•Ç\n",
       "10223                                                                                                                                  \\nmodi govt built 153 crore houses under awas yojana from 201418 this multiple times more than earlier govt\\nvia namo app\n",
       "88050     modi was fact shocked and made immobile when said will not accept modi prime minister after 2014 elections entire india got stumped and came stand still after repeated persuasion accepted and modi became how can you forget something happened 2014\n",
       "82740                                                                                                                                                      the hindu ‚Äúunlike 2014 there modi wave this time open election and there will fight every seat incl‚Ä¶ \n",
       "31556                                                                     whatever damn sure modi will bomb and neutralise this 72000 scheme like nobody else and should very 1st day good that pappu declared days pms rallies giving enough time and ammo for \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows that contain numbers\n",
    "rows_with_numbers = df[df[\"clean_text\"].str.contains(r\"\\d\")]\n",
    "rows_with_numbers[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d403d",
   "metadata": {},
   "source": [
    "Hence we defined the `rem_numbers` as a function that replaces all numerical values as an empty string (`''`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d3a58576-8dd7-4043-a903-41b7cfab88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m rem_numbers(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m rem_numbers(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Removes numbers. This function simply replaces all numerical symbols to the empty string. Hence, for symbols enclosed by\u001b[39m\n",
      "\u001b[33m    whitespace, the whitespace are not collapsed to a single whitespace (for more information, see the examples).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the numerical symbol removed\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    rem_numbers(\" h3llo, k4must4 k4  n4?\")\u001b[39m\n",
      "\u001b[33m    ' hllo, kmust k  n?'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33mr\"\\d+\"\u001b[39m, \u001b[33m\"\"\u001b[39m, text)\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rem_numbers??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b1491-1821-42b1-a63f-dab941dc003f",
   "metadata": {},
   "source": [
    "### **Whitespace**\n",
    "\n",
    "We also noticed the prevalance of excess whitespaces in between words, as seen in the sample below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "da2c270a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123951    and your bjp friends with pakistan birthday wish karne waha chale jaate chacha nirav modi vijay mallaya mehul choksi such scamsters whom you helped flee from country with friends like those can public interest served  \n",
       "104950                                                                                                                  sir need thank nehru and congress for doing nothing and leaving all the work done modi they also know that  \n",
       "66865                                                                                                                           hello  thank you for admitting that had brave leadership who started this mission least years modi  \n",
       "76220                                                    modi gets the credit credit does not capability credit goes one who gets things done did your rajdeeps program madhavan said upa was disaster disaster  and rajdeep beeped \n",
       "16422                                                                                                                           madam kannada slogans are there majority banners are kannada  modi even start his rally with kannada\n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows that contain 2 or more whitespaces in a row\n",
    "rows_with_whitespaces = df[df[\"clean_text\"].str.contains(r\"\\s{2,}\")]\n",
    "rows_with_whitespaces[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8144d29",
   "metadata": {},
   "source": [
    "Thus, function `collapse_whitespace` collapses all whitespace characters to a single space. Formally, it is a transducer\n",
    "\n",
    "$$\n",
    "\\Box^+ \\mapsto \\Box \\qquad \\text{where the space character is } \\Box\n",
    "$$\n",
    "\n",
    "Informally, it replaces all strings of whitespaces to a single whitespace character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3823f3bc-0a42-473a-8888-a4c06f0659ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m collapse_whitespace(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m collapse_whitespace(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    This collapses whitespace. Here, collapsing means the transduction of all whitespace strings of any\u001b[39m\n",
      "\u001b[33m    length to a whitespace string of unit length (e.g., \"   \" -> \" \"; formally \" \"+ -> \" \").\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the whitespaces collapsed.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    collapse_whitespace(\"  huh,  was.  that!!! \")\u001b[39m\n",
      "\u001b[33m    $ 'huh, was. that!!!'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33m\" +\"\u001b[39m, \u001b[33m\" \"\u001b[39m, text).strip()\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "collapse_whitespace??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd388a-e397-4100-a6df-a971db6f85df",
   "metadata": {},
   "source": [
    "To seamlessly call all these cleaning functions, we have the `clean` function that acts as a container that calls these separate components. The definition of this wrapper function is quite long, see [this appendix](#appendix:-clean-wrapper-function-definition) for its definition.\n",
    "\n",
    "We can now clean the dataset and store it in a new column named `clean_ours` (to differentiate it with the, still dirty, column `clean_text` from the dataset author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6d4ea4d2-e8fe-437f-a46f-a18b1b34f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  string\n",
      " 1   category    162969 non-null  int64 \n",
      " 2   clean_ours  162969 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"clean_ours\"] = df[\"clean_text\"].map(clean).astype(\"string\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf28ad",
   "metadata": {},
   "source": [
    "To confirm if the character cleaning worked, we can check for the differences between `clean_text` and `clean_ours` from the filtered rows below and compare the differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "12724f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100701</th>\n",
       "      <td>2019 elections are achievements narendra modi people and large hugely appreciative his leadership quality</td>\n",
       "      <td>1</td>\n",
       "      <td>elections are achievements narendra modi people and large hugely appreciative his leadership quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91067</th>\n",
       "      <td>india upfront issues distinguished voices questions has modi demonstrated ‚Äòdum‚Äô fight ‚Äògaribi‚Äô does india believe that rahul better placed give ‚Äònyay‚Äô the ‚Äòkisan‚Äô can ‚Äòhandout‚Äô niti create naukri join</td>\n",
       "      <td>1</td>\n",
       "      <td>india upfront issues distinguished voices questions has modi demonstrated dum fight garibi does india believe that rahul better placed give nyay the kisan can handout niti create naukri join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118749</th>\n",
       "      <td>full modi prime minister first 2019 interview speaks arnab goswami media network watch ‚ñ∂Ô∏è</td>\n",
       "      <td>1</td>\n",
       "      <td>full modi prime minister first interview speaks arnab goswami media network watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61787</th>\n",
       "      <td>india‚Äô scientists have destroyed ‚Äúlive satellite‚Äù the lower earth orbit today completing hightech and difficult task dubbed</td>\n",
       "      <td>-1</td>\n",
       "      <td>india scientists have destroyed live satellite the lower earth orbit today completing hightech and difficult task dubbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69690</th>\n",
       "      <td>india shot down satellite modi says shifting balance power asia via nytimes ‚òû</td>\n",
       "      <td>-1</td>\n",
       "      <td>india shot down satellite modi says shifting balance power asia via nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37885</th>\n",
       "      <td>major terrorist attacks since balakot bombings wiped out 300 pakis has modi finally made the difference</td>\n",
       "      <td>1</td>\n",
       "      <td>major terrorist attacks since balakot bombings wiped out pakis has modi finally made the difference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>shot the arm bjp will sure terrible harm bjp coming elections congress will have fun for five years atal lost due onion price modi can also face the same music quick and guaranty minimum 15000month job all graduates dig pools\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>shot the arm bjp will sure terrible harm bjp coming elections congress will have fun for five years atal lost due onion price modi can also face the same music quick and guaranty minimum month job all graduates dig pools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131982</th>\n",
       "      <td>from nehru rahul gandhi family lying from past four generation poverty narendra modi ‚Å¶ ‚Å¶ ‚Å¶</td>\n",
       "      <td>-1</td>\n",
       "      <td>from nehru rahul gandhi family lying from past four generation poverty narendra modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15835</th>\n",
       "      <td>congress was corrupt despite that implemented rti which was used expose many its scams under modi information commissioner vacancies have been left open and they dont respond rti queries still the one fighting corruption ‚Äç‚ôÇÔ∏è‚Äç‚ôÇÔ∏è</td>\n",
       "      <td>0</td>\n",
       "      <td>congress was corrupt despite that implemented rti which was used expose many its scams under modi information commissioner vacancies have been left open and they dont respond rti queries still the one fighting corruption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>narendra modi scores 100100 the prime minister this great country deserves another chance hope the rest his cabinet colleagues follow suit and win hearts and brains the electoral</td>\n",
       "      <td>1</td>\n",
       "      <td>narendra modi scores the prime minister this great country deserves another chance hope the rest his cabinet colleagues follow suit and win hearts and brains the electoral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                 clean_text  \\\n",
       "100701                                                                                                                           2019 elections are achievements narendra modi people and large hugely appreciative his leadership quality    \n",
       "91067                             india upfront issues distinguished voices questions has modi demonstrated ‚Äòdum‚Äô fight ‚Äògaribi‚Äô does india believe that rahul better placed give ‚Äònyay‚Äô the ‚Äòkisan‚Äô can ‚Äòhandout‚Äô niti create naukri join    \n",
       "118749                                                                                                                                           full modi prime minister first 2019 interview speaks arnab goswami media network watch ‚ñ∂Ô∏è    \n",
       "61787                                                                                                          india‚Äô scientists have destroyed ‚Äúlive satellite‚Äù the lower earth orbit today completing hightech and difficult task dubbed    \n",
       "69690                                                                                                                                                        india shot down satellite modi says shifting balance power asia via nytimes ‚òû    \n",
       "37885                                                                                                                               major terrorist attacks since balakot bombings wiped out 300 pakis has modi finally made the difference   \n",
       "9839    shot the arm bjp will sure terrible harm bjp coming elections congress will have fun for five years atal lost due onion price modi can also face the same music quick and guaranty minimum 15000month job all graduates dig pools\\n   \n",
       "131982                                                                                                                                          from nehru rahul gandhi family lying from past four generation poverty narendra modi ‚Å¶ ‚Å¶ ‚Å¶    \n",
       "15835   congress was corrupt despite that implemented rti which was used expose many its scams under modi information commissioner vacancies have been left open and they dont respond rti queries still the one fighting corruption ‚Äç‚ôÇÔ∏è‚Äç‚ôÇÔ∏è   \n",
       "10003                                                   narendra modi scores 100100 the prime minister this great country deserves another chance hope the rest his cabinet colleagues follow suit and win hearts and brains the electoral    \n",
       "\n",
       "        category  \\\n",
       "100701         1   \n",
       "91067          1   \n",
       "118749         1   \n",
       "61787         -1   \n",
       "69690         -1   \n",
       "37885          1   \n",
       "9839           1   \n",
       "131982        -1   \n",
       "15835          0   \n",
       "10003          1   \n",
       "\n",
       "                                                                                                                                                                                                                          clean_ours  \n",
       "100701                                                                                                                          elections are achievements narendra modi people and large hugely appreciative his leadership quality  \n",
       "91067                                 india upfront issues distinguished voices questions has modi demonstrated dum fight garibi does india believe that rahul better placed give nyay the kisan can handout niti create naukri join  \n",
       "118749                                                                                                                                             full modi prime minister first interview speaks arnab goswami media network watch  \n",
       "61787                                                                                                       india scientists have destroyed live satellite the lower earth orbit today completing hightech and difficult task dubbed  \n",
       "69690                                                                                                                                                    india shot down satellite modi says shifting balance power asia via nytimes  \n",
       "37885                                                                                                                            major terrorist attacks since balakot bombings wiped out pakis has modi finally made the difference  \n",
       "9839    shot the arm bjp will sure terrible harm bjp coming elections congress will have fun for five years atal lost due onion price modi can also face the same music quick and guaranty minimum month job all graduates dig pools  \n",
       "131982                                                                                                                                          from nehru rahul gandhi family lying from past four generation poverty narendra modi  \n",
       "15835   congress was corrupt despite that implemented rti which was used expose many its scams under modi information commissioner vacancies have been left open and they dont respond rti queries still the one fighting corruption  \n",
       "10003                                                    narendra modi scores the prime minister this great country deserves another chance hope the rest his cabinet colleagues follow suit and win hearts and brains the electoral  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_rows = df[\n",
    "    df[\"clean_text\"].str.contains(r\"\\s{2,}|\\d|[^\\w\\s]|[\\u263a-\\U0001f645]|[√â√©√Å√°√≥√ì√∫√ö√≠√ç]\")\n",
    "]\n",
    "example_rows.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94256624",
   "metadata": {},
   "source": [
    "We are now finished with basic text cleaning, but the data cleaning does not end here. Given that the text is sourced from Twitter, it includes characteristics, such as spam and informal expressions, which are not addressed by basic cleaning methods. As a result, we move on to further cleaning tailored to the nature of Twitter data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110683a-3879-452e-9d2f-50c4af4e0ad6",
   "metadata": {},
   "source": [
    "### **Spam, Expressions, Onomatopoeia, etc.**\n",
    "\n",
    "Since the domain of the corpus is Twitter, spam (e.g., `bbbb`), expressions (e.g., `bruhhhh`), and onomatopoeia (e.g., `hahahaha`) may become an issue by the vector representation step. Hence we employed a simple rule-based spam removal algorithm.\n",
    "\n",
    "We remove words in the string that contains the same letter or substring thrice and consecutively. These were done using regular expressions:\n",
    "\n",
    "$$\n",
    "\\text{same\\_char\\_thrice} := (.)\\textbackslash1^{\\{2,\\}}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\text{same\\_substring\\_twice} := (.^+)\\textbackslash1^+\n",
    "$$\n",
    "\n",
    "Furthermore, we also remove any string that has a length less than three, since these are either stopwords (that weren't detected in the stopword removal stage) or more spam.\n",
    "\n",
    "Finally, we employ adaptive character diversity threshold for the string $s$.\n",
    "\n",
    "$$\n",
    "\\frac{\\texttt{\\#\\_unique\\_chars}(s)}{|s|} < 0.3 + \\left(\\frac{0.1 \\cdot \\text{min}(|s|, 10)}{10}\\right)\n",
    "$$\n",
    "\n",
    "It calculates the diversity of characters in a string; if the string repeats the same character alot, we expect it to be unintelligible or useless, hence we remove the string.\n",
    "\n",
    "The definition of this wrapper function is quite long, see its definition in [this appendix](#appendix:-find_spam_and_empty-wrapper-function-definition).\n",
    "\n",
    "Let's first look at a random sample of 10 entries from the dataset that will be modified by the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9015aea8-b6f6-4408-b027-f9c79cf7d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5826                                                                                                                                                                      modi for ambani adani rahul for aam garib aadmi choice yours choose wisely\n",
       "154860                      problem south bangalore constituency late ananth kumar wife doing lot social work every voter cofusionall want vote modi central but due humiliation done her and for sake humanity please justice her you wonderful man\n",
       "5761                                                                                                                                     aap comes pawar central will give lakh per annam evary indian who did nat voted modi new young arvind yojna\n",
       "52589                                                                                                                   live west bengal mamata banerjee said that drdo achievements are being used for publicity mongering modi\\nfollow for updates\n",
       "75481                                                                           for nd consecutive time narendra modi will launch the bjp poll campaign for lok sabha elections from jammu the city temples addressing election rally dhoomi akhnoor\n",
       "52769                                                                                                         hii everyonetoday the proud moment for usindia becomes th nation enter elite space power club with antisatellite weapon announces modi\n",
       "20922                                          delhi who has seats begging party for alliance which has seats party with seats rejecting that offer\\nvaranasi loksabha seat against modi aap gives cong cong gives gives bsp bsp candidate joins bjp\n",
       "134418                                                                                                                                                                                          look how modi boy runs away form live program hahaha\n",
       "85090                                                                                                                                                       real interest rates were jacked rrr the great economist sabotage the recovery under modi\n",
       "112920    our kids financial sector assured give gm gold free every newly married couple after submitting marriage certificate once our kids get elected they can order all jewellery shops india give gm gold free newly married modi created funds\n",
       "Name: clean_ours, dtype: string"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected = df[df[\"clean_ours\"].apply(spam_affected)]\n",
    "affected_sample = affected[\"clean_ours\"].sample(10)\n",
    "affected_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e75f3f-6619-47b8-9b73-5d3d9fa38fbc",
   "metadata": {},
   "source": [
    "Let's now call this function on the `clean_ours` column of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7ac69746-f471-4a66-9292-c2b363d12de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_ours\"] = df[\"clean_ours\"].map(find_spam_and_empty).astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfddca4",
   "metadata": {},
   "source": [
    "To confirm if the function was able to do remove all the spammy substrings, we can check `before` and `after` and compare their differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "afc3e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52589</th>\n",
       "      <td>live west bengal mamata banerjee said that drdo achievements are being used for publicity mongering modi\\nfollow for updates</td>\n",
       "      <td>live west bengal banerjee said that drdo achievements are being used for publicity mongering modi follow for updates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>modi for ambani adani rahul for aam garib aadmi choice yours choose wisely</td>\n",
       "      <td>modi for ambani adani rahul for garib choice yours choose wisely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112920</th>\n",
       "      <td>our kids financial sector assured give gm gold free every newly married couple after submitting marriage certificate once our kids get elected they can order all jewellery shops india give gm gold free newly married modi created funds</td>\n",
       "      <td>our kids financial sector assured give gold free every newly married couple after submitting marriage certificate once our kids get elected they can order all jewellery shops india give gold free newly married modi created funds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154860</th>\n",
       "      <td>problem south bangalore constituency late ananth kumar wife doing lot social work every voter cofusionall want vote modi central but due humiliation done her and for sake humanity please justice her you wonderful man</td>\n",
       "      <td>problem south bangalore constituency late kumar wife doing lot social work every voter cofusionall want vote modi central but due humiliation done her and for sake humanity please justice her you wonderful man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52769</th>\n",
       "      <td>hii everyonetoday the proud moment for usindia becomes th nation enter elite space power club with antisatellite weapon announces modi</td>\n",
       "      <td>hii everyonetoday the proud moment for usindia becomes nation enter elite space power club with antisatellite weapon announces modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75481</th>\n",
       "      <td>for nd consecutive time narendra modi will launch the bjp poll campaign for lok sabha elections from jammu the city temples addressing election rally dhoomi akhnoor</td>\n",
       "      <td>for consecutive time narendra modi will launch the bjp poll campaign for lok sabha elections from jammu the city temples addressing election rally dhoomi akhnoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20922</th>\n",
       "      <td>delhi who has seats begging party for alliance which has seats party with seats rejecting that offer\\nvaranasi loksabha seat against modi aap gives cong cong gives gives bsp bsp candidate joins bjp</td>\n",
       "      <td>delhi who has seats begging party for alliance which has seats party with seats rejecting that offer varanasi loksabha seat against modi gives cong cong gives gives bsp bsp candidate joins bjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85090</th>\n",
       "      <td>real interest rates were jacked rrr the great economist sabotage the recovery under modi</td>\n",
       "      <td>real interest rates were jacked the great economist sabotage the recovery under modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134418</th>\n",
       "      <td>look how modi boy runs away form live program hahaha</td>\n",
       "      <td>look how modi boy runs away form live program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5761</th>\n",
       "      <td>aap comes pawar central will give lakh per annam evary indian who did nat voted modi new young arvind yojna</td>\n",
       "      <td>comes pawar central will give lakh per annam evary indian who did nat voted modi new young arvind yojna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            before  \\\n",
       "52589                                                                                                                 live west bengal mamata banerjee said that drdo achievements are being used for publicity mongering modi\\nfollow for updates   \n",
       "5826                                                                                                                                                                    modi for ambani adani rahul for aam garib aadmi choice yours choose wisely   \n",
       "112920  our kids financial sector assured give gm gold free every newly married couple after submitting marriage certificate once our kids get elected they can order all jewellery shops india give gm gold free newly married modi created funds   \n",
       "154860                    problem south bangalore constituency late ananth kumar wife doing lot social work every voter cofusionall want vote modi central but due humiliation done her and for sake humanity please justice her you wonderful man   \n",
       "52769                                                                                                       hii everyonetoday the proud moment for usindia becomes th nation enter elite space power club with antisatellite weapon announces modi   \n",
       "75481                                                                         for nd consecutive time narendra modi will launch the bjp poll campaign for lok sabha elections from jammu the city temples addressing election rally dhoomi akhnoor   \n",
       "20922                                        delhi who has seats begging party for alliance which has seats party with seats rejecting that offer\\nvaranasi loksabha seat against modi aap gives cong cong gives gives bsp bsp candidate joins bjp   \n",
       "85090                                                                                                                                                     real interest rates were jacked rrr the great economist sabotage the recovery under modi   \n",
       "134418                                                                                                                                                                                        look how modi boy runs away form live program hahaha   \n",
       "5761                                                                                                                                   aap comes pawar central will give lakh per annam evary indian who did nat voted modi new young arvind yojna   \n",
       "\n",
       "                                                                                                                                                                                                                                       after  \n",
       "52589                                                                                                                   live west bengal banerjee said that drdo achievements are being used for publicity mongering modi follow for updates  \n",
       "5826                                                                                                                                                                        modi for ambani adani rahul for garib choice yours choose wisely  \n",
       "112920  our kids financial sector assured give gold free every newly married couple after submitting marriage certificate once our kids get elected they can order all jewellery shops india give gold free newly married modi created funds  \n",
       "154860                     problem south bangalore constituency late kumar wife doing lot social work every voter cofusionall want vote modi central but due humiliation done her and for sake humanity please justice her you wonderful man  \n",
       "52769                                                                                                    hii everyonetoday the proud moment for usindia becomes nation enter elite space power club with antisatellite weapon announces modi  \n",
       "75481                                                                      for consecutive time narendra modi will launch the bjp poll campaign for lok sabha elections from jammu the city temples addressing election rally dhoomi akhnoor  \n",
       "20922                                       delhi who has seats begging party for alliance which has seats party with seats rejecting that offer varanasi loksabha seat against modi gives cong cong gives gives bsp bsp candidate joins bjp  \n",
       "85090                                                                                                                                                   real interest rates were jacked the great economist sabotage the recovery under modi  \n",
       "134418                                                                                                                                                                                         look how modi boy runs away form live program  \n",
       "5761                                                                                                                                 comes pawar central will give lakh per annam evary indian who did nat voted modi new young arvind yojna  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\"before\": affected_sample, \"after\": df[\"clean_ours\"]})\n",
    "\n",
    "changed = comparison[comparison[\"before\"] != comparison[\"after\"]]\n",
    "changed.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e183f-9359-4a84-b212-0cb3d09fc0ed",
   "metadata": {},
   "source": [
    "Let‚Äôs examine whether applying this function has caused any significant changes to the DataFrame structure, given that it can convert entire cells to `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f55e97e4-bbda-41ad-9438-3547b0f0e973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  string\n",
      " 1   category    162969 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faeeb6c",
   "metadata": {},
   "source": [
    "The DataFrame structure is intact, but `clean_ours` now has 27 fewer non-null values, reflecting cells that were entirely filtered out as spam as seen below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "13e7f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21806</th>\n",
       "      <td>bjpmpsubramanianswamyiamchowkidarcampaignpmmodi</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21855</th>\n",
       "      <td>terrorfundinghurriyatleaderspropertyseizedhafizsaeedmodigovt</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24148</th>\n",
       "      <td>pmnarendramodirequestsofexservicemanindianarmyhavildarombirsinghsharma9258</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35636</th>\n",
       "      <td>2019</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35866</th>\n",
       "      <td>‚Äç</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35968</th>\n",
       "      <td>whattttttt</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37837</th>\n",
       "      <td>allllll</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40587</th>\n",
       "      <td>1145am</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40977</th>\n",
       "      <td>‚åö1145 ‚ù§</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48127</th>\n",
       "      <td>birthdaaaaaay</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51360</th>\n",
       "      <td>panchattt</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53552</th>\n",
       "      <td>2findia2fwhatpmmodididnottellyouinaddresstonationindiahadachievedasatcapabil</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73958</th>\n",
       "      <td>oops</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77224</th>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83278</th>\n",
       "      <td>jawanshaaaa</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92073</th>\n",
       "      <td>‚Å¶ ‚Å¶ ‚Å¶ ‚Å¶ ‚Å¶ ‚Å¶</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102992</th>\n",
       "      <td>importanthearingsinuktodayoncasesoffugitivevijaymallyaandniravmodi</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103389</th>\n",
       "      <td>ismoditakesganjasaidaamadamiministernotgoodpltoinewsseenpl</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103563</th>\n",
       "      <td>missionshaktipmmodiviolatemodelcodeofconductectodecideontoday</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107944</th>\n",
       "      <td>mmurderer\\noof\\nddemocratic\\niindia</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114693</th>\n",
       "      <td>iindia\\nddwalpment oonly mmodi</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122246</th>\n",
       "      <td>‚Äô  ‚Äô</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136055</th>\n",
       "      <td>sixerrrmodi sixxerrrr</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141136</th>\n",
       "      <td>tooo</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141812</th>\n",
       "      <td>checkoutcccchhhnnnddrrraa\\n</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152943</th>\n",
       "      <td>congressizcommingtakebeefmodikehtahaicowizmotherandbjptakingthemeatofcow</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161347</th>\n",
       "      <td>2019</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          clean_text  \\\n",
       "21806                                bjpmpsubramanianswamyiamchowkidarcampaignpmmodi   \n",
       "21855                   terrorfundinghurriyatleaderspropertyseizedhafizsaeedmodigovt   \n",
       "24148     pmnarendramodirequestsofexservicemanindianarmyhavildarombirsinghsharma9258   \n",
       "35636                                                                          2019    \n",
       "35866                                                                             ‚Äç    \n",
       "35968                                                                    whattttttt    \n",
       "37837                                                                        allllll   \n",
       "40587                                                                         1145am   \n",
       "40977                                                                        ‚åö1145 ‚ù§   \n",
       "48127                                                                birthdaaaaaay     \n",
       "51360                                                                     panchattt    \n",
       "53552   2findia2fwhatpmmodididnottellyouinaddresstonationindiahadachievedasatcapabil   \n",
       "73958                                                                           oops   \n",
       "77224                                                                                  \n",
       "83278                                                                   jawanshaaaa    \n",
       "92073                                                                   ‚Å¶ ‚Å¶ ‚Å¶ ‚Å¶ ‚Å¶ ‚Å¶    \n",
       "102992            importanthearingsinuktodayoncasesoffugitivevijaymallyaandniravmodi   \n",
       "103389                    ismoditakesganjasaidaamadamiministernotgoodpltoinewsseenpl   \n",
       "103563                 missionshaktipmmodiviolatemodelcodeofconductectodecideontoday   \n",
       "107944                                          mmurderer\\noof\\nddemocratic\\niindia    \n",
       "114693                                                iindia\\nddwalpment oonly mmodi   \n",
       "122246                                                                        ‚Äô  ‚Äô     \n",
       "136055                                                         sixerrrmodi sixxerrrr   \n",
       "141136                                                                         tooo    \n",
       "141812                                                   checkoutcccchhhnnnddrrraa\\n   \n",
       "152943     congressizcommingtakebeefmodikehtahaicowizmotherandbjptakingthemeatofcow    \n",
       "161347                                                                          2019   \n",
       "\n",
       "       clean_ours  \n",
       "21806        <NA>  \n",
       "21855        <NA>  \n",
       "24148        <NA>  \n",
       "35636        <NA>  \n",
       "35866        <NA>  \n",
       "35968        <NA>  \n",
       "37837        <NA>  \n",
       "40587        <NA>  \n",
       "40977        <NA>  \n",
       "48127        <NA>  \n",
       "51360        <NA>  \n",
       "53552        <NA>  \n",
       "73958        <NA>  \n",
       "77224        <NA>  \n",
       "83278        <NA>  \n",
       "92073        <NA>  \n",
       "102992       <NA>  \n",
       "103389       <NA>  \n",
       "103563       <NA>  \n",
       "107944       <NA>  \n",
       "114693       <NA>  \n",
       "122246       <NA>  \n",
       "136055       <NA>  \n",
       "141136       <NA>  \n",
       "141812       <NA>  \n",
       "152943       <NA>  \n",
       "161347       <NA>  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_rows = df[df['clean_ours'].isna()]\n",
    "missing_rows[['clean_text', 'clean_ours']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3dbd4-474c-4d76-9afe-198c4c53c063",
   "metadata": {},
   "source": [
    "## **Post-Cleaning Steps**\n",
    "\n",
    "At some point during the cleaning stage, some entries of the dataset could have been reduced to `NaN` or the empty string `\"\"`, or we could have introduced duplicates again. So, let's call `dropna` and `drop_duplicates` again to finalize the cleaning stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f365bcfa-e44b-46a1-9702-ad36cfcf7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bdd5c44f-32ab-4b34-b7e4-121c2a898c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb4d20",
   "metadata": {},
   "source": [
    "# **3. Preprocessing**\n",
    "\n",
    "> üèóÔ∏è Perhaps swap S3 and S4. Refer to literature on what comes first.\n",
    "\n",
    "This section discusses preprocessing steps for the cleaned data. Because the goal is to analyze the textual sentiments of tweets the following preprocessing steps are needed to provide the Bag of Words model with the relevant information required to get the semantic embeddings of each tweet.\n",
    "\n",
    "Before and after each preprocessing step, we will show 5 random entries in the dataset to show the effects of each preprocessing task.\n",
    "\n",
    "## **Lemmatization**\n",
    "\n",
    "We follow a similar methodology for data cleaning presented in <u>(George & Murugesan, 2024)</u>. We preprocess the dataset entries via lemmatization. We use NLTK for this task using WordNetLemmatizer lemmatization, repectively <u>(Bird & Loper, 2004)</u>. For the lemmatization step, we use the WordNet for English lemmatization and Open Multilingual WordNet version 1.4 for translations and multilingual support which is important for our case since some tweets contain text from Indian Languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a0c3a9b5-b35a-47ca-9ecf-7f950db07395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40695</th>\n",
       "      <td>there‚Äô modi govt there‚Äô only modi</td>\n",
       "      <td>0</td>\n",
       "      <td>there modi govt there only modi</td>\n",
       "      <td>there modi govt there only modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146107</th>\n",
       "      <td>ranjith joins list filmmakers against modi</td>\n",
       "      <td>0</td>\n",
       "      <td>ranjith joins list filmmakers against modi</td>\n",
       "      <td>ranjith join list filmmaker against modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153907</th>\n",
       "      <td>need review for hair\\nwhich one best brown black @ ahmedabad india</td>\n",
       "      <td>1</td>\n",
       "      <td>need review for hair which one best brown black ahmedabad india</td>\n",
       "      <td>need review for hair which one best brown black ahmedabad india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60420</th>\n",
       "      <td>modi announces drdo‚Äô recent achievement his election rally</td>\n",
       "      <td>0</td>\n",
       "      <td>modi announces drdo recent achievement his election rally</td>\n",
       "      <td>modi announces drdo recent achievement his election rally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>why would demobilization lead money modi and ambani not the only one with money</td>\n",
       "      <td>0</td>\n",
       "      <td>why would demobilization lead money modi and ambani not the only one with money</td>\n",
       "      <td>why would demobilization lead money modi and ambani not the only one with money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31169</th>\n",
       "      <td>still modi says its acche din</td>\n",
       "      <td>0</td>\n",
       "      <td>still modi says its acche din</td>\n",
       "      <td>still modi say it acche din</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94694</th>\n",
       "      <td>oooextending last post make that conclusivesee what were they including ndtv trying project the public\\nwhateverjeetega toh modi ‚úå‚úå</td>\n",
       "      <td>0</td>\n",
       "      <td>last post make that conclusivesee what were they including ndtv trying project the public whateverjeetega toh modi</td>\n",
       "      <td>last post make that conclusivesee what were they including ndtv trying project the public whateverjeetega toh modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51972</th>\n",
       "      <td>modi plz check some institutes nehru built\\ndrdo\\ncsir\\nbarc\\napsara\\nincospar isro\\nnpl\\niit\\niist\\niofs\\nongc\\naiims\\niim\\nnit\\nbokaro rourkela steel\\ncdri\\ncbri\\ncecri\\nceeri\\ncftri\\ncgcri\\ncimap\\nclri\\ncmeri\\ncrri\\ncsio\\ncsmcri\\ncazri\\ntoday‚Äô glories are based yesterday‚Äô preperation</td>\n",
       "      <td>0</td>\n",
       "      <td>modi plz check some institutes nehru built drdo csir barc apsara incospar isro npl iofs ongc aiims nit bokaro rourkela steel cdri cbri cecri ceeri cftri cgcri cimap clri cmeri crri csio csmcri cazri today glories are based yesterday preperation</td>\n",
       "      <td>modi plz check some institute nehru built drdo csir barc apsara incospar isro npl iofs ongc aiims nit bokaro rourkela steel cdri cbri cecri ceeri cftri cgcri cimap clri cmeri crri csio csmcri cazri today glory are based yesterday preperation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124696</th>\n",
       "      <td>ignore trolls modi sending them irritate you focus your work looking the impending defeat modi frustrated  happy see inch shrink inch</td>\n",
       "      <td>1</td>\n",
       "      <td>ignore trolls modi sending them irritate you focus your work looking the impending defeat modi frustrated happy see inch shrink inch</td>\n",
       "      <td>ignore troll modi sending them irritate you focus your work looking the impending defeat modi frustrated happy see inch shrink inch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105367</th>\n",
       "      <td>modi meansmaker developed india</td>\n",
       "      <td>1</td>\n",
       "      <td>modi meansmaker developed india</td>\n",
       "      <td>modi meansmaker developed india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                             clean_text  \\\n",
       "40695                                                                                                                                                                                                                                                                there‚Äô modi govt there‚Äô only modi    \n",
       "146107                                                                                                                                                                                                                                                      ranjith joins list filmmakers against modi    \n",
       "153907                                                                                                                                                                                                                              need review for hair\\nwhich one best brown black @ ahmedabad india    \n",
       "60420                                                                                                                                                                                                                                       modi announces drdo‚Äô recent achievement his election rally    \n",
       "3576                                                                                                                                                                                                                    why would demobilization lead money modi and ambani not the only one with money   \n",
       "31169                                                                                                                                                                                                                                                                    still modi says its acche din    \n",
       "94694                                                                                                                                                              oooextending last post make that conclusivesee what were they including ndtv trying project the public\\nwhateverjeetega toh modi ‚úå‚úå    \n",
       "51972   modi plz check some institutes nehru built\\ndrdo\\ncsir\\nbarc\\napsara\\nincospar isro\\nnpl\\niit\\niist\\niofs\\nongc\\naiims\\niim\\nnit\\nbokaro rourkela steel\\ncdri\\ncbri\\ncecri\\nceeri\\ncftri\\ncgcri\\ncimap\\nclri\\ncmeri\\ncrri\\ncsio\\ncsmcri\\ncazri\\ntoday‚Äô glories are based yesterday‚Äô preperation   \n",
       "124696                                                                                                                                                          ignore trolls modi sending them irritate you focus your work looking the impending defeat modi frustrated  happy see inch shrink inch     \n",
       "105367                                                                                                                                                                                                                                                                  modi meansmaker developed india   \n",
       "\n",
       "        category  \\\n",
       "40695          0   \n",
       "146107         0   \n",
       "153907         1   \n",
       "60420          0   \n",
       "3576           0   \n",
       "31169          0   \n",
       "94694          0   \n",
       "51972          0   \n",
       "124696         1   \n",
       "105367         1   \n",
       "\n",
       "                                                                                                                                                                                                                                                  clean_ours  \\\n",
       "40695                                                                                                                                                                                                                        there modi govt there only modi   \n",
       "146107                                                                                                                                                                                                            ranjith joins list filmmakers against modi   \n",
       "153907                                                                                                                                                                                       need review for hair which one best brown black ahmedabad india   \n",
       "60420                                                                                                                                                                                              modi announces drdo recent achievement his election rally   \n",
       "3576                                                                                                                                                                         why would demobilization lead money modi and ambani not the only one with money   \n",
       "31169                                                                                                                                                                                                                          still modi says its acche din   \n",
       "94694                                                                                                                                     last post make that conclusivesee what were they including ndtv trying project the public whateverjeetega toh modi   \n",
       "51972   modi plz check some institutes nehru built drdo csir barc apsara incospar isro npl iofs ongc aiims nit bokaro rourkela steel cdri cbri cecri ceeri cftri cgcri cimap clri cmeri crri csio csmcri cazri today glories are based yesterday preperation   \n",
       "124696                                                                                                                  ignore trolls modi sending them irritate you focus your work looking the impending defeat modi frustrated happy see inch shrink inch   \n",
       "105367                                                                                                                                                                                                                       modi meansmaker developed india   \n",
       "\n",
       "                                                                                                                                                                                                                                               lemmatized  \n",
       "40695                                                                                                                                                                                                                     there modi govt there only modi  \n",
       "146107                                                                                                                                                                                                           ranjith join list filmmaker against modi  \n",
       "153907                                                                                                                                                                                    need review for hair which one best brown black ahmedabad india  \n",
       "60420                                                                                                                                                                                           modi announces drdo recent achievement his election rally  \n",
       "3576                                                                                                                                                                      why would demobilization lead money modi and ambani not the only one with money  \n",
       "31169                                                                                                                                                                                                                         still modi say it acche din  \n",
       "94694                                                                                                                                  last post make that conclusivesee what were they including ndtv trying project the public whateverjeetega toh modi  \n",
       "51972   modi plz check some institute nehru built drdo csir barc apsara incospar isro npl iofs ongc aiims nit bokaro rourkela steel cdri cbri cecri ceeri cftri cgcri cimap clri cmeri crri csio csmcri cazri today glory are based yesterday preperation  \n",
       "124696                                                                                                                ignore troll modi sending them irritate you focus your work looking the impending defeat modi frustrated happy see inch shrink inch  \n",
       "105367                                                                                                                                                                                                                    modi meansmaker developed india  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized\"] = df[\"clean_ours\"].map(lemmatizer)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42589219-d005-4ab3-b825-cccb7fa6d663",
   "metadata": {},
   "source": [
    "## **Stop Word Removal**\n",
    "\n",
    "After lemmatization, we may now remove the stop words present in the dataset. The stopword removal _needs_ to be after lemmatization since this step requires all words to be reduces to their base dictionary form, and the `stopword_set` only considers base dictionary forms of the stopwords.\n",
    "\n",
    "**stopwords.** For stop words removal, we refer to the English stopwords dataset defined in NLTK and Wolfram Mathematica <u>(Bird & Loper, 2004; Wolfram Research, 2015)</u>. However, since the task is sentiment analysis, words that invoke polarity, intensification, and negation are important. Words like \"not\" and \"okay\" are commonly included as stopwords. Therefore, the stopwords from [nltk,mathematica] are manually adjusted to only include stopwords that invoke neutrality, examples are \"after\", \"when\", and \"you.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4a91231f-c21d-41da-9296-7b8607f9cd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85309</th>\n",
       "      <td>please follow this thread schemes modi  thanks for information</td>\n",
       "      <td>1</td>\n",
       "      <td>please follow this thread schemes modi thanks for information</td>\n",
       "      <td>please follow thread scheme modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630</th>\n",
       "      <td>this anchor taught tough lesson about modi jis work live show that hell never forget  shop guy says hell vote for modi and then the anchor tried mock gst passerby gives him good gyana about gst benefits must watch</td>\n",
       "      <td>1</td>\n",
       "      <td>this anchor taught tough lesson about modi jis work live show that hell never forget shop guy says hell vote for modi and then the anchor tried mock gst passerby gives him good gyana about gst benefits must watch</td>\n",
       "      <td>anchor taught tough lesson about modi ji work live never forget shop guy vote modi anchor mock gst passerby good gyana about gst benefit watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32423</th>\n",
       "      <td>bengaluru bjp mla says some incompetent candidates party banking modis popularity</td>\n",
       "      <td>-1</td>\n",
       "      <td>bengaluru bjp mla says some incompetent candidates party banking modis popularity</td>\n",
       "      <td>bengaluru bjp mla incompetent candidate party banking modis popularity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136111</th>\n",
       "      <td>her response happiness and more and more modis blessings</td>\n",
       "      <td>1</td>\n",
       "      <td>her response happiness and more and more modis blessings</td>\n",
       "      <td>response happiness more more modis blessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131969</th>\n",
       "      <td>voodoo vindaloo whoodunit</td>\n",
       "      <td>0</td>\n",
       "      <td>voodoo vindaloo whoodunit</td>\n",
       "      <td>voodoo vindaloo whoodunit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41379</th>\n",
       "      <td>modi wave wont felt telugu states professionals the hans india ‚ö°assembly elections</td>\n",
       "      <td>0</td>\n",
       "      <td>modi wave wont felt telugu states professionals the hans india assembly elections</td>\n",
       "      <td>modi wave felt telugu state professional han india assembly election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33092</th>\n",
       "      <td>finance minister arun jaitley tuesday said that there only one gamechanger the 2019 lok sabha elections and that none other than prime minister narendra modi</td>\n",
       "      <td>1</td>\n",
       "      <td>finance minister arun jaitley tuesday said that there only one gamechanger the lok sabha elections and that none other than prime minister narendra modi</td>\n",
       "      <td>finance minister arun jaitley tuesday only gamechanger lok sabha election prime minister narendra modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70692</th>\n",
       "      <td>unable accept the facts all opposition that modi becoming famous daybyday the crusial election time what things happening not created better oppositions accept the defeat pool avoid their mental agony</td>\n",
       "      <td>1</td>\n",
       "      <td>unable accept the facts all opposition that modi becoming famous daybyday the crusial election time what things happening not created better oppositions accept the defeat pool avoid their mental agony</td>\n",
       "      <td>unable accept fact all opposition modi famous daybyday crusial election time thing happening created better opposition accept defeat pool avoid mental agony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149895</th>\n",
       "      <td>leader kcr believes masood azhar pak govt not indian army their claimsits abt modibjp kcr good that trust indian army matram sense leader ledu</td>\n",
       "      <td>1</td>\n",
       "      <td>leader kcr believes masood azhar pak govt not indian army their claimsits abt modibjp kcr good that trust indian army matram sense leader ledu</td>\n",
       "      <td>leader kcr belief masood azhar pak govt indian army claimsits abt modibjp kcr good trust indian army matram sense leader ledu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39134</th>\n",
       "      <td>there series modi besides movie what else radio series street theaters all over india comic books wah sahab how much more marketing you have any shame you had done some work you wouldnt have required this level marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>there series modi besides movie what else radio series street theaters all over india comic books wah sahab how much more marketing you have any shame you had done some work you wouldnt have required this level marketing</td>\n",
       "      <td>series modi movie radio series street theater all india comic book wah sahab much more marketing shame work required level marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                          clean_text  \\\n",
       "85309                                                                                                                                                                please follow this thread schemes modi  thanks for information    \n",
       "15630         this anchor taught tough lesson about modi jis work live show that hell never forget  shop guy says hell vote for modi and then the anchor tried mock gst passerby gives him good gyana about gst benefits must watch    \n",
       "32423                                                                                                                                             bengaluru bjp mla says some incompetent candidates party banking modis popularity    \n",
       "136111                                                                                                                                                                      her response happiness and more and more modis blessings   \n",
       "131969                                                                                                                                                                                                    voodoo vindaloo whoodunit    \n",
       "41379                                                                                                                                            modi wave wont felt telugu states professionals the hans india ‚ö°assembly elections    \n",
       "33092                                                                  finance minister arun jaitley tuesday said that there only one gamechanger the 2019 lok sabha elections and that none other than prime minister narendra modi   \n",
       "70692                       unable accept the facts all opposition that modi becoming famous daybyday the crusial election time what things happening not created better oppositions accept the defeat pool avoid their mental agony   \n",
       "149895                                                                               leader kcr believes masood azhar pak govt not indian army their claimsits abt modibjp kcr good that trust indian army matram sense leader ledu    \n",
       "39134   there series modi besides movie what else radio series street theaters all over india comic books wah sahab how much more marketing you have any shame you had done some work you wouldnt have required this level marketing   \n",
       "\n",
       "        category  \\\n",
       "85309          1   \n",
       "15630          1   \n",
       "32423         -1   \n",
       "136111         1   \n",
       "131969         0   \n",
       "41379          0   \n",
       "33092          1   \n",
       "70692          1   \n",
       "149895         1   \n",
       "39134          1   \n",
       "\n",
       "                                                                                                                                                                                                                          clean_ours  \\\n",
       "85309                                                                                                                                                                  please follow this thread schemes modi thanks for information   \n",
       "15630           this anchor taught tough lesson about modi jis work live show that hell never forget shop guy says hell vote for modi and then the anchor tried mock gst passerby gives him good gyana about gst benefits must watch   \n",
       "32423                                                                                                                                              bengaluru bjp mla says some incompetent candidates party banking modis popularity   \n",
       "136111                                                                                                                                                                      her response happiness and more and more modis blessings   \n",
       "131969                                                                                                                                                                                                     voodoo vindaloo whoodunit   \n",
       "41379                                                                                                                                              modi wave wont felt telugu states professionals the hans india assembly elections   \n",
       "33092                                                                       finance minister arun jaitley tuesday said that there only one gamechanger the lok sabha elections and that none other than prime minister narendra modi   \n",
       "70692                       unable accept the facts all opposition that modi becoming famous daybyday the crusial election time what things happening not created better oppositions accept the defeat pool avoid their mental agony   \n",
       "149895                                                                                leader kcr believes masood azhar pak govt not indian army their claimsits abt modibjp kcr good that trust indian army matram sense leader ledu   \n",
       "39134   there series modi besides movie what else radio series street theaters all over india comic books wah sahab how much more marketing you have any shame you had done some work you wouldnt have required this level marketing   \n",
       "\n",
       "                                                                                                                                                          lemmatized  \n",
       "85309                                                                                                                               please follow thread scheme modi  \n",
       "15630                 anchor taught tough lesson about modi ji work live never forget shop guy vote modi anchor mock gst passerby good gyana about gst benefit watch  \n",
       "32423                                                                                         bengaluru bjp mla incompetent candidate party banking modis popularity  \n",
       "136111                                                                                                                   response happiness more more modis blessing  \n",
       "131969                                                                                                                                     voodoo vindaloo whoodunit  \n",
       "41379                                                                                           modi wave felt telugu state professional han india assembly election  \n",
       "33092                                                         finance minister arun jaitley tuesday only gamechanger lok sabha election prime minister narendra modi  \n",
       "70692   unable accept fact all opposition modi famous daybyday crusial election time thing happening created better opposition accept defeat pool avoid mental agony  \n",
       "149895                                 leader kcr belief masood azhar pak govt indian army claimsits abt modibjp kcr good trust indian army matram sense leader ledu  \n",
       "39134                           series modi movie radio series street theater all india comic book wah sahab much more marketing shame work required level marketing  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized\"] = df[\"lemmatized\"].map(lambda t: rem_stopwords(t, stopwords_set))\n",
    "df = df.dropna(subset=[\"lemmatized\"])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd19e4-020a-4e3d-9d0f-6187ce4102d0",
   "metadata": {},
   "source": [
    "## **Looking at the DataFrame**\n",
    "\n",
    "After preprocessing, the dataset now contains:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "883b7f78-ba3d-4bad-9969-0a09b067e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      " 3   lemmatized  162942 non-null  object\n",
      "dtypes: int64(1), object(1), string(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54e5b1-3b81-477e-96ee-602c33533a41",
   "metadata": {},
   "source": [
    "Here are 10 randomly picked entries in the dataframe with all columns shown for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "54e069ce-83c3-4769-8914-b442625a6032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109570</th>\n",
       "      <td>modi will back our tab tum chane bhunnaaa aur khana usskae next elections plans banana</td>\n",
       "      <td>0</td>\n",
       "      <td>modi will back our tab tum chane aur khana usskae next elections plans banana</td>\n",
       "      <td>modi back tab tum chane aur khana usskae election plan banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154819</th>\n",
       "      <td>you lack outlook even not accepting good suggestionsyuo are also hopeless this time along with modi</td>\n",
       "      <td>1</td>\n",
       "      <td>you lack outlook even not accepting good suggestionsyuo are also hopeless this time along with modi</td>\n",
       "      <td>lack outlook even accepting good suggestionsyuo hopeless time along modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>from rahul gandhis fake promise today\\nfrom where will bring money this much money india than according him modi government failure and chowkidar chor\\nthan more than this money was india before five years\\nthan why not thought this</td>\n",
       "      <td>-1</td>\n",
       "      <td>from rahul gandhis fake promise today from where will bring money this much money india than according him modi government failure and chowkidar chor than more than this money was india before five years than why not thought this</td>\n",
       "      <td>rahul gandhi fake promise today bring money much money india modi government failure chowkidar chor more money india year thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154668</th>\n",
       "      <td>will most stupid decision fight election from need keep check his strategic team whether they are committed win the election either they want modi once again just saying rethink and get rid sanghis</td>\n",
       "      <td>1</td>\n",
       "      <td>will most stupid decision fight election from need keep check his strategic team whether they are committed win the election either they want modi once again just saying rethink and get rid sanghis</td>\n",
       "      <td>stupid decision fight election need check strategic team committed win election modi just rethink rid sanghis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69331</th>\n",
       "      <td>curious know what this historian eats and drinks daytime may not like one man but understand technical achievements drdo and isro appreciate modi that these guys are exposing themselves will recorded history</td>\n",
       "      <td>-1</td>\n",
       "      <td>curious know what this historian eats and drinks daytime may not like one man but understand technical achievements drdo and isro appreciate modi that these guys are exposing themselves will recorded history</td>\n",
       "      <td>curious historian eats drink daytime like man understand technical achievement drdo isro appreciate modi guy exposing recorded history</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                       clean_text  \\\n",
       "109570                                                                                                                                                    modi will back our tab tum chane bhunnaaa aur khana usskae next elections plans banana    \n",
       "154819                                                                                                                                        you lack outlook even not accepting good suggestionsyuo are also hopeless this time along with modi   \n",
       "3127    from rahul gandhis fake promise today\\nfrom where will bring money this much money india than according him modi government failure and chowkidar chor\\nthan more than this money was india before five years\\nthan why not thought this    \n",
       "154668                                     will most stupid decision fight election from need keep check his strategic team whether they are committed win the election either they want modi once again just saying rethink and get rid sanghis    \n",
       "69331                             curious know what this historian eats and drinks daytime may not like one man but understand technical achievements drdo and isro appreciate modi that these guys are exposing themselves will recorded history   \n",
       "\n",
       "        category  \\\n",
       "109570         0   \n",
       "154819         1   \n",
       "3127          -1   \n",
       "154668         1   \n",
       "69331         -1   \n",
       "\n",
       "                                                                                                                                                                                                                                   clean_ours  \\\n",
       "109570                                                                                                                                                          modi will back our tab tum chane aur khana usskae next elections plans banana   \n",
       "154819                                                                                                                                    you lack outlook even not accepting good suggestionsyuo are also hopeless this time along with modi   \n",
       "3127    from rahul gandhis fake promise today from where will bring money this much money india than according him modi government failure and chowkidar chor than more than this money was india before five years than why not thought this   \n",
       "154668                                  will most stupid decision fight election from need keep check his strategic team whether they are committed win the election either they want modi once again just saying rethink and get rid sanghis   \n",
       "69331                         curious know what this historian eats and drinks daytime may not like one man but understand technical achievements drdo and isro appreciate modi that these guys are exposing themselves will recorded history   \n",
       "\n",
       "                                                                                                                                    lemmatized  \n",
       "109570                                                                           modi back tab tum chane aur khana usskae election plan banana  \n",
       "154819                                                                lack outlook even accepting good suggestionsyuo hopeless time along modi  \n",
       "3127         rahul gandhi fake promise today bring money much money india modi government failure chowkidar chor more money india year thought  \n",
       "154668                           stupid decision fight election need check strategic team committed win election modi just rethink rid sanghis  \n",
       "69331   curious historian eats drink daytime like man understand technical achievement drdo isro appreciate modi guy exposing recorded history  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a64d042-e337-4d55-a6e4-0d065abd2738",
   "metadata": {},
   "source": [
    "## **Tokenization**\n",
    "\n",
    "Since the data cleaning and preprocessing stage is comprehensive, the tokenization step in the BoW model reduces to a simple word-boundary split operation. Each preprocessed entry in the DataFrame is split by spaces. For example, the entry `\"shri narendra modis\"` (entry: 42052) becomes `[\"shri\", \"narendra\", \"modis\"]`. By the end of tokenization, all entries are transformed into arrays of strings.\n",
    "\n",
    "## **Word Bigrams**\n",
    "\n",
    "As noted earlier, modifiers and polarity words are not included in the stopword set. The BoW model constructs a vocabulary containing both unigrams and bigrams. Including bigrams allows the model to capture common word patterns, such as\n",
    "\n",
    "$$\n",
    "\\left\\langle \\texttt{Adj}\\right\\rangle \\left\\langle \\texttt{M} \\mid \\texttt{Pron} \\right\\rangle\n",
    "$$\n",
    "\n",
    "<center>or</center>\n",
    "\n",
    "$$\n",
    "\\left\\langle \\texttt{Adv}\\right\\rangle \\left\\langle \\texttt{V} \\mid \\texttt{Adj} \\mid \\texttt{Adv} \\right\\rangle\n",
    "$$\n",
    "\n",
    "## **Vector Representation**\n",
    "\n",
    "After the stemming and lemmatization steps, each entry can now be represented as a vector using a Bag of Words (BoW) model. We employ scikit-learn's `CountVectorizer`, which provides a ready-to-use implementation of BoW <u>(Pedregosa et al., 2011)</u>.\n",
    "\n",
    "A comparison of other traditional vector representations are discussed in [this appendix](#appendix:-comparison-of-traditional-vectorization-techniques).\n",
    "Words with modifiers have the modifiers directly attached, enabling subsequent models to capture the concept of modification fully. Consequently, after tokenization and bigram construction, the vocabulary size can grow up to $O(n^2)$, where $n$ is the number of unique tokens.\n",
    "\n",
    "**minimum document frequency constraint:** Despite cleaning and spam removal, some tokens remain irrelevant or too rare. To address this, a minimum document frequency constraint is applied: $\\texttt{min\\_df} = 10$, meaning a token must appear in at least 10 documents to be included in the BoW vocabulary. This reduces noise and ensures the model focuses on meaningful terms.\n",
    "\n",
    "---\n",
    "\n",
    "These parameters of the BoW model are encapsulated in the `BagOfWordsModel` class. The class definition is available in [this appendix](#appendix:-BagOfWordsModel-class-definition).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7bfba459-6837-4481-929c-ef5ee023b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erin\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bow = BagOfWordsModel(df[\"lemmatized\"], 10)\n",
    "\n",
    "# some sanity checks\n",
    "assert (\n",
    "    bow.matrix.shape[0] == df.shape[0]\n",
    "), \"number of rows in the matrix DOES NOT matches the number of documents\"\n",
    "assert bow.sparsity, \"the sparsity is TOO HIGH, something went wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75919779-1b56-4bec-9662-90afc11e1356",
   "metadata": {},
   "source": [
    "The error above is normal, recall that our tokenization step essentially reduced into an array split step. With this, we need to set the `tokenizer` function attribute of the `BagOfWordsModel` to not use its default tokenization pattern. That causes this warning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf5220-712f-4af3-9e2e-0fc3753f5cb1",
   "metadata": {},
   "source": [
    "### **Model Metrics**\n",
    "\n",
    "To get an idea of the model, we will now look at its shape and sparsity, with shape being the number of documents and tokens present in the model. While sparsity refers to the number of elements in a matrix that are zero, calculating how sparse or varied the words are in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0246d-899e-4bb6-957a-75419316197a",
   "metadata": {},
   "source": [
    "The resulting vector has a shape of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b6a5b688-b636-4320-bf22-e508a97aa862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162942, 30386)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc081f2-0630-4a0c-a40a-aeddcdfc8fb8",
   "metadata": {},
   "source": [
    "The first entry of the pair is the number of documents (the ones that remain after all the data cleaning and preprocessing steps) and the second entry is the number of tokens (or unique words in the vocabulary).\n",
    "\n",
    "The resulting model has a sparsity of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4fd01aa7-4842-4473-b410-591fd47983f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995039539872171"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - bow.sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33434da",
   "metadata": {},
   "source": [
    "The model is 99.95% sparse, meaning the tweets often do not share the same words leading to a large vocabulary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3277d-2106-490d-a304-8ff6e0780fd5",
   "metadata": {},
   "source": [
    "Now, looking at the most frequent and least frequent terms in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "10dd4551-90d0-4795-9303-1118fcc058c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['modi', 'india', 'ha', 'all', 'people', 'bjp', 'like', 'congress',\n",
       "       'narendra', 'only', 'election', 'narendra modi', 'vote', 'govt',\n",
       "       'about', 'indian', 'year', 'time', 'country', 'just', 'modis',\n",
       "       'more', 'nation', 'rahul', 'even', 'government', 'party', 'power',\n",
       "       'gandhi', 'minister', 'leader', 'good', 'modi govt', 'need',\n",
       "       'modi ha', 'space', 'work', 'prime', 'money', 'credit', 'sir',\n",
       "       'pakistan', 'back', 'day', 'today', 'prime minister', 'scientist',\n",
       "       'never', 'support', 'win'], dtype=object)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_frequencies = np.asarray((bow.matrix > 0).sum(axis=0)).flatten()\n",
    "freq_order = np.argsort(doc_frequencies)[::-1]\n",
    "bow.feature_names[freq_order[:50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c2f23-6494-4d41-937f-19664010b138",
   "metadata": {},
   "source": [
    "We see that the main talking point of the Tweets, which hovers around Indian politics with keywords like \"modi\", \"india\", and \"bjp\". For additional context, \"bjp\" referes to the _Bharatiya Janata Party_ which is a conservative political party in India, and one of the two major Indian political parties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b775494-3472-4089-8d86-e24346616155",
   "metadata": {},
   "source": [
    "Now, looking at the least popular words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "35f91a0d-dae1-41af-9f92-c06a973ebbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['healthy democracy', 'ha mass', 'ha separate', 'ha shifted',\n",
       "       'hat drdo', 'about defeat', 'yet ha', 'yes more', 'yes narendra',\n",
       "       'hatred people', 'ha requested', 'hate more', 'hate much',\n",
       "       'hatemonger', 'hater gonna', 'heal', 'hazaribagh', 'head drdo',\n",
       "       'sleep night', 'abinandan', 'able provide', 'able speak',\n",
       "       'able vote', 'youth need', 'youth power', 'hai isliye', 'hai chor',\n",
       "       'handy', 'hand narendra', 'hand people', 'hae', 'ha withdrawn',\n",
       "       'happens credit', 'happier', 'bhaiyo', 'socha', 'social political',\n",
       "       'social security', 'biased journalist', 'big congratulation',\n",
       "       'sirmodi', 'bhutan', 'bhi berozgar', 'bhi mumkin', 'skta',\n",
       "       'bhatt aditi', 'bhi aur', 'slamming', 'smart modi', 'slogan blame'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.feature_names[freq_order[-50:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5478a6-4ff0-4d64-a329-11278fe4e60a",
   "metadata": {},
   "source": [
    "We still see that the themes mentioned in the most frequent terms are still present in this subset. Although, more filler or non-distinct words do appear more often, like \"photos\", \"soft\" and \"types\".\n",
    "\n",
    "But the present of words like \"reelection\" and \"wars\" still point to this subset still being relevant to the main theme of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb530e2",
   "metadata": {},
   "source": [
    "# **4 exploratory data analysis**\n",
    "\n",
    "This section discusses the exploratory data analysis conducted on the dataset after cleaning.\n",
    "\n",
    "> Notes from Zhean: <br>\n",
    "> From manual checking via OpenRefine, there are a total of 162972. `df.info()` should have the same result post-processing.\n",
    "> Furthermore, there should be two columns, `clean_text` (which is a bit of a misnormer since it is still dirty) contains the Tweets (text data). The second column is the `category` which contains the sentiment of the Tweet and is a tribool (1 positive, 0 neutral or indeterminate, and -1 for negative).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ad21e-cb7b-4d91-87f9-a14c15ec8365",
   "metadata": {},
   "source": [
    "# **references**\n",
    "\n",
    "Bird, S., & Loper, E. (2004, July). NLTK: The natural language toolkit. _Proceedings of the ACL Interactive Poster and Demonstration Sessions_, 214‚Äì217. https://aclanthology.org/P04-3031/\n",
    "\n",
    "El-Demerdash, A. A., Hussein, S. E., & Zaki, J. F. W. (2021). Course evaluation based on deep learning and SSA hyperparameters optimization. _Computers, Materials & Continua, 71_(1), 941‚Äì959. https://doi.org/10.32604/cmc.2022.021839\n",
    "\n",
    "George, M., & Murugesan, R. (2024). Improving sentiment analysis of financial news headlines using hybrid Word2Vec-TFIDF feature extraction technique. _Procedia Computer Science, 244_, 1‚Äì8.\n",
    "\n",
    "Hussein, S. (2021). _Twitter sentiments dataset_. Mendeley.\n",
    "\n",
    "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. _Journal of Machine Learning Research, 12_, 2825‚Äì2830.\n",
    "\n",
    "Rani, D., Kumar, R., & Chauhan, N. (2022, October). Study and comparison of vectorization techniques used in text classification. In _2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)_ (pp. 1‚Äì6). IEEE.\n",
    "\n",
    "Wolfram Research. (2015). _DeleteStopwords_. https://reference.wolfram.com/language/ref/DeleteStopwords.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7173f9-2c8d-4a5a-af3d-95761f09463a",
   "metadata": {},
   "source": [
    "# **appendix: `clean` wrapper function definition**\n",
    "\n",
    "Below is the definition of the `clean` wrapper function that encapsulates all internal functions used in the cleaning pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fef8310b-aad6-4e48-80e6-e891c17a0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m clean(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m clean(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    This is the main function for data cleaning (i.e., it calls all the cleaning functions in the prescribed order).\u001b[39m\n",
      "\n",
      "\u001b[33m    This function should be used as a first-class function in a map.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: The string entry from a DataFrame column.\u001b[39m\n",
      "\u001b[33m    * stopwords: stopword dictionary.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Clean string\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;66;03m# cleaning on the base string\u001b[39;00m\n",
      "    text = normalize(text)\n",
      "    text = rem_punctuation(text)\n",
      "    text = rem_numbers(text)\n",
      "    text = collapse_whitespace(text)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "clean??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d116f4e-672a-4f3e-aa7d-1ee96d62d86b",
   "metadata": {},
   "source": [
    "# **appendix: `find_spam_and_empty` wrapper function definition**\n",
    "\n",
    "Below is the definition of the `find_spam_and_empty` wrapper function that encapsulates all internal functions for the spam detection algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "434da366-1648-4abd-8af0-ad4d4cd53d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m find_spam_and_empty(text: str, min_length: int = \u001b[32m3\u001b[39m) -> str | \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m find_spam_and_empty(text: str, min_length: int = \u001b[32m3\u001b[39m) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Filter out empty text and unintelligible/spammy unintelligible substrings in the text.\u001b[39m\n",
      "\n",
      "\u001b[33m    Spammy substrings:\u001b[39m\n",
      "\u001b[33m    - Shorter than min_length\u001b[39m\n",
      "\u001b[33m    - Containing non-alphabetic characters\u001b[39m\n",
      "\u001b[33m    - Consisting of a repeated substring (e.g., 'aaaaaa', 'ababab', 'abcabcabc')\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: input string.\u001b[39m\n",
      "\u001b[33m    * min_length: minimum length of word to keep.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m        Cleaned string, or None if empty after filtering.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    cleaned_tokens = []\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;28;01min\u001b[39;00m text.split():\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(t) < min_length:\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m re.search(\u001b[33mr\"(.)\\1{2,}\"\u001b[39m, t):\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        min_diversity = \u001b[32m0.3\u001b[39m + (\u001b[32m0.1\u001b[39m * min(len(t), \u001b[32m10\u001b[39m) / \u001b[32m10\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(set(t)) / len(t) < min_diversity:\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m re.match(\u001b[33mr\"^(.+)\\1+\"\u001b[39m, t):\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        cleaned_tokens.append(t)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\" \"\u001b[39m.join(cleaned_tokens) \u001b[38;5;28;01mif\u001b[39;00m cleaned_tokens \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "find_spam_and_empty??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f63c6-670f-42b1-8195-3c8156b2f4be",
   "metadata": {},
   "source": [
    "# **appendix: comparison of traditional vectorization techniques**\n",
    "\n",
    "Traditional vectorization techniques include BoW and Term Frequency-Inverse Document Frequency (TF-IDF). TF-IDF weights each word based on its frequency in a document and its rarity across the corpus, reducing the impact of common words. BoW, in contrast, simply counts word occurrences without considering corpus-level frequency. In this project, BoW was chosen because stopwords were already removed during preprocessing, and the dataset is domain-specific <u>(Rani et al., 2022)</u>. In such datasets, frequent words are often meaningful domain keywords, so scaling them down (as TF-IDF would) could reduce the importance of these key terms in the feature representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e651fa3-b1f3-4e71-9092-018bbabc07dc",
   "metadata": {},
   "source": [
    "# **appendix: `BagOfWordsModel` class definition**\n",
    "\n",
    "Below is the definition of the `BagOfWordsModel` class that encapsulates the desired parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0a9c57a0-98b3-40cb-8cd4-a1d9b30eb6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m BagOfWordsModel(texts: Iterable[str], min_freq: int | float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mSource:\u001b[39m        \n",
      "\u001b[38;5;28;01mclass\u001b[39;00m BagOfWordsModel:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    A Bag-of-Words representation for a text corpus.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Attributes\u001b[39m\n",
      "\u001b[33m    * matrix (scipy.sparse.csr_matrix): The document-term matrix of word counts.\u001b[39m\n",
      "\u001b[33m    * feature_names (list[str]): List of feature names corresponding to the matrix columns.\u001b[39m\n",
      "\u001b[33m    *\u001b[39m\n",
      "\u001b[33m    # Usage\u001b[39m\n",
      "\u001b[33m    ```\u001b[39m\n",
      "\u001b[33m    bow = BagOfWordsModel(df[\"lemmatized_str\"])\u001b[39m\n",
      "\u001b[33m    ```\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __init__(self, texts: Iterable[str], min_freq: int | float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Initialize the BagOfWordsModel by fitting the vectorizer to the text corpus. This also filters out tokens\u001b[39m\n",
      "\u001b[33m        that do not appear more than five times in the dataset.\u001b[39m\n",
      "\n",
      "\u001b[33m        This sets its tokenizer to the word boundary tokenizer since the input, at this point, **should** be\u001b[39m\n",
      "\u001b[33m        cleaned and processed text.\u001b[39m\n",
      "\n",
      "\u001b[33m        This also uses both unigrams and bigrams, hence, at the worst case its space complexity is O(n^2).\u001b[39m\n",
      "\n",
      "\u001b[33m        # Parameters\u001b[39m\n",
      "\u001b[33m        * texts: An iterable of cleaned text documents.\u001b[39m\n",
      "\u001b[33m        * min_freq: Determines the document frequency of a token for it to appear in the model.\u001b[39m\n",
      "\u001b[33m        Can be a type of int (i.e., the token must appear min_freq number of times in the document)\u001b[39m\n",
      "\u001b[33m        or a float (i.e, token must be in min_freq% of the documents)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        vectorizer = CountVectorizer(\n",
      "            min_df=min_freq \u001b[38;5;28;01mif\u001b[39;00m min_freq \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m,\n",
      "            tokenizer=str.split,    \u001b[38;5;66;03m# Use str.split instead of lambda\u001b[39;00m\n",
      "            lowercase=\u001b[38;5;28;01mFalse\u001b[39;00m,        \u001b[38;5;66;03m# Don't lowercase\u001b[39;00m\n",
      "            ngram_range=(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m),      \u001b[38;5;66;03m# Unigrams and bigrams\u001b[39;00m\n",
      "        )\n",
      "        self.matrix = vectorizer.fit_transform(texts)\n",
      "        self.feature_names = vectorizer.get_feature_names_out()\n",
      "        self.vectorizer = vectorizer\n",
      "        self.sparsity = self.matrix.nnz / (self.matrix.shape[\u001b[32m0\u001b[39m] * self.matrix.shape[\u001b[32m1\u001b[39m])\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m transform_sentence(self, sentence: str):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Returns the embedding of the sentence using the BoW matrix.\u001b[39m\n",
      "\n",
      "\u001b[33m        # Parameters:\u001b[39m\n",
      "\u001b[33m        * sentence: Cleaned sentence to vectorize.\u001b[39m\n",
      "\n",
      "\u001b[33m        # Returns\u001b[39m\n",
      "\u001b[33m        Sentence embedding.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.vectorizer.transform([sentence])\n",
      "\u001b[31mFile:\u001b[39m           c:\\users\\erin\\documents\\github\\stintsy-order-of-erin\\lib\\bag_of_words.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "BagOfWordsModel??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
