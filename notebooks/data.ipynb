{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44906e4e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Twitter Posts\n",
    "\n",
    "<!-- Notebook name goes here -->\n",
    "<center><b>Notebook: Data Description, Cleaning, Exploratory Data Analysis, and Preprocessing</b></center>\n",
    "<br>\n",
    "\n",
    "**by**: Stephen Borja, Justin Ching, Erin Chua, and Zhean Ganituen.\n",
    "\n",
    "**dataset**: Hussein, S. (2021). Twitter Sentiments Dataset [Dataset]. Mendeley. https://doi.org/10.17632/Z9ZW7NT5H2.1\n",
    "\n",
    "**motivation**: Every minute, social media users generate a large influx of textual data on live events. Performing sentiment analysis on this data provides a real-time view of public perception, enabling quick insights into the general population‚Äôs opinions and reactions.\n",
    "\n",
    "**goal**: By the end of the project, our goal is to create and compare supervised learning algorithms for sentiment analysis.\n",
    "\n",
    "### **dataset description**\n",
    "\n",
    "The Twitter Sentiments Dataset is a dataset that contains nearly 163k tweets from Twitter. The time period of when these were collected is unknown, but it was published to Mendeley Data on May 14, 2021 by Sherif Hussein of Mansoura University.\n",
    "\n",
    "Tweets were extracted using the Twitter API, but the specifics of how the tweets were selected are unmentioned. The tweets are mostly English with a mix of some Hindi words for code-switching <u>(El-Demerdash., 2021)</u>. All of them seem to be talking about the political state of India. Most tweets mention Narendra Modi, the current Prime Minister of India.\n",
    "\n",
    "Each tweet was assigned a label using TextBlob's sentiment analysis <u>(El‚ÄëDemerdash, Hussein, & Zaki, 2021)</u>, which assigns labels automatically.\n",
    "\n",
    "Twitter_Data\n",
    "\n",
    "- **`clean_text`**: The tweet's text\n",
    "- **`category`**: The tweet's sentiment category\n",
    "\n",
    "What each row and column represents: `each row represents one tweet.` <br>\n",
    "Number of observations: `162,980`\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) Code-switching is the practice of alternating between two languages $L_1$ (the native language) and $L_2$ (the source language) in a conversation. In this context, the code-switching is done to appear more casual since the conversation is done via Twitter (now, X).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47491b2f",
   "metadata": {},
   "source": [
    "## **1. Project Set-up**\n",
    "\n",
    "We set the global imports for the projects (ensure these are installed via uv and is part of the environment). Furthermore, load the dataset here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "d7578d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:01:26.803271Z",
     "start_time": "2025-06-17T14:01:26.567527Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Use lib directory\n",
    "sys.path.append(os.path.abspath(\"../lib\"))\n",
    "\n",
    "# Imports from lib files\n",
    "from janitor import *\n",
    "from lemmatize import lemmatizer\n",
    "from boilerplate import stopwords_set\n",
    "from bag_of_words import BagOfWordsModel\n",
    "\n",
    "# Pandas congiruation\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Load raw data file\n",
    "df = pd.read_csv(\"../data/Twitter_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ec446",
   "metadata": {},
   "source": [
    "## **2. Data Cleaning**\n",
    "\n",
    "This section discusses the methodology for data cleaning.\n",
    "\n",
    "As to not waste computational time, a preliminary step is to ensure that no `NaN` or duplicate entries exist before the cleaning steps. Everytime we call a `.drop()` function, we will show the result of `info()` to see how many entries are filtered out.\n",
    "\n",
    "Let's first drop the `NaN` entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "28609dbc-1d51-4bba-b64c-a570c9ac4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8865f85-09ec-4528-8b69-4f39ec72ae26",
   "metadata": {},
   "source": [
    "Now, remove the duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "452f1167-41cd-49a9-a328-8311f1567071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b98d6d",
   "metadata": {},
   "source": [
    "We also ensure that all the values in the `category` column are within the range of [-1, 0, 1], which represent the three sentiments, namely, negative, neutral, and positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "c9f17c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225e3f7",
   "metadata": {},
   "source": [
    "Then remove any values outside of the provided range to keep the data consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "a7fa1384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3659      1.0\n",
       "117064    1.0\n",
       "136016    0.0\n",
       "72881     1.0\n",
       "132625    1.0\n",
       "110168    0.0\n",
       "50209     1.0\n",
       "46837     1.0\n",
       "55919     1.0\n",
       "41572     0.0\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"category\"].isin([-1, 0, 1])]\n",
    "df[\"category\"].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a31de7",
   "metadata": {},
   "source": [
    "By converting a CSV file into a DataFrame, pandas automatically defaults numeric values to `float64` when it encounters decimals or `NaN` types. Text of `str` type get inferred and loaded into a `object` as the generic type for strings. We can check the dtype of our DataFrame column through `.info()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a5f1374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d93c9",
   "metadata": {},
   "source": [
    "First we convert column `category` from `float64` to `int64` after dropping `NaN` rows and removing any values outside of [-1, 0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "fe43fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Series name: category\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "162969 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"category\"] = df[\"category\"].astype(int)\n",
    "df[\"category\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "4b01cbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22847     0\n",
       "17788     0\n",
       "7755     -1\n",
       "60042     1\n",
       "87280     1\n",
       "58364    -1\n",
       "47166     0\n",
       "60971     1\n",
       "11434     0\n",
       "114741   -1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a8070",
   "metadata": {},
   "source": [
    "Next, we convert column `clean_string` from `object` type into the pandas defined `string` type for consistency and better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "edc2bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Series name: clean_text\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "162969 non-null  string\n",
      "dtypes: string(1)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"clean_text\"] = df[\"clean_text\"].astype(\"string\")\n",
    "df[\"clean_text\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "3d21b06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[0, \"clean_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec33f2-9967-4458-878b-79b697ec9e4e",
   "metadata": {},
   "source": [
    "## **Main Cleaning Pipeline**\n",
    "\n",
    "We follow a similar methodology for data cleaning presented in (George & Murugesan, 2024).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a22cb",
   "metadata": {},
   "source": [
    "### **Normalization**\n",
    "\n",
    "Due to the nature of the text being tweets, we noticed a prevalence in the use of emojis and accented characters as seen in the samples below. Although in a real-world context these do serve as a form of emotional expression, it provides no relevance towards _textual_ sentiment analysis, thus we normalize the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "e06f520c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114886                    declares modi breaks thread communal harmony karnatakaso rahul will contest election from karnataka contrary earlier decisi√≥n kerala addition amethi \n",
       "74639     stop write dont know about 2012 congress party has capability test this fire but today have capability leader like narendra modi who can take any difficult decisi√≥n \n",
       "50461                              v√≠a not against any particular nation demonstration our own technology former drdo chief saraswat tells cnnnews18s follow live updates here \n",
       "59831                                                                                                      india shoots down satellite test modi hails arrival space power v√≠a \n",
       "23047                                                                     unlikely titfortat istan darpok nikamm√© babus chorriforri crook donnie bullyfears strength look jago \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with accented characters\n",
    "accented_char_rows = df[df[\"clean_text\"].str.contains(r\"√â|√©|√Å|√°|√≥|√ì|√∫|√ö|√≠|√ç\")]\n",
    "accented_char_rows[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "ff6b5d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21900     look this modi landmark example good governance ‚úåÔ∏è global political leaders and business houses use modi‚Äô reforms bench mark best practices ‡§ø‡§ú‡§Ø‡§∏‡§Ç‡•ç‡§™‡§∏‡§≠‡§æ \n",
       "61261                                               life congressi\\nends with nehru Ôø£Ôø£Ôø£Ôø£Ôø£Ôø£Ôø£Ôø£Ôø£Ôø£Ôø£ dont blame nehru modiji did nehru did not modi\\nÔºøÔºøÔºøÔºøÔºøÔºøÔºøÔºøÔºøÔºøÔºø \\ ‚Ä¢‚Ä¢ \n",
       "125459                                                                                                                                   ‚ú® ‚Äúchaukidar‚Äù ‚ú®\\n‚ú® join \n",
       "162951                                                                                                                           now confirmed modi supporter ‚ò∫‚ò∫‚ò∫\n",
       "46706                              congrats isro and drdo for their great work and years research but what exactly did modi this why are people praising him ‚Äç‚ôÇÔ∏è \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with emojis\n",
    "rows_with_emojis = df[df[\"clean_text\"].str.contains(r\"[\\u263a-\\U0001f645]\", regex=True)]\n",
    "rows_with_emojis[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb30dbd",
   "metadata": {},
   "source": [
    "The first function is the `normalize` function, it normalizes the text input to ASCII-only characters (say, \"c√≥mo est√°s\" becomes \"como estas\") and lowercased alphabetic symbols. The dataset contains Unicode characters (e.g., emojis and accented characters) which the function replaces to the empty string (`''`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "b0425f96-ed91-41ca-9033-5bb53f14c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m normalize(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m normalize(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Normalize text from a pandas entry to ASCII-only lowercase characters. Hence, this removes Unicode characters with no ASCII\u001b[39m\n",
      "\u001b[33m    equivalent (e.g., emojis and CJKs).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    ASCII-normalized text containing only lowercase letters.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    normalize(\"¬øC√≥mo est√°s?\")\u001b[39m\n",
      "\u001b[33m    $ 'como estas?'\u001b[39m\n",
      "\n",
      "\u001b[33m    normalize(\" hahahaha HUY! Kamusta üòÖ Mayaman $$$ ka na ba?\")\u001b[39m\n",
      "\u001b[33m    $ ' hahahaha huy! kamusta  mayaman $$$ ka na ba?'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    normalized = unicodedata.normalize(\u001b[33m\"NFKD\"\u001b[39m, text)\n",
      "    ascii_text = normalized.encode(\u001b[33m\"ascii\"\u001b[39m, \u001b[33m\"ignore\"\u001b[39m).decode(\u001b[33m\"ascii\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m ascii_text.lower()\n",
      "\u001b[31mFile:\u001b[39m      a:\\college\\year 3\\term 2\\stintsy\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "normalize??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc84505-f974-442b-8763-62bd20d729ea",
   "metadata": {},
   "source": [
    "### **Punctuations**\n",
    "\n",
    "Punctuations are part of natural speech and reading to provide a sense of structure, clarity, and tone to sentences, but in the context of a classification study punctuations do not add much information to the sentiment of a message. The sentiment of `i hate you!` and `i hate you` are going to be the same despite the punctuation mark `!` being used to accentuate the sentiment. We can see a sample of rows with punctations below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "3e026e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144450                                                                                                        the truth nehru makes modi look petty minded crass can‚Äô think thing that modi has done over the last years that made feel proud indian\n",
       "162676                                                                                                                                                opposition‚Äô show strength andhra pradesh‚Äô vizag can opposition unite against modi more videos \n",
       "139450                                                                                                                                                                                    modi took stoneage and rahulji aims for golden era\\n‡§æ‡•á‡§∂‡§¨‡§ö‡§æ\n",
       "72535     ‚Äô shame rajdeep how you find ways target modi for every achievements his and his government tried give spin while scientists giving credit very due but loyalty rest only with one family more trust left with journalists and especially \n",
       "9613                                                                                                                                                       jaitley calls rahul gandhi‚Äô income promise ‚Äòbluff‚Äô says modi has already given more poor \n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows with punctuation\n",
    "rows_with_punc = df[df[\"clean_text\"].str.contains(r\"[^\\w\\s]\")]\n",
    "rows_with_punc[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b3a75",
   "metadata": {},
   "source": [
    "The function `rem_punctuation` replaces all punctuations and special characters into an empty string (`''`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "62aa658b-8dbd-4533-af84-cbb221571835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m rem_punctuation(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m rem_punctuation(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Removes the punctuations. This function simply replaces all punctuation marks and special characters\u001b[39m\n",
      "\u001b[33m    to the empty string. Hence, for symbols enclosed by whitespace, the whitespace are not collapsed to a single whitespace\u001b[39m\n",
      "\u001b[33m    (for more information, see the examples).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the punctuation removed.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    rem_punctuation(\"this word $$ has two spaces after it!\")\u001b[39m\n",
      "\u001b[33m    $ 'this word  has two spaces after it'\u001b[39m\n",
      "\n",
      "\u001b[33m    rem_punctuation(\"these!words@have$no%space\")\u001b[39m\n",
      "\u001b[33m    $ 'thesewordshavenospace'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(f\"[{re.escape(string.punctuation)}]\", \u001b[33m\"\"\u001b[39m, text)\n",
      "\u001b[31mFile:\u001b[39m      a:\\college\\year 3\\term 2\\stintsy\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rem_punctuation??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47e93e-aa0e-473c-89d5-f30df86815da",
   "metadata": {},
   "source": [
    "### **Numbers**\n",
    "\n",
    "Similar to punctuations, numbers do not add any information to the sentiment of a message as seen in the samples below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "103a4a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146733                                                                                                           its not that easy end article 370 mehbooba mufti hold beer modi\n",
       "27684                                                    would have been the first person criticize joshi was made mhrd 2014 now praising him not because love but hate for modi\n",
       "108020                                            political parties have the polls only meet the expectations voters says modi and says bjp will win more seats than 2014 polls \n",
       "113465                 ‡±ç‡∞ø ‡∞∏‡∞Æ‡∞Ø‡∞Ç‡±ã ‡±Ä‡±Å ‡±ç‡∞ø ‡∞æ‡±Ä‡±Å ‡±ç‡∞ø ‡±Ç‡∞æ ‡∞ø‡±ç‡±ç‡∞ø‡∞Ç‡±á‡±Å 2903 1830 ajay gadde persnol how many jobs did your government provided youth how can you partial towards northern india\n",
       "147838    ppl ppl this not about modi western analysts have been doubting for long time when are successful something they point poverty india ‚Äô set pattern modi came only 2014\n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows that contain numbers\n",
    "rows_with_numbers = df[df[\"clean_text\"].str.contains(r\"\\d\")]\n",
    "rows_with_numbers[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d403d",
   "metadata": {},
   "source": [
    "Hence we defined the `rem_numbers` as a function that replaces all numerical values as an empty string (`''`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "d3a58576-8dd7-4043-a903-41b7cfab88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m rem_numbers(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m rem_numbers(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Removes numbers. This function simply replaces all numerical symbols to the empty string. Hence, for symbols enclosed by\u001b[39m\n",
      "\u001b[33m    whitespace, the whitespace are not collapsed to a single whitespace (for more information, see the examples).\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the numerical symbol removed\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    rem_numbers(\" h3llo, k4must4 k4  n4?\")\u001b[39m\n",
      "\u001b[33m    ' hllo, kmust k  n?'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33mr\"\\d+\"\u001b[39m, \u001b[33m\"\"\u001b[39m, text)\n",
      "\u001b[31mFile:\u001b[39m      a:\\college\\year 3\\term 2\\stintsy\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rem_numbers??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b1491-1821-42b1-a63f-dab941dc003f",
   "metadata": {},
   "source": [
    "### **Whitespace**\n",
    "\n",
    "We also noticed the prevalance of excess whitespaces in between words, as seen in the sample below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "da2c270a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126955                                                                                                                               how important sentence can missed from tweet  killed the democracy its because the state government now got  \n",
       "18357                                                                                    ran away looks like you are smoking something special  changed identity chowkider not \\nanyways where are those lakhs which was being screamed your modi \n",
       "16883                                                                                                                                                                         clearly modi tsunami after balakot strike the very least modi wave  \n",
       "7597      congress was blaming modi that under his govt ppl unemployed now instead bribing poor ppl and make them nakaras lyk just give them jobs mehnat roti khane mein maza hai rishwat khareedi roti mein nahi  khair tumhe samajh nahi aayega \n",
       "26099                                                                                                                               there lack money sirbut the lack loyality the major problem \\nwhich only completed modi  abki baar chokhidar ‚ù§\n",
       "Name: clean_text, dtype: string"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding a sample of rows that contain 2 or more whitespaces in a row\n",
    "rows_with_whitespaces = df[df[\"clean_text\"].str.contains(r\"\\s{2,}\")]\n",
    "rows_with_whitespaces[\"clean_text\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8144d29",
   "metadata": {},
   "source": [
    "Thus, function `collapse_whitespace` collapses all whitespace characters to a single space. Formally, it is a transducer\n",
    "\n",
    "$$\n",
    "\\Box^+ \\mapsto \\Box \\qquad \\text{where the space character is } \\Box\n",
    "$$\n",
    "\n",
    "Informally, it replaces all strings of whitespaces to a single whitespace character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "3823f3bc-0a42-473a-8888-a4c06f0659ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m collapse_whitespace(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m collapse_whitespace(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    This collapses whitespace. Here, collapsing means the transduction of all whitespace strings of any\u001b[39m\n",
      "\u001b[33m    length to a whitespace string of unit length (e.g., \"   \" -> \" \"; formally \" \"+ -> \" \").\u001b[39m\n",
      "\n",
      "\u001b[33m    Do not use this function alone, use `clean_and_tokenize()`.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: String entry.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Text with the whitespaces collapsed.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Examples\u001b[39m\n",
      "\u001b[33m    collapse_whitespace(\"  huh,  was.  that!!! \")\u001b[39m\n",
      "\u001b[33m    $ 'huh, was. that!!!'\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33m\" +\"\u001b[39m, \u001b[33m\" \"\u001b[39m, text).strip()\n",
      "\u001b[31mFile:\u001b[39m      a:\\college\\year 3\\term 2\\stintsy\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "collapse_whitespace??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd388a-e397-4100-a6df-a971db6f85df",
   "metadata": {},
   "source": [
    "To seamlessly call all these cleaning functions, we have the `clean` function that acts as a container that calls these separate components. The definition of this wrapper function is quite long, see [this appendix](#appendix:-clean-wrapper-function-definition) for its definition.\n",
    "\n",
    "We can now clean the dataset and store it in a new column named `clean_ours` (to differentiate it with the, still dirty, column `clean_text` from the dataset author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "6d4ea4d2-e8fe-437f-a46f-a18b1b34f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  string\n",
      " 1   category    162969 non-null  int64 \n",
      " 2   clean_ours  162969 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 9.0 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"clean_ours\"] = df[\"clean_text\"].map(clean).astype(\"string\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf28ad",
   "metadata": {},
   "source": [
    "To confirm if the character cleaning worked, we can check for the differences between `clean_text` and `clean_ours` from the filtered rows below and compare the differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "12724f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71349</th>\n",
       "      <td>wont say much read below please\\nanswer people are largely criticizing rahul gandhis minimum income plan 72000 but why they did not say anything narendra modis demonitisation when most the black money did not return anonymous</td>\n",
       "      <td>1</td>\n",
       "      <td>wont say much read below please\\nanswer people are largely criticizing rahul gandhis minimum income plan but why they did not say anything narendra modis demonitisation when most the black money did not return anonymous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98592</th>\n",
       "      <td>income tax raids karnataka kannadigas must blame jawaharlal nehru not modi for bringing income tax act 1961</td>\n",
       "      <td>0</td>\n",
       "      <td>income tax raids karnataka kannadigas must blame jawaharlal nehru not modi for bringing income tax act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84576</th>\n",
       "      <td>were joking yesterday about surgical strikes space well heres modi campaign rally today ‚Äúland sky space government has shown courage conduct surgical strike all spheres‚Äù</td>\n",
       "      <td>0</td>\n",
       "      <td>were joking yesterday about surgical strikes space well heres modi campaign rally today land sky space government has shown courage conduct surgical strike all spheres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90594</th>\n",
       "      <td>congress claims credit for mission shakti congress era defence minister says had idea ‚Äì opindia news via</td>\n",
       "      <td>0</td>\n",
       "      <td>congress claims credit for mission shakti congress era defence minister says had idea opindia news via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154801</th>\n",
       "      <td>modi govt says terror and talks can‚Äô together you you not accept this precondition valid and fair</td>\n",
       "      <td>1</td>\n",
       "      <td>modi govt says terror and talks can together you you not accept this precondition valid and fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113329</th>\n",
       "      <td>modi mentions how the strict laws his govt against economic offenders are reaping resultsproperties worth rs14000crore belonging vijaymallya have been seized even though total liability against him stands rs9000crore says</td>\n",
       "      <td>1</td>\n",
       "      <td>modi mentions how the strict laws his govt against economic offenders are reaping resultsproperties worth rscrore belonging vijaymallya have been seized even though total liability against him stands rscrore says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108588</th>\n",
       "      <td>should vote modi for orop implemented after years 35000 crores disbursed crore veterans</td>\n",
       "      <td>0</td>\n",
       "      <td>should vote modi for orop implemented after years crores disbursed crore veterans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139770</th>\n",
       "      <td>obviously the ministers like giriraj singh anant hegdektaka every day comments against muslims christians the communal politician become naturally communities will appeal against bjp ‡§æ‡•á‡§∂‡§¨‡§ö‡§æ</td>\n",
       "      <td>1</td>\n",
       "      <td>obviously the ministers like giriraj singh anant hegdektaka every day comments against muslims christians the communal politician become naturally communities will appeal against bjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69959</th>\n",
       "      <td>now the debris left over the space will cleaned under the swatch bharat mission  modi sarkar hai toh mumkin hai bai</td>\n",
       "      <td>0</td>\n",
       "      <td>now the debris left over the space will cleaned under the swatch bharat mission modi sarkar hai toh mumkin hai bai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39354</th>\n",
       "      <td>modi‚Äô skill india raga‚Äô kill india</td>\n",
       "      <td>0</td>\n",
       "      <td>modi skill india raga kill india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                clean_text  \\\n",
       "71349   wont say much read below please\\nanswer people are largely criticizing rahul gandhis minimum income plan 72000 but why they did not say anything narendra modis demonitisation when most the black money did not return anonymous    \n",
       "98592                                                                                                                          income tax raids karnataka kannadigas must blame jawaharlal nehru not modi for bringing income tax act 1961   \n",
       "84576                                                           were joking yesterday about surgical strikes space well heres modi campaign rally today ‚Äúland sky space government has shown courage conduct surgical strike all spheres‚Äù    \n",
       "90594                                                                                                                            congress claims credit for mission shakti congress era defence minister says had idea ‚Äì opindia news via    \n",
       "154801                                                                                                                                   modi govt says terror and talks can‚Äô together you you not accept this precondition valid and fair   \n",
       "113329      modi mentions how the strict laws his govt against economic offenders are reaping resultsproperties worth rs14000crore belonging vijaymallya have been seized even though total liability against him stands rs9000crore says    \n",
       "108588                                                                                                                                            should vote modi for orop implemented after years 35000 crores disbursed crore veterans    \n",
       "139770                                       obviously the ministers like giriraj singh anant hegdektaka every day comments against muslims christians the communal politician become naturally communities will appeal against bjp ‡§æ‡•á‡§∂‡§¨‡§ö‡§æ   \n",
       "69959                                                                                                                  now the debris left over the space will cleaned under the swatch bharat mission  modi sarkar hai toh mumkin hai bai   \n",
       "39354                                                                                                                                                                                                   modi‚Äô skill india raga‚Äô kill india   \n",
       "\n",
       "        category  \\\n",
       "71349          1   \n",
       "98592          0   \n",
       "84576          0   \n",
       "90594          0   \n",
       "154801         1   \n",
       "113329         1   \n",
       "108588         0   \n",
       "139770         1   \n",
       "69959          0   \n",
       "39354          0   \n",
       "\n",
       "                                                                                                                                                                                                                         clean_ours  \n",
       "71349   wont say much read below please\\nanswer people are largely criticizing rahul gandhis minimum income plan but why they did not say anything narendra modis demonitisation when most the black money did not return anonymous  \n",
       "98592                                                                                                                        income tax raids karnataka kannadigas must blame jawaharlal nehru not modi for bringing income tax act  \n",
       "84576                                                       were joking yesterday about surgical strikes space well heres modi campaign rally today land sky space government has shown courage conduct surgical strike all spheres  \n",
       "90594                                                                                                                        congress claims credit for mission shakti congress era defence minister says had idea opindia news via  \n",
       "154801                                                                                                                             modi govt says terror and talks can together you you not accept this precondition valid and fair  \n",
       "113329         modi mentions how the strict laws his govt against economic offenders are reaping resultsproperties worth rscrore belonging vijaymallya have been seized even though total liability against him stands rscrore says  \n",
       "108588                                                                                                                                            should vote modi for orop implemented after years crores disbursed crore veterans  \n",
       "139770                                       obviously the ministers like giriraj singh anant hegdektaka every day comments against muslims christians the communal politician become naturally communities will appeal against bjp  \n",
       "69959                                                                                                            now the debris left over the space will cleaned under the swatch bharat mission modi sarkar hai toh mumkin hai bai  \n",
       "39354                                                                                                                                                                                              modi skill india raga kill india  "
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_rows = df[\n",
    "    df[\"clean_text\"].str.contains(r\"\\s{2,}|\\d|[^\\w\\s]|[\\u263a-\\U0001f645]|[√â√©√Å√°√≥√ì√∫√ö√≠√ç]\")\n",
    "]\n",
    "example_rows.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94256624",
   "metadata": {},
   "source": [
    "We are now finished with basic text cleaning, but the data cleaning does not end here. Given that the text is sourced from Twitter, it includes characteristics, such as spam and informal expressions, which are not addressed by basic cleaning methods. As a result, we move on to further cleaning tailored to the nature of Twitter data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110683a-3879-452e-9d2f-50c4af4e0ad6",
   "metadata": {},
   "source": [
    "### **Spam, Expressions, Onomatopoeia, etc.**\n",
    "\n",
    "Since the domain of the corpus is Twitter, spam (e.g., `bbbb`), expressions (e.g., `bruhhhh`), and onomatopoeia (e.g., `hahahaha`) may become an issue by the vector representation step. Hence we employed a simple rule-based spam removal algorithm.\n",
    "\n",
    "We remove words in the string that contains the same letter or substring thrice and consecutively. These were done using regular expressions:\n",
    "\n",
    "$$\n",
    "\\text{same\\_char\\_thrice} := (.)\\textbackslash1^{\\{2,\\}}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\text{same\\_substring\\_twice} := (.^+)\\textbackslash1^+\n",
    "$$\n",
    "\n",
    "Furthermore, we also remove any string that has a length less than three, since these are either stopwords (that weren't detected in the stopword removal stage) or more spam.\n",
    "\n",
    "Finally, we employ adaptive character diversity threshold for the string $s$.\n",
    "\n",
    "$$\n",
    "\\frac{\\texttt{\\#\\_unique\\_chars}(s)}{|s|} < 0.3 + \\left(\\frac{0.1 \\cdot \\text{min}(|s|, 10)}{10}\\right)\n",
    "$$\n",
    "\n",
    "It calculates the diversity of characters in a string; if the string repeats the same character alot, we expect it to be unintelligible or useless, hence we remove the string.\n",
    "\n",
    "The definition of this wrapper function is quite long, see its definition in [this appendix](#appendix:-find_spam_and_empty-wrapper-function-definition).\n",
    "\n",
    "Let's first look at a random sample of 10 entries from the dataset that will be modified by the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "9015aea8-b6f6-4408-b027-f9c79cf7d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121729                                                                                        accused just like accused bibi and vice versa bilawal accuse modi yaar and then nazriyati and now again have stuck deal accused isnt accuse pak really\n",
       "12236                                                                                                          you are just aaptardmind you also played role creating chaos that brought modi power and now you are crying against your own creation\n",
       "136123                                                                            month remaining for ssc rrb fci other competitive exam guys keep away form yogi modi rahul gandhi whatsapp instagram before the exam otherwise you know the result\n",
       "74552                                                                                                                                              suppose this happening and suddnly mpdi enters the hall all chants modi modi modi modi hahahhahah\n",
       "111591    not conviction they knew writing the wall the anti corruption movement rise modi and after modi was announced candidate they became pro modi its they are opportunists thats okay prob when ppl say zeerepublic are pro bjppro nationalist\n",
       "92314                                                                 mean its all good say good things about your religion and ideology everyone does that but should have some basis facts koi modi marketing campaign nahi hai mann mein aaya pel\n",
       "54063                                                                                                                                                  its that cant survive another five year modi motherjaat swineis retweeting aatankistans tweet\n",
       "8347                                                                                                                                                                       god our bbc news google sorry for narendra modi images top criminals list\n",
       "2441                                                                                                                                                                              how aaj tak and media creates anti modi voices must watch aktk via\n",
       "144833                                                                                                                                question for modi and sitharaman why couldnt the iafs su fighters engage intruding paf fs therein lies scandal\n",
       "Name: clean_ours, dtype: string"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected = df[df[\"clean_ours\"].apply(spam_affected)]\n",
    "affected_sample = affected[\"clean_ours\"].sample(10)\n",
    "affected_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e75f3f-6619-47b8-9b73-5d3d9fa38fbc",
   "metadata": {},
   "source": [
    "Let's now call this function on the `clean_ours` column of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "7ac69746-f471-4a66-9292-c2b363d12de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_ours\"] = df[\"clean_ours\"].map(find_spam_and_empty).astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfddca4",
   "metadata": {},
   "source": [
    "To confirm if the function was able to do remove all the spammy substrings, we can check `before` and `after` and compare their differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "afc3e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92314</th>\n",
       "      <td>mean its all good say good things about your religion and ideology everyone does that but should have some basis facts koi modi marketing campaign nahi hai mann mein aaya pel</td>\n",
       "      <td>mean its all good say good things about your religion and ideology everyone does that but should have some basis facts koi modi marketing campaign nahi hai mann mein pel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54063</th>\n",
       "      <td>its that cant survive another five year modi motherjaat swineis retweeting aatankistans tweet</td>\n",
       "      <td>its that cant survive another five year modi motherjaat swineis retweeting tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121729</th>\n",
       "      <td>accused just like accused bibi and vice versa bilawal accuse modi yaar and then nazriyati and now again have stuck deal accused isnt accuse pak really</td>\n",
       "      <td>accused just like accused and vice versa bilawal accuse modi yaar and then nazriyati and now again have stuck deal accused isnt accuse pak really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>how aaj tak and media creates anti modi voices must watch aktk via</td>\n",
       "      <td>how tak and media creates anti modi voices must watch aktk via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144833</th>\n",
       "      <td>question for modi and sitharaman why couldnt the iafs su fighters engage intruding paf fs therein lies scandal</td>\n",
       "      <td>question for modi and sitharaman why couldnt the iafs fighters engage intruding paf therein lies scandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12236</th>\n",
       "      <td>you are just aaptardmind you also played role creating chaos that brought modi power and now you are crying against your own creation</td>\n",
       "      <td>you are just you also played role creating chaos that brought modi power and now you are crying against your own creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136123</th>\n",
       "      <td>month remaining for ssc rrb fci other competitive exam guys keep away form yogi modi rahul gandhi whatsapp instagram before the exam otherwise you know the result</td>\n",
       "      <td>month remaining for fci other competitive exam guys keep away form yogi modi rahul gandhi whatsapp instagram before the exam otherwise you know the result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111591</th>\n",
       "      <td>not conviction they knew writing the wall the anti corruption movement rise modi and after modi was announced candidate they became pro modi its they are opportunists thats okay prob when ppl say zeerepublic are pro bjppro nationalist</td>\n",
       "      <td>not conviction they knew writing the wall the anti corruption movement rise modi and after modi was announced candidate they became pro modi its they are opportunists thats okay prob when say zeerepublic are pro bjppro nationalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74552</th>\n",
       "      <td>suppose this happening and suddnly mpdi enters the hall all chants modi modi modi modi hahahhahah</td>\n",
       "      <td>suppose this happening and suddnly mpdi enters the hall all chants modi modi modi modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>god our bbc news google sorry for narendra modi images top criminals list</td>\n",
       "      <td>god our news google sorry for narendra modi images top criminals list</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            before  \\\n",
       "92314                                                               mean its all good say good things about your religion and ideology everyone does that but should have some basis facts koi modi marketing campaign nahi hai mann mein aaya pel   \n",
       "54063                                                                                                                                                its that cant survive another five year modi motherjaat swineis retweeting aatankistans tweet   \n",
       "121729                                                                                      accused just like accused bibi and vice versa bilawal accuse modi yaar and then nazriyati and now again have stuck deal accused isnt accuse pak really   \n",
       "2441                                                                                                                                                                            how aaj tak and media creates anti modi voices must watch aktk via   \n",
       "144833                                                                                                                              question for modi and sitharaman why couldnt the iafs su fighters engage intruding paf fs therein lies scandal   \n",
       "12236                                                                                                        you are just aaptardmind you also played role creating chaos that brought modi power and now you are crying against your own creation   \n",
       "136123                                                                          month remaining for ssc rrb fci other competitive exam guys keep away form yogi modi rahul gandhi whatsapp instagram before the exam otherwise you know the result   \n",
       "111591  not conviction they knew writing the wall the anti corruption movement rise modi and after modi was announced candidate they became pro modi its they are opportunists thats okay prob when ppl say zeerepublic are pro bjppro nationalist   \n",
       "74552                                                                                                                                            suppose this happening and suddnly mpdi enters the hall all chants modi modi modi modi hahahhahah   \n",
       "8347                                                                                                                                                                     god our bbc news google sorry for narendra modi images top criminals list   \n",
       "\n",
       "                                                                                                                                                                                                                                         after  \n",
       "92314                                                                mean its all good say good things about your religion and ideology everyone does that but should have some basis facts koi modi marketing campaign nahi hai mann mein pel  \n",
       "54063                                                                                                                                                         its that cant survive another five year modi motherjaat swineis retweeting tweet  \n",
       "121729                                                                                       accused just like accused and vice versa bilawal accuse modi yaar and then nazriyati and now again have stuck deal accused isnt accuse pak really  \n",
       "2441                                                                                                                                                                            how tak and media creates anti modi voices must watch aktk via  \n",
       "144833                                                                                                                                question for modi and sitharaman why couldnt the iafs fighters engage intruding paf therein lies scandal  \n",
       "12236                                                                                                                you are just you also played role creating chaos that brought modi power and now you are crying against your own creation  \n",
       "136123                                                                              month remaining for fci other competitive exam guys keep away form yogi modi rahul gandhi whatsapp instagram before the exam otherwise you know the result  \n",
       "111591  not conviction they knew writing the wall the anti corruption movement rise modi and after modi was announced candidate they became pro modi its they are opportunists thats okay prob when say zeerepublic are pro bjppro nationalist  \n",
       "74552                                                                                                                                                   suppose this happening and suddnly mpdi enters the hall all chants modi modi modi modi  \n",
       "8347                                                                                                                                                                     god our news google sorry for narendra modi images top criminals list  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\"before\": affected_sample, \"after\": df[\"clean_ours\"]})\n",
    "\n",
    "changed = comparison[comparison[\"before\"] != comparison[\"after\"]]\n",
    "changed.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e183f-9359-4a84-b212-0cb3d09fc0ed",
   "metadata": {},
   "source": [
    "Let‚Äôs examine whether applying this function has caused any significant changes to the DataFrame structure, given that it can convert entire cells to `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "f55e97e4-bbda-41ad-9438-3547b0f0e973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162969 non-null  string\n",
      " 1   category    162969 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 9.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faeeb6c",
   "metadata": {},
   "source": [
    "The DataFrame structure is intact, but `clean_ours` now has 27 fewer non-null values, reflecting cell that were entirely filtered out as spam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3dbd4-474c-4d76-9afe-198c4c53c063",
   "metadata": {},
   "source": [
    "## **Post-Cleaning Steps**\n",
    "\n",
    "At some point during the cleaning stage, some entries of the dataset could have been reduced to `NaN` or the empty string `\"\"`, or we could have introduced duplicates again. So, let's call `dropna` and `drop_duplicates` again to finalize the cleaning stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "f365bcfa-e44b-46a1-9702-ad36cfcf7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "bdd5c44f-32ab-4b34-b7e4-121c2a898c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      "dtypes: int64(1), string(2)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb4d20",
   "metadata": {},
   "source": [
    "# **3. Preprocessing**\n",
    "\n",
    "> üèóÔ∏è Perhaps swap S3 and S4. Refer to literature on what comes first.\n",
    "\n",
    "This section discusses preprocessing steps for the cleaned data. Because the goal is to analyze the textual sentiments of tweets the following preprocessing steps are needed to provide the Bag of Words model with the relevant information required to get the semantic embeddings of each tweet.\n",
    "\n",
    "Before and after each preprocessing step, we will show 5 random entries in the dataset to show the effects of each preprocessing task.\n",
    "\n",
    "## **Lemmatization**\n",
    "\n",
    "We follow a similar methodology for data cleaning presented in <u>(George & Murugesan, 2024)</u>. We preprocess the dataset entries via lemmatization. We use NLTK for this task using WordNetLemmatizer lemmatization, repectively <u>(Bird & Loper, 2004)</u>. For the lemmatization step, we use the WordNet for English lemmatization and Open Multilingual WordNet version 1.4 for translations and multilingual support which is important for our case since some tweets contain text from Indian Languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "a0c3a9b5-b35a-47ca-9ecf-7f950db07395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106289</th>\n",
       "      <td>wait for modis 2nd term the desperation will conveyed accordingly</td>\n",
       "      <td>0</td>\n",
       "      <td>wait for modis term the desperation will conveyed accordingly</td>\n",
       "      <td>wait for modis term the desperation will conveyed accordingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48662</th>\n",
       "      <td>the bjp spot slipping from 240 200 now hear back towards 160180 type number leading indicators that happening modi assassination plots timesnow nitin gadkari making statements</td>\n",
       "      <td>-1</td>\n",
       "      <td>the bjp spot slipping from now hear back towards type number leading indicators that happening modi plots timesnow nitin gadkari making statements</td>\n",
       "      <td>the bjp spot slipping from now hear back towards type number leading indicator that happening modi plot timesnow nitin gadkari making statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107500</th>\n",
       "      <td>the failed promise every village ranked the bottom usagetopopulation ratio along with tanzania with only oneinfour indians using the internet according 2018 report</td>\n",
       "      <td>-1</td>\n",
       "      <td>the failed promise every village ranked the bottom usagetopopulation ratio along with tanzania with only oneinfour indians using the internet according report</td>\n",
       "      <td>the failed promise every village ranked the bottom usagetopopulation ratio along with tanzania with only oneinfour indian using the internet according report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75969</th>\n",
       "      <td>india shot down one its satellites space with antisatellite missile wednesday prime minister narendra modi said hailing the countrys first test such technology major breakthrough that establishes space power\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>india shot down one its satellites space with antisatellite missile wednesday prime minister narendra modi said hailing the countrys first test such technology major breakthrough that establishes space power</td>\n",
       "      <td>india shot down one it satellite space with antisatellite missile wednesday prime minister narendra modi said hailing the country first test such technology major breakthrough that establishes space power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138071</th>\n",
       "      <td>all these pakistani lover anti india fake agenda gajwa hind behind making film fool nation became faud baji money destroy india make another pakistan modi bunker saving nation they scare how suxese besharm gandi nali keede</td>\n",
       "      <td>-1</td>\n",
       "      <td>all these pakistani lover anti india fake agenda gajwa hind behind making film fool nation became faud baji money destroy india make another pakistan modi bunker saving nation they scare how suxese besharm gandi nali keede</td>\n",
       "      <td>all these pakistani lover anti india fake agenda gajwa hind behind making film fool nation became faud baji money destroy india make another pakistan modi bunker saving nation they scare how suxese besharm gandi nali keede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17787</th>\n",
       "      <td>modi totally messed the economy will remembered the history for wasteful expenditures like demonetisation statue makingsight seeing and spending thousands crores public money for improving his imaage</td>\n",
       "      <td>0</td>\n",
       "      <td>modi totally messed the economy will remembered the history for wasteful expenditures like demonetisation statue makingsight seeing and spending thousands crores public money for improving his imaage</td>\n",
       "      <td>modi totally messed the economy will remembered the history for wasteful expenditure like demonetisation statue makingsight seeing and spending thousand crore public money for improving his imaage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100422</th>\n",
       "      <td>modi bashing can demonising him has become thing agar aap yeah nahi karte log aapko secular nahi mante</td>\n",
       "      <td>0</td>\n",
       "      <td>modi bashing can demonising him has become thing agar yeah nahi karte log secular nahi mante</td>\n",
       "      <td>modi bashing can demonising him ha become thing agar yeah nahi karte log secular nahi mante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154761</th>\n",
       "      <td>good day for banking industry for more mergers future india need less bank but more branches modi hai toh mumkin hai merger years hind modi</td>\n",
       "      <td>1</td>\n",
       "      <td>good day for banking industry for more mergers future india need less bank but more branches modi hai toh mumkin hai merger years hind modi</td>\n",
       "      <td>good day for banking industry for more merger future india need less bank but more branch modi hai toh mumkin hai merger year hind modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64825</th>\n",
       "      <td>modi govt will extol the virtues national security while ignoring crucial component economic security bhumish khudkhudia public policy professional writes</td>\n",
       "      <td>1</td>\n",
       "      <td>modi govt will extol the virtues national security while ignoring crucial component economic security bhumish public policy professional writes</td>\n",
       "      <td>modi govt will extol the virtue national security while ignoring crucial component economic security bhumish public policy professional writes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35756</th>\n",
       "      <td>ask electoral commission modi has nothing now</td>\n",
       "      <td>0</td>\n",
       "      <td>ask electoral commission modi has nothing now</td>\n",
       "      <td>ask electoral commission modi ha nothing now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                            clean_text  \\\n",
       "106289                                                                                                                                                              wait for modis 2nd term the desperation will conveyed accordingly    \n",
       "48662                                                 the bjp spot slipping from 240 200 now hear back towards 160180 type number leading indicators that happening modi assassination plots timesnow nitin gadkari making statements    \n",
       "107500                                                            the failed promise every village ranked the bottom usagetopopulation ratio along with tanzania with only oneinfour indians using the internet according 2018 report    \n",
       "75969                india shot down one its satellites space with antisatellite missile wednesday prime minister narendra modi said hailing the countrys first test such technology major breakthrough that establishes space power\\n   \n",
       "138071  all these pakistani lover anti india fake agenda gajwa hind behind making film fool nation became faud baji money destroy india make another pakistan modi bunker saving nation they scare how suxese besharm gandi nali keede   \n",
       "17787                          modi totally messed the economy will remembered the history for wasteful expenditures like demonetisation statue makingsight seeing and spending thousands crores public money for improving his imaage   \n",
       "100422                                                                                                                         modi bashing can demonising him has become thing agar aap yeah nahi karte log aapko secular nahi mante    \n",
       "154761                                                                                    good day for banking industry for more mergers future india need less bank but more branches modi hai toh mumkin hai merger years hind modi    \n",
       "64825                                                                      modi govt will extol the virtues national security while ignoring crucial component economic security bhumish khudkhudia public policy professional writes    \n",
       "35756                                                                                                                                                                                    ask electoral commission modi has nothing now   \n",
       "\n",
       "        category  \\\n",
       "106289         0   \n",
       "48662         -1   \n",
       "107500        -1   \n",
       "75969          1   \n",
       "138071        -1   \n",
       "17787          0   \n",
       "100422         0   \n",
       "154761         1   \n",
       "64825          1   \n",
       "35756          0   \n",
       "\n",
       "                                                                                                                                                                                                                            clean_ours  \\\n",
       "106289                                                                                                                                                                   wait for modis term the desperation will conveyed accordingly   \n",
       "48662                                                                               the bjp spot slipping from now hear back towards type number leading indicators that happening modi plots timesnow nitin gadkari making statements   \n",
       "107500                                                                  the failed promise every village ranked the bottom usagetopopulation ratio along with tanzania with only oneinfour indians using the internet according report   \n",
       "75969                  india shot down one its satellites space with antisatellite missile wednesday prime minister narendra modi said hailing the countrys first test such technology major breakthrough that establishes space power   \n",
       "138071  all these pakistani lover anti india fake agenda gajwa hind behind making film fool nation became faud baji money destroy india make another pakistan modi bunker saving nation they scare how suxese besharm gandi nali keede   \n",
       "17787                          modi totally messed the economy will remembered the history for wasteful expenditures like demonetisation statue makingsight seeing and spending thousands crores public money for improving his imaage   \n",
       "100422                                                                                                                                    modi bashing can demonising him has become thing agar yeah nahi karte log secular nahi mante   \n",
       "154761                                                                                     good day for banking industry for more mergers future india need less bank but more branches modi hai toh mumkin hai merger years hind modi   \n",
       "64825                                                                                  modi govt will extol the virtues national security while ignoring crucial component economic security bhumish public policy professional writes   \n",
       "35756                                                                                                                                                                                    ask electoral commission modi has nothing now   \n",
       "\n",
       "                                                                                                                                                                                                                            lemmatized  \n",
       "106289                                                                                                                                                                   wait for modis term the desperation will conveyed accordingly  \n",
       "48662                                                                                  the bjp spot slipping from now hear back towards type number leading indicator that happening modi plot timesnow nitin gadkari making statement  \n",
       "107500                                                                   the failed promise every village ranked the bottom usagetopopulation ratio along with tanzania with only oneinfour indian using the internet according report  \n",
       "75969                     india shot down one it satellite space with antisatellite missile wednesday prime minister narendra modi said hailing the country first test such technology major breakthrough that establishes space power  \n",
       "138071  all these pakistani lover anti india fake agenda gajwa hind behind making film fool nation became faud baji money destroy india make another pakistan modi bunker saving nation they scare how suxese besharm gandi nali keede  \n",
       "17787                             modi totally messed the economy will remembered the history for wasteful expenditure like demonetisation statue makingsight seeing and spending thousand crore public money for improving his imaage  \n",
       "100422                                                                                                                                     modi bashing can demonising him ha become thing agar yeah nahi karte log secular nahi mante  \n",
       "154761                                                                                         good day for banking industry for more merger future india need less bank but more branch modi hai toh mumkin hai merger year hind modi  \n",
       "64825                                                                                   modi govt will extol the virtue national security while ignoring crucial component economic security bhumish public policy professional writes  \n",
       "35756                                                                                                                                                                                     ask electoral commission modi ha nothing now  "
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized\"] = df[\"clean_ours\"].map(lemmatizer)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42589219-d005-4ab3-b825-cccb7fa6d663",
   "metadata": {},
   "source": [
    "## **Stop Word Removal**\n",
    "\n",
    "After lemmatization, we may now remove the stop words present in the dataset. The stopword removal _needs_ to be after lemmatization since this step requires all words to be reduces to their base dictionary form, and the `stopword_set` only considers base dictionary forms of the stopwords.\n",
    "\n",
    "**stopwords.** For stop words removal, we refer to the English stopwords dataset defined in NLTK and Wolfram Mathematica <u>(Bird & Loper, 2004; Wolfram Research, 2015)</u>. However, since the task is sentiment analysis, words that invoke polarity, intensification, and negation are important. Words like \"not\" and \"okay\" are commonly included as stopwords. Therefore, the stopwords from [nltk,mathematica] are manually adjusted to only include stopwords that invoke neutrality, examples are \"after\", \"when\", and \"you.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4a91231f-c21d-41da-9296-7b8607f9cd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106279</th>\n",
       "      <td>every politician promises all these more the fact remains the condition small keeps getting worse with every passing day easy credit available for ambani nirav modi mallaya but not for small businesses who toil their lives away and finally shut shop</td>\n",
       "      <td>1</td>\n",
       "      <td>every politician promises all these more the fact remains the condition small keeps getting worse with every passing day easy credit available for ambani nirav modi mallaya but not for small businesses who toil their lives away and finally shut shop</td>\n",
       "      <td>politician promise all more fact remains condition small worse passing day easy credit available ambani nirav modi mallaya small business toil life away finally shut shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107411</th>\n",
       "      <td>the election commission does not act this violation the model code the railways then modi has ensured india the new north korea ‡§æ‡•á‡§∂‡§¨‡§ö‡§æ</td>\n",
       "      <td>1</td>\n",
       "      <td>the election commission does not act this violation the model code the railways then modi has ensured india the new north korea</td>\n",
       "      <td>election commission doe violation model code railway modi ha ensured india north korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161658</th>\n",
       "      <td>sorry modi sarkar will come with lakh new vacancies 2020</td>\n",
       "      <td>-1</td>\n",
       "      <td>sorry modi sarkar will come with lakh new vacancies</td>\n",
       "      <td>sorry modi sarkar lakh vacancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>modi could too didn‚Äô had the urge spend public money selfglorification also you think the massive political funding comes for free eventually modi has return the favor diverting public funds welfare programs his owners hence bjp cant</td>\n",
       "      <td>1</td>\n",
       "      <td>modi could too didn had the urge spend public money selfglorification also you think the massive political funding comes for free eventually modi has return the favor diverting public funds welfare programs his owners hence bjp cant</td>\n",
       "      <td>modi urge spend public money selfglorification massive political funding free eventually modi ha return favor diverting public fund welfare program owner bjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89989</th>\n",
       "      <td>just type modi and jumlas google and click search and see magic</td>\n",
       "      <td>1</td>\n",
       "      <td>just type modi and jumlas google and click search and see magic</td>\n",
       "      <td>just type modi jumlas google click search magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43989</th>\n",
       "      <td>narendra modi his address nation antisatellite weapon asat successfully targeted live satellite low earth orbit leo part mission shakti</td>\n",
       "      <td>1</td>\n",
       "      <td>narendra modi his address nation antisatellite weapon asat successfully targeted live satellite low earth orbit leo part mission shakti</td>\n",
       "      <td>narendra modi address nation antisatellite weapon asat successfully targeted live satellite low earth orbit leo mission shakti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117436</th>\n",
       "      <td>400 for modi make india super power 2022</td>\n",
       "      <td>1</td>\n",
       "      <td>for modi make india super power</td>\n",
       "      <td>modi india super power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67618</th>\n",
       "      <td>where are the jobs modi where are the jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>where are the jobs modi where are the jobs</td>\n",
       "      <td>job modi job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117732</th>\n",
       "      <td>gandhi vows that elected will remove people with rss links from the bureaucracy‚Äúthey are judges they are professors they went from rssrun crammers pass the civilservice exam rss military academies into the army‚Äù\\n</td>\n",
       "      <td>-1</td>\n",
       "      <td>gandhi vows that elected will remove people with rss links from the bureaucracythey are judges they are professors they went from rssrun crammers pass the civilservice exam rss military academies into the army</td>\n",
       "      <td>gandhi vow elected remove people rss link bureaucracythey judge professor rssrun crammer civilservice exam rss military academy army</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19383</th>\n",
       "      <td>positive campaign always yields better results instead giving 6000month for free modi should introduce universal job guarantee yojna give voters moment pride and usefulness\\niss desh yuva jagrook hai mehanati hai swabhimani hai usko job chahiye bheekh</td>\n",
       "      <td>1</td>\n",
       "      <td>positive campaign always yields better results instead giving month for free modi should introduce universal job guarantee yojna give voters moment pride and usefulness iss desh yuva jagrook hai mehanati hai swabhimani hai usko job chahiye bheekh</td>\n",
       "      <td>positive campaign always yield better result month free modi introduce universal job guarantee yojna voter moment pride usefulness iss desh yuva jagrook hai mehanati hai swabhimani hai usko job chahiye bheekh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                         clean_text  \\\n",
       "106279    every politician promises all these more the fact remains the condition small keeps getting worse with every passing day easy credit available for ambani nirav modi mallaya but not for small businesses who toil their lives away and finally shut shop   \n",
       "107411                                                                                                                      the election commission does not act this violation the model code the railways then modi has ensured india the new north korea ‡§æ‡•á‡§∂‡§¨‡§ö‡§æ    \n",
       "161658                                                                                                                                                                                                    sorry modi sarkar will come with lakh new vacancies 2020    \n",
       "5629                     modi could too didn‚Äô had the urge spend public money selfglorification also you think the massive political funding comes for free eventually modi has return the favor diverting public funds welfare programs his owners hence bjp cant    \n",
       "89989                                                                                                                                                                                               just type modi and jumlas google and click search and see magic   \n",
       "43989                                                                                                                       narendra modi his address nation antisatellite weapon asat successfully targeted live satellite low earth orbit leo part mission shakti   \n",
       "117436                                                                                                                                                                                                                     400 for modi make india super power 2022   \n",
       "67618                                                                                                                                                                                                                   where are the jobs modi where are the jobs    \n",
       "117732                                        gandhi vows that elected will remove people with rss links from the bureaucracy‚Äúthey are judges they are professors they went from rssrun crammers pass the civilservice exam rss military academies into the army‚Äù\\n   \n",
       "19383   positive campaign always yields better results instead giving 6000month for free modi should introduce universal job guarantee yojna give voters moment pride and usefulness\\niss desh yuva jagrook hai mehanati hai swabhimani hai usko job chahiye bheekh   \n",
       "\n",
       "        category  \\\n",
       "106279         1   \n",
       "107411         1   \n",
       "161658        -1   \n",
       "5629           1   \n",
       "89989          1   \n",
       "43989          1   \n",
       "117436         1   \n",
       "67618          0   \n",
       "117732        -1   \n",
       "19383          1   \n",
       "\n",
       "                                                                                                                                                                                                                                                       clean_ours  \\\n",
       "106279  every politician promises all these more the fact remains the condition small keeps getting worse with every passing day easy credit available for ambani nirav modi mallaya but not for small businesses who toil their lives away and finally shut shop   \n",
       "107411                                                                                                                            the election commission does not act this violation the model code the railways then modi has ensured india the new north korea   \n",
       "161658                                                                                                                                                                                                        sorry modi sarkar will come with lakh new vacancies   \n",
       "5629                     modi could too didn had the urge spend public money selfglorification also you think the massive political funding comes for free eventually modi has return the favor diverting public funds welfare programs his owners hence bjp cant   \n",
       "89989                                                                                                                                                                                             just type modi and jumlas google and click search and see magic   \n",
       "43989                                                                                                                     narendra modi his address nation antisatellite weapon asat successfully targeted live satellite low earth orbit leo part mission shakti   \n",
       "117436                                                                                                                                                                                                                            for modi make india super power   \n",
       "67618                                                                                                                                                                                                                  where are the jobs modi where are the jobs   \n",
       "117732                                          gandhi vows that elected will remove people with rss links from the bureaucracythey are judges they are professors they went from rssrun crammers pass the civilservice exam rss military academies into the army   \n",
       "19383      positive campaign always yields better results instead giving month for free modi should introduce universal job guarantee yojna give voters moment pride and usefulness iss desh yuva jagrook hai mehanati hai swabhimani hai usko job chahiye bheekh   \n",
       "\n",
       "                                                                                                                                                                                                              lemmatized  \n",
       "106279                                        politician promise all more fact remains condition small worse passing day easy credit available ambani nirav modi mallaya small business toil life away finally shut shop  \n",
       "107411                                                                                                                            election commission doe violation model code railway modi ha ensured india north korea  \n",
       "161658                                                                                                                                                                                    sorry modi sarkar lakh vacancy  \n",
       "5629                                                       modi urge spend public money selfglorification massive political funding free eventually modi ha return favor diverting public fund welfare program owner bjp  \n",
       "89989                                                                                                                                                                    just type modi jumlas google click search magic  \n",
       "43989                                                                                     narendra modi address nation antisatellite weapon asat successfully targeted live satellite low earth orbit leo mission shakti  \n",
       "117436                                                                                                                                                                                            modi india super power  \n",
       "67618                                                                                                                                                                                                       job modi job  \n",
       "117732                                                                              gandhi vow elected remove people rss link bureaucracythey judge professor rssrun crammer civilservice exam rss military academy army  \n",
       "19383   positive campaign always yield better result month free modi introduce universal job guarantee yojna voter moment pride usefulness iss desh yuva jagrook hai mehanati hai swabhimani hai usko job chahiye bheekh  "
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemmatized\"] = df[\"lemmatized\"].map(lambda t: rem_stopwords(t, stopwords_set))\n",
    "df = df.dropna(subset=[\"lemmatized\"])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd19e4-020a-4e3d-9d0f-6187ce4102d0",
   "metadata": {},
   "source": [
    "## **Looking at the DataFrame**\n",
    "\n",
    "After preprocessing, the dataset now contains:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "883b7f78-ba3d-4bad-9969-0a09b067e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162942 entries, 0 to 162979\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   clean_text  162942 non-null  string\n",
      " 1   category    162942 non-null  int64 \n",
      " 2   clean_ours  162942 non-null  string\n",
      " 3   lemmatized  162942 non-null  object\n",
      "dtypes: int64(1), object(1), string(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54e5b1-3b81-477e-96ee-602c33533a41",
   "metadata": {},
   "source": [
    "Here are 10 randomly picked entries in the dataframe with all columns shown for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "54e069ce-83c3-4769-8914-b442625a6032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_ours</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62203</th>\n",
       "      <td>did you see his face rahul gandhi scoffs after modis address rahul congress should celebrate along with the nation rather than sulk grudging that the proud acheivement took place ndas tenure</td>\n",
       "      <td>1</td>\n",
       "      <td>did you see his face rahul gandhi scoffs after modis address rahul congress should celebrate along with the nation rather than sulk grudging that the proud acheivement took place ndas tenure</td>\n",
       "      <td>face rahul gandhi scoff modis address rahul congress celebrate along nation rather sulk grudging proud acheivement place ndas tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116917</th>\n",
       "      <td>will scrap the niti aayog and replace with lean planning commission voted power tweets president updates</td>\n",
       "      <td>0</td>\n",
       "      <td>will scrap the niti and replace with lean planning commission voted power tweets president updates</td>\n",
       "      <td>scrap niti replace lean planning commission voted power tweet president update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75246</th>\n",
       "      <td>very happy that india became the 4th space power world thanks modi support our scientist for doing this</td>\n",
       "      <td>1</td>\n",
       "      <td>very happy that india became the space power world thanks modi support our scientist for doing this</td>\n",
       "      <td>very happy india space power modi support scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46221</th>\n",
       "      <td>jindabad  congratulations successfully testing indias first missile har har modi\\nghar ghar</td>\n",
       "      <td>1</td>\n",
       "      <td>jindabad congratulations successfully testing indias first missile har har modi ghar ghar</td>\n",
       "      <td>jindabad congratulation successfully testing india missile har har modi ghar ghar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99336</th>\n",
       "      <td>why this not used varanasi modi fight there</td>\n",
       "      <td>0</td>\n",
       "      <td>why this not used varanasi modi fight there</td>\n",
       "      <td>varanasi modi fight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            clean_text  \\\n",
       "62203   did you see his face rahul gandhi scoffs after modis address rahul congress should celebrate along with the nation rather than sulk grudging that the proud acheivement took place ndas tenure   \n",
       "116917                                                                                       will scrap the niti aayog and replace with lean planning commission voted power tweets president updates    \n",
       "75246                                                                                          very happy that india became the 4th space power world thanks modi support our scientist for doing this   \n",
       "46221                                                                                                    jindabad  congratulations successfully testing indias first missile har har modi\\nghar ghar     \n",
       "99336                                                                                                                                                      why this not used varanasi modi fight there   \n",
       "\n",
       "        category  \\\n",
       "62203          1   \n",
       "116917         0   \n",
       "75246          1   \n",
       "46221          1   \n",
       "99336          0   \n",
       "\n",
       "                                                                                                                                                                                            clean_ours  \\\n",
       "62203   did you see his face rahul gandhi scoffs after modis address rahul congress should celebrate along with the nation rather than sulk grudging that the proud acheivement took place ndas tenure   \n",
       "116917                                                                                              will scrap the niti and replace with lean planning commission voted power tweets president updates   \n",
       "75246                                                                                              very happy that india became the space power world thanks modi support our scientist for doing this   \n",
       "46221                                                                                                        jindabad congratulations successfully testing indias first missile har har modi ghar ghar   \n",
       "99336                                                                                                                                                      why this not used varanasi modi fight there   \n",
       "\n",
       "                                                                                                                                  lemmatized  \n",
       "62203   face rahul gandhi scoff modis address rahul congress celebrate along nation rather sulk grudging proud acheivement place ndas tenure  \n",
       "116917                                                        scrap niti replace lean planning commission voted power tweet president update  \n",
       "75246                                                                                    very happy india space power modi support scientist  \n",
       "46221                                                      jindabad congratulation successfully testing india missile har har modi ghar ghar  \n",
       "99336                                                                                                                    varanasi modi fight  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a64d042-e337-4d55-a6e4-0d065abd2738",
   "metadata": {},
   "source": [
    "## **Tokenization**\n",
    "\n",
    "Since the data cleaning and preprocessing stage is comprehensive, the tokenization step in the BoW model reduces to a simple word-boundary split operation. Each preprocessed entry in the DataFrame is split by spaces. For example, the entry `\"shri narendra modis\"` (entry: 42052) becomes `[\"shri\", \"narendra\", \"modis\"]`. By the end of tokenization, all entries are transformed into arrays of strings.\n",
    "\n",
    "## **Word Bigrams**\n",
    "\n",
    "As noted earlier, modifiers and polarity words are not included in the stopword set. The BoW model constructs a vocabulary containing both unigrams and bigrams. Including bigrams allows the model to capture common word patterns, such as\n",
    "\n",
    "$$\n",
    "\\left\\langle \\texttt{Adj}\\right\\rangle \\left\\langle \\texttt{M} \\mid \\texttt{Pron} \\right\\rangle\n",
    "$$\n",
    "\n",
    "<center>or</center>\n",
    "\n",
    "$$\n",
    "\\left\\langle \\texttt{Adv}\\right\\rangle \\left\\langle \\texttt{V} \\mid \\texttt{Adj} \\mid \\texttt{Adv} \\right\\rangle\n",
    "$$\n",
    "\n",
    "## **Vector Representation**\n",
    "\n",
    "After the stemming and lemmatization steps, each entry can now be represented as a vector using a Bag of Words (BoW) model. We employ scikit-learn's `CountVectorizer`, which provides a ready-to-use implementation of BoW <u>(Pedregosa et al., 2011)</u>.\n",
    "\n",
    "A comparison of other traditional vector representations are discussed in [this appendix](#appendix:-comparison-of-traditional-vectorization-techniques).\n",
    "Words with modifiers have the modifiers directly attached, enabling subsequent models to capture the concept of modification fully. Consequently, after tokenization and bigram construction, the vocabulary size can grow up to $O(n^2)$, where $n$ is the number of unique tokens.\n",
    "\n",
    "**minimum document frequency constraint:** Despite cleaning and spam removal, some tokens remain irrelevant or too rare. To address this, a minimum document frequency constraint is applied: $\\texttt{min\\_df} = 10$, meaning a token must appear in at least 10 documents to be included in the BoW vocabulary. This reduces noise and ensures the model focuses on meaningful terms.\n",
    "\n",
    "---\n",
    "\n",
    "These parameters of the BoW model are encapsulated in the `BagOfWordsModel` class. The class definition is available in [this appendix](#appendix:-BagOfWordsModel-class-definition).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "7bfba459-6837-4481-929c-ef5ee023b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\College\\Year 3\\Term 2\\STINTSY\\STINTSY-Order-of-Erin\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bow = BagOfWordsModel(df[\"lemmatized\"], 10)\n",
    "\n",
    "# some sanity checks\n",
    "assert (\n",
    "    bow.matrix.shape[0] == df.shape[0]\n",
    "), \"number of rows in the matrix DOES NOT matches the number of documents\"\n",
    "assert bow.sparsity, \"the sparsity is TOO HIGH, something went wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75919779-1b56-4bec-9662-90afc11e1356",
   "metadata": {},
   "source": [
    "The error above is normal, recall that our tokenization step essentially reduced into an array split step. With this, we need to set the `tokenizer` function attribute of the `BagOfWordsModel` to not use its default tokenization pattern. That causes this warning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf5220-712f-4af3-9e2e-0fc3753f5cb1",
   "metadata": {},
   "source": [
    "### **Model Metrics**\n",
    "\n",
    "To get an idea of the model, we will now look at its shape and sparsity, with shape being the number of documents and tokens present in the model. While sparsity refers to the number of elements in a matrix that are zero, calculating how sparse or varied the words are in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0246d-899e-4bb6-957a-75419316197a",
   "metadata": {},
   "source": [
    "The resulting vector has a shape of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "b6a5b688-b636-4320-bf22-e508a97aa862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162942, 30386)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc081f2-0630-4a0c-a40a-aeddcdfc8fb8",
   "metadata": {},
   "source": [
    "The first entry of the pair is the number of documents (the ones that remain after all the data cleaning and preprocessing steps) and the second entry is the number of tokens (or unique words in the vocabulary).\n",
    "\n",
    "The resulting model has a sparsity of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "4fd01aa7-4842-4473-b410-591fd47983f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995039539872171"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - bow.sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33434da",
   "metadata": {},
   "source": [
    "The model is 99.95% sparse, meaning the tweets often do not share the same words leading to a large vocabulary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3277d-2106-490d-a304-8ff6e0780fd5",
   "metadata": {},
   "source": [
    "Now, looking at the most frequent and least frequent terms in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "10dd4551-90d0-4795-9303-1118fcc058c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['modi', 'india', 'ha', 'all', 'people', 'bjp', 'like', 'congress',\n",
       "       'narendra', 'only', 'election', 'narendra modi', 'vote', 'govt',\n",
       "       'about', 'indian', 'year', 'time', 'country', 'just', 'modis',\n",
       "       'more', 'nation', 'rahul', 'even', 'government', 'party', 'power',\n",
       "       'gandhi', 'minister', 'leader', 'good', 'modi govt', 'need',\n",
       "       'modi ha', 'space', 'work', 'prime', 'money', 'credit', 'sir',\n",
       "       'pakistan', 'back', 'day', 'today', 'prime minister', 'scientist',\n",
       "       'never', 'support', 'win'], dtype=object)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_frequencies = np.asarray((bow.matrix > 0).sum(axis=0)).flatten()\n",
    "freq_order = np.argsort(doc_frequencies)[::-1]\n",
    "bow.feature_names[freq_order[:50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c2f23-6494-4d41-937f-19664010b138",
   "metadata": {},
   "source": [
    "We see that the main talking point of the Tweets, which hovers around Indian politics with keywords like \"modi\", \"india\", and \"bjp\". For additional context, \"bjp\" referes to the _Bharatiya Janata Party_ which is a conservative political party in India, and one of the two major Indian political parties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b775494-3472-4089-8d86-e24346616155",
   "metadata": {},
   "source": [
    "Now, looking at the least popular words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "35f91a0d-dae1-41af-9f92-c06a973ebbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['healthy democracy', 'ha mass', 'ha separate', 'ha shifted',\n",
       "       'hat drdo', 'about defeat', 'yet ha', 'yes more', 'yes narendra',\n",
       "       'hatred people', 'ha requested', 'hate more', 'hate much',\n",
       "       'hatemonger', 'hater gonna', 'heal', 'hazaribagh', 'head drdo',\n",
       "       'sleep night', 'abinandan', 'able provide', 'able speak',\n",
       "       'able vote', 'youth need', 'youth power', 'hai isliye', 'hai chor',\n",
       "       'handy', 'hand narendra', 'hand people', 'hae', 'ha withdrawn',\n",
       "       'happens credit', 'happier', 'bhaiyo', 'socha', 'social political',\n",
       "       'social security', 'biased journalist', 'big congratulation',\n",
       "       'sirmodi', 'bhutan', 'bhi berozgar', 'bhi mumkin', 'skta',\n",
       "       'bhatt aditi', 'bhi aur', 'slamming', 'smart modi', 'slogan blame'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.feature_names[freq_order[-50:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5478a6-4ff0-4d64-a329-11278fe4e60a",
   "metadata": {},
   "source": [
    "We still see that the themes mentioned in the most frequent terms are still present in this subset. Although, more filler or non-distinct words do appear more often, like \"photos\", \"soft\" and \"types\".\n",
    "\n",
    "But the present of words like \"reelection\" and \"wars\" still point to this subset still being relevant to the main theme of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb530e2",
   "metadata": {},
   "source": [
    "# **4 exploratory data analysis**\n",
    "\n",
    "This section discusses the exploratory data analysis conducted on the dataset after cleaning.\n",
    "\n",
    "> Notes from Zhean: <br>\n",
    "> From manual checking via OpenRefine, there are a total of 162972. `df.info()` should have the same result post-processing.\n",
    "> Furthermore, there should be two columns, `clean_text` (which is a bit of a misnormer since it is still dirty) contains the Tweets (text data). The second column is the `category` which contains the sentiment of the Tweet and is a tribool (1 positive, 0 neutral or indeterminate, and -1 for negative).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ad21e-cb7b-4d91-87f9-a14c15ec8365",
   "metadata": {},
   "source": [
    "# **references**\n",
    "\n",
    "Bird, S., & Loper, E. (2004, July). NLTK: The natural language toolkit. _Proceedings of the ACL Interactive Poster and Demonstration Sessions_, 214‚Äì217. https://aclanthology.org/P04-3031/\n",
    "\n",
    "El-Demerdash, A. A., Hussein, S. E., & Zaki, J. F. W. (2021). Course evaluation based on deep learning and SSA hyperparameters optimization. _Computers, Materials & Continua, 71_(1), 941‚Äì959. https://doi.org/10.32604/cmc.2022.021839\n",
    "\n",
    "George, M., & Murugesan, R. (2024). Improving sentiment analysis of financial news headlines using hybrid Word2Vec-TFIDF feature extraction technique. _Procedia Computer Science, 244_, 1‚Äì8.\n",
    "\n",
    "Hussein, S. (2021). _Twitter sentiments dataset_. Mendeley.\n",
    "\n",
    "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. _Journal of Machine Learning Research, 12_, 2825‚Äì2830.\n",
    "\n",
    "Rani, D., Kumar, R., & Chauhan, N. (2022, October). Study and comparison of vectorization techniques used in text classification. In _2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)_ (pp. 1‚Äì6). IEEE.\n",
    "\n",
    "Wolfram Research. (2015). _DeleteStopwords_. https://reference.wolfram.com/language/ref/DeleteStopwords.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7173f9-2c8d-4a5a-af3d-95761f09463a",
   "metadata": {},
   "source": [
    "# **appendix: `clean` wrapper function definition**\n",
    "\n",
    "Below is the definition of the `clean` wrapper function that encapsulates all internal functions used in the cleaning pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "fef8310b-aad6-4e48-80e6-e891c17a0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m clean(text: str) -> str\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m clean(text: str) -> str:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    This is the main function for data cleaning (i.e., it calls all the cleaning functions in the prescribed order).\u001b[39m\n",
      "\n",
      "\u001b[33m    This function should be used as a first-class function in a map.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: The string entry from a DataFrame column.\u001b[39m\n",
      "\u001b[33m    * stopwords: stopword dictionary.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m    Clean string\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;66;03m# cleaning on the base string\u001b[39;00m\n",
      "    text = normalize(text)\n",
      "    text = rem_punctuation(text)\n",
      "    text = rem_numbers(text)\n",
      "    text = collapse_whitespace(text)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[31mFile:\u001b[39m      a:\\college\\year 3\\term 2\\stintsy\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "clean??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d116f4e-672a-4f3e-aa7d-1ee96d62d86b",
   "metadata": {},
   "source": [
    "# **appendix: `find_spam_and_empty` wrapper function definition**\n",
    "\n",
    "Below is the definition of the `find_spam_and_empty` wrapper function that encapsulates all internal functions for the spam detection algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "434da366-1648-4abd-8af0-ad4d4cd53d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m find_spam_and_empty(text: str, min_length: int = \u001b[32m3\u001b[39m) -> str | \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m find_spam_and_empty(text: str, min_length: int = \u001b[32m3\u001b[39m) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Filter out empty text and unintelligible/spammy unintelligible substrings in the text.\u001b[39m\n",
      "\n",
      "\u001b[33m    Spammy substrings:\u001b[39m\n",
      "\u001b[33m    - Shorter than min_length\u001b[39m\n",
      "\u001b[33m    - Containing non-alphabetic characters\u001b[39m\n",
      "\u001b[33m    - Consisting of a repeated substring (e.g., 'aaaaaa', 'ababab', 'abcabcabc')\u001b[39m\n",
      "\n",
      "\u001b[33m    # Parameters\u001b[39m\n",
      "\u001b[33m    * text: input string.\u001b[39m\n",
      "\u001b[33m    * min_length: minimum length of word to keep.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Returns\u001b[39m\n",
      "\u001b[33m        Cleaned string, or None if empty after filtering.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    cleaned_tokens = []\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;28;01min\u001b[39;00m text.split():\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(t) < min_length:\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m re.search(\u001b[33mr\"(.)\\1{2,}\"\u001b[39m, t):\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        min_diversity = \u001b[32m0.3\u001b[39m + (\u001b[32m0.1\u001b[39m * min(len(t), \u001b[32m10\u001b[39m) / \u001b[32m10\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(set(t)) / len(t) < min_diversity:\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m re.match(\u001b[33mr\"^(.+)\\1+\"\u001b[39m, t):\n",
      "            \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "        cleaned_tokens.append(t)\n",
      "\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\" \"\u001b[39m.join(cleaned_tokens) \u001b[38;5;28;01mif\u001b[39;00m cleaned_tokens \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mFile:\u001b[39m      a:\\college\\year 3\\term 2\\stintsy\\stintsy-order-of-erin\\lib\\janitor.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "find_spam_and_empty??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f63c6-670f-42b1-8195-3c8156b2f4be",
   "metadata": {},
   "source": [
    "# **appendix: comparison of traditional vectorization techniques**\n",
    "\n",
    "Traditional vectorization techniques include BoW and Term Frequency-Inverse Document Frequency (TF-IDF). TF-IDF weights each word based on its frequency in a document and its rarity across the corpus, reducing the impact of common words. BoW, in contrast, simply counts word occurrences without considering corpus-level frequency. In this project, BoW was chosen because stopwords were already removed during preprocessing, and the dataset is domain-specific <u>(Rani et al., 2022)</u>. In such datasets, frequent words are often meaningful domain keywords, so scaling them down (as TF-IDF would) could reduce the importance of these key terms in the feature representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e651fa3-b1f3-4e71-9092-018bbabc07dc",
   "metadata": {},
   "source": [
    "# **appendix: `BagOfWordsModel` class definition**\n",
    "\n",
    "Below is the definition of the `BagOfWordsModel` class that encapsulates the desired parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "0a9c57a0-98b3-40cb-8cd4-a1d9b30eb6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m BagOfWordsModel(texts: Iterable[str], min_freq: int | float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mSource:\u001b[39m        \n",
      "\u001b[38;5;28;01mclass\u001b[39;00m BagOfWordsModel:\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    A Bag-of-Words representation for a text corpus.\u001b[39m\n",
      "\n",
      "\u001b[33m    # Attributes\u001b[39m\n",
      "\u001b[33m    * matrix (scipy.sparse.csr_matrix): The document-term matrix of word counts.\u001b[39m\n",
      "\u001b[33m    * feature_names (list[str]): List of feature names corresponding to the matrix columns.\u001b[39m\n",
      "\u001b[33m    *\u001b[39m\n",
      "\u001b[33m    # Usage\u001b[39m\n",
      "\u001b[33m    ```\u001b[39m\n",
      "\u001b[33m    bow = BagOfWordsModel(df[\"lemmatized_str\"])\u001b[39m\n",
      "\u001b[33m    ```\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __init__(self, texts: Iterable[str], min_freq: int | float | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Initialize the BagOfWordsModel by fitting the vectorizer to the text corpus. This also filters out tokens\u001b[39m\n",
      "\u001b[33m        that do not appear more than five times in the dataset.\u001b[39m\n",
      "\n",
      "\u001b[33m        This sets its tokenizer to the word boundary tokenizer since the input, at this point, **should** be\u001b[39m\n",
      "\u001b[33m        cleaned and processed text.\u001b[39m\n",
      "\n",
      "\u001b[33m        This also uses both unigrams and bigrams, hence, at the worst case its space complexity is O(n^2).\u001b[39m\n",
      "\n",
      "\u001b[33m        # Parameters\u001b[39m\n",
      "\u001b[33m        * texts: An iterable of cleaned text documents.\u001b[39m\n",
      "\u001b[33m        * min_freq: Determines the document frequency of a token for it to appear in the model.\u001b[39m\n",
      "\u001b[33m        Can be a type of int (i.e., the token must appear min_freq number of times in the document)\u001b[39m\n",
      "\u001b[33m        or a float (i.e, token must be in min_freq% of the documents)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        vectorizer = CountVectorizer(\n",
      "            min_df=min_freq \u001b[38;5;28;01mif\u001b[39;00m min_freq \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m,\n",
      "            tokenizer=str.split,    \u001b[38;5;66;03m# Use str.split instead of lambda\u001b[39;00m\n",
      "            lowercase=\u001b[38;5;28;01mFalse\u001b[39;00m,        \u001b[38;5;66;03m# Don't lowercase\u001b[39;00m\n",
      "            ngram_range=(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m),      \u001b[38;5;66;03m# Unigrams and bigrams\u001b[39;00m\n",
      "        )\n",
      "        self.matrix = vectorizer.fit_transform(texts)\n",
      "        self.feature_names = vectorizer.get_feature_names_out()\n",
      "        self.vectorizer = vectorizer\n",
      "        self.sparsity = self.matrix.nnz / (self.matrix.shape[\u001b[32m0\u001b[39m] * self.matrix.shape[\u001b[32m1\u001b[39m])\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m transform_sentence(self, sentence: str):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Returns the embedding of the sentence using the BoW matrix.\u001b[39m\n",
      "\n",
      "\u001b[33m        # Parameters:\u001b[39m\n",
      "\u001b[33m        * sentence: Cleaned sentence to vectorize.\u001b[39m\n",
      "\n",
      "\u001b[33m        # Returns\u001b[39m\n",
      "\u001b[33m        Sentence embedding.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.vectorizer.transform([sentence])\n",
      "\u001b[31mFile:\u001b[39m           a:\\college\\year 3\\term 2\\stintsy\\stintsy-order-of-erin\\lib\\bag_of_words.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "BagOfWordsModel??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
