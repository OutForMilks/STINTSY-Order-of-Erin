{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44906e4e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Twitter Posts\n",
    "<!-- Notebook name goes here -->\n",
    "<center><b>Notebook: Data Description, Cleaning, Exploratory Data Analysis, and Preprocessing</b></center>\n",
    "<br>\n",
    "\n",
    "**By**: Stephen Borja, Justin Ching, Erin Chua, and Zhean Ganituen.\n",
    "\n",
    "**Dataset**: Hussein, S. (2021). Twitter Sentiments Dataset [Dataset]. Mendeley. https://doi.org/10.17632/Z9ZW7NT5H2.1\n",
    "\n",
    "**Motivation**: Every minute, social media users generate a large influx of textual data on live events. Performing sentiment analysis on this data provides a real-time view of public perception, enabling quick insights into the general populationâ€™s opinions and reactions.\n",
    "\n",
    "**Goal**: By the end of the project, our goal is to create and compare supervised learning algorithms for sentiment analysis.\n",
    "\n",
    "### **Dataset Description**\n",
    "\n",
    "The Twitter Sentiments Dataset is a dataset that contains nearly 163k tweets from Twitter. The time period of when these were collected is unknown, but it was published to Mendeley Data on May 14, 2021 by Sherif Hussein of Mansoura University.\n",
    "\n",
    "Tweets were extracted using the Twitter API, but the specifics of how the tweets were selected are unmentioned. The tweets are mostly English with a mix of some Hindi words for code-switching<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1). All of them seem to be talking about the political state of India. Most tweets mention Narendra Modi, the current Prime Minister of India.\n",
    "\n",
    "Each tweet was assigned a label using TextBlob's sentiment analysis (Elâ€‘Demerdash, Hussein, & Zaki, 2021), which assigns labels automatically.\n",
    "\n",
    "What each row and column represents: `each row represents one tweet.`\n",
    "Number of observations: `162,980`\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) Code-switching is the practice of alternating between two languages $L_1$ (the native language) and $L_2$ (the source language) in a conversation. In this context, the code-switching is done to appear more casual since the conversation is done via Twitter (now, X). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed82ded3d24a0cb",
   "metadata": {},
   "source": [
    "Twitter_Data\n",
    "- **`clean_text`**: The tweet's text\n",
    "- **`category`**: The tweet's sentiment category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47491b2f",
   "metadata": {},
   "source": [
    "## 1 project set up\n",
    "Set up here the imports for the projects (ensure these are installed via uv and is part of the environment). Furthermore, load the dataset here. Also load the raw dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7578d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:01:26.803271Z",
     "start_time": "2025-06-17T14:01:26.567527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92614     dreaming too much thanks modi government rahul...\n",
       "111504    today after arnabs interview modi there shorta...\n",
       "41132     nirav modi mallya dawood being brought india b...\n",
       "103473    you have already lost your mind and speaking a...\n",
       "25923     apache ah64e\\ntotal contract first batch arriv...\n",
       "158078    india and modi called out the paki bluff nucle...\n",
       "117486    like that onemodi should question answer\\nhaha...\n",
       "56450     just like notebandi could have been announced ...\n",
       "21421     narendra modi bjp name bigad rahe valsad bjp t...\n",
       "42638     ill put bet prime minister modi informing peop...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "# no need to import `torch` here since no training occurs yet.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load raw data file\n",
    "df = pd.read_csv(\"../data/Twitter_Data.csv\")\n",
    "\n",
    "# At this point, we only want the `clean_text` column\n",
    "#     Remark. The `clean_text` column (at this point in the project) is a bit of a misnomer.\n",
    "#     Since, after manual validation and exploration, it is still dirty.\n",
    "#     Hence, moving forward, the `clean_text` column will be simply referred to as `text`.\n",
    "text = df[\"clean_text\"]\n",
    "#text.sample(n=10)    # sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ec446",
   "metadata": {},
   "source": [
    "## 2 data cleaning\n",
    "This section discusses the methodology for data cleaning.\n",
    "\n",
    "---\n",
    "**References**\n",
    "1. ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6190c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb4d20",
   "metadata": {},
   "source": [
    "# 3 preprocessing\n",
    "\n",
    "> ðŸ—ï¸ Perhaps swap S3 and S4. Refer to literature on what comes first.\n",
    "\n",
    "This section discusses preprocessing steps for the cleaned data.\n",
    "\n",
    "---\n",
    "**References**\n",
    "1. ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856f6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb530e2",
   "metadata": {},
   "source": [
    "# 4 exploratory data analysis\n",
    "\n",
    "This section discusses the exploratory data analysis conducted on the dataset after cleaning.\n",
    "\n",
    "> Notes from Zhean: <br>\n",
    "> From manual checking via OpenRefine, there are a total of 162972. `df.info()` should have the same result post-processing.\n",
    "> Furthermore, there should be two columns, `clean_text` (which is a bit of a misnormer since it is still dirty) contains the Tweets (text data). The second column is the `category` which contains the sentiment of the Tweet and is a tribool (1 positive, 0 neutral or indeterminate, and -1 for negative).\n",
    "\n",
    "---\n",
    "**References**\n",
    "1. ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53bbe181",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
